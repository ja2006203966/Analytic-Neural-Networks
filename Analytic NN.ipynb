{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.optimize as opt\n",
    "# import sys, os, random, gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras import metrics\n",
    "# from keras.utils import np_utils\n",
    "# import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "# ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(10):\n",
    "for example in ds.take(i):\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "#         x.append(image)\n",
    "#         y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(3):\n",
    "    image, label = example[\"image\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PandasArray>\n",
       "[7129300520, 6414100192, 5631500400, 2487200875, 1954400510, 7237550310,\n",
       " 1321400060, 2008000270, 2414600126, 3793500160,\n",
       " ...\n",
       " 7852140040, 9834201367, 3448900210, 7936000429, 2997800021,  263000018,\n",
       " 6600060120, 1523300141,  291310100, 1523300157]\n",
       "Length: 21613, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"id\"].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_ALIASES',\n",
       " '_AXIS_IALIASES',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_NAMES',\n",
       " '_AXIS_NUMBERS',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_numeric_operations',\n",
       " '_add_series_or_dataframe_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_aggregate',\n",
       " '_aggregate_multiple_funcs',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_box_col_values',\n",
       " '_box_item_values',\n",
       " '_builtin_table',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_combine_frame',\n",
       " '_combine_match_index',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_dict_from',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_create_indexer',\n",
       " '_cython_table',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_from_arrays',\n",
       " '_from_axes',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_cython_func',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_iget_item_cache',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_internal_get_values',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_builtin_func',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_datelike_mixed_type',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_numeric_mixed_type',\n",
       " '_is_view',\n",
       " '_ix',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_needs_reindex_multi',\n",
       " '_obj_with_exclusions',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_selected_obj',\n",
       " '_selection',\n",
       " '_selection_list',\n",
       " '_selection_name',\n",
       " '_series',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_setup_axes',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_try_aggregate_string_function',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " '_xs',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'condition',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'date',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'floordiv',\n",
       " 'floors',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'grade',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'id',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'lat',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'long',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'price',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'sqft_living',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot',\n",
       " 'sqft_lot15',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tshift',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'waterfront',\n",
       " 'where',\n",
       " 'xs',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg = x_rg[:,2]\n",
    "x_rg = x_rg[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 18), (21613,))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape, y_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(tf.keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQV(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(KQV, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "        wk_init = tf.random_normal_initializer()\n",
    "        wv_init = tf.random_normal_initializer()\n",
    "        \n",
    "        self.wq = tf.Variable(initial_value=wq_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wk = tf.Variable(initial_value=wk_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wv = tf.Variable(initial_value=wv_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "\n",
    "        \n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(self.units,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        q = tf.matmul(self.wq,inputs)\n",
    "        k = tf.matmul(self.wk,inputs)\n",
    "        v = tf.matmul(self.wv, inputs)\n",
    "\n",
    "        return k, q, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "#         a = tf.constant(a)\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "#         cn = tf.cast(cn, tf.float64)\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "#         vc = tf.cast(vc, tf.float64)\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "#         out_num = self.order*2\n",
    "#         v = tf.expand_dims(v, axis = -1)\n",
    "#         v = tf.tile(v, self.Tile_reshape(out_num))\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"vc shape:\", vc1.shape)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        print(\"v shape:\", v.shape)\n",
    "#         v = tf.Variable(self.rui(shape = tf.shape(v)), dtype=tf.float32)*v\n",
    "        \n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        q = self.wq(q)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        k = self.wk(v)\n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         print(\"wk\",k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         n = tf.matmul(q,k) ##tooooooooooo slow\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##--------------------------------------------------------------------normalize----------\n",
    "#         k = tf.math.log(tf.math.abs(k+1e-10)+1)\n",
    "#         q = tf.math.log(tf.math.abs(q+1e-10)+1)\n",
    "\n",
    "#         print(\"kdiv\",tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))\n",
    "\n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "#         n = k*q\n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##-----------------------------------------------top k version------------------------------\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "##------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "#         n = k*q\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=1000, num_out=100, rank=2):\n",
    "        super(Data_Selection, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, q, k, v):\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        n = k*q\n",
    "##------------------------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.expand_dims(v, axis=-1)\n",
    "        v = n*v\n",
    "        v = tf.reduce_sum(v, axis=-2)\n",
    "        print(\"v shape:\", v.shape)\n",
    "\n",
    "##-----------------------------------------------------\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(tf.rank(x))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train, axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(np.sum(x_train, axis = -1), axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "\n",
    "x_train = x_train/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (1, 18)\n",
      "vc shape: (1, 18)\n",
      "v shape: (1, 18, 7)\n",
      "wk tf.Tensor(\n",
      "[[[ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]]], shape=(1, 18, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[ 2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19]\n",
      "  [-8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18]\n",
      "  [ 2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19]\n",
      "  [ 3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19]\n",
      "  [-2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19]\n",
      "  [ 2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19]\n",
      "  [-3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[ 1.1536372e+00  8.6522788e-01  8.5080743e+02  1.4420465e+03\n",
      "    5.7681859e-01  0.0000000e+00  8.6522788e-01  8.6522788e-01\n",
      "    2.5956836e+00  5.7105042e+02  2.7975702e+02  5.7076196e+02\n",
      "    0.0000000e+00  2.8300451e+04  1.3720034e+01 -3.5294086e+01\n",
      "    6.1719586e+02  1.1536372e+03]\n",
      "  [-8.5340548e-01 -6.4005411e-01 -6.2938654e+02 -1.0667568e+03\n",
      "   -4.2670274e-01  0.0000000e+00 -6.4005411e-01 -6.4005411e-01\n",
      "   -1.9201623e+00 -4.2243570e+02 -2.0695082e+02 -4.2222235e+02\n",
      "    0.0000000e+00 -2.0935316e+04 -1.0149424e+01  2.6108873e+01\n",
      "   -4.5657193e+02 -8.5340546e+02]\n",
      "  [ 1.4279835e+00  1.0709877e+00  1.0531378e+03  1.7849794e+03\n",
      "    7.1399176e-01  0.0000000e+00  1.0709877e+00  1.0709877e+00\n",
      "    3.2129629e+00  7.0685187e+02  3.4628601e+02  7.0649487e+02\n",
      "    0.0000000e+00  3.5030578e+04  1.6982794e+01 -4.3687370e+01\n",
      "    7.6397119e+02  1.4279835e+03]\n",
      "  [-1.1096001e-02 -8.3220005e-03 -8.1833000e+00 -1.3870001e+01\n",
      "   -5.5480003e-03  0.0000000e+00 -8.3220005e-03 -8.3220005e-03\n",
      "   -2.4966002e-02 -5.4925203e+00 -2.6907802e+00 -5.4897461e+00\n",
      "    0.0000000e+00 -2.7220154e+02 -1.3196307e-01  3.3946827e-01\n",
      "   -5.9363604e+00 -1.1096001e+01]\n",
      "  [-7.7478671e-01 -5.8109003e-01 -5.7140521e+02 -9.6848340e+02\n",
      "   -3.8739336e-01  0.0000000e+00 -5.8109003e-01 -5.8109003e-01\n",
      "   -1.7432702e+00 -3.8351941e+02 -1.8788577e+02 -3.8332571e+02\n",
      "    0.0000000e+00 -1.9006680e+04 -9.2144222e+00  2.3703630e+01\n",
      "   -4.1451089e+02 -7.7478668e+02]\n",
      "  [-8.7473464e-01 -6.5605098e-01 -6.4511682e+02 -1.0934183e+03\n",
      "   -4.3736732e-01  0.0000000e+00 -6.5605098e-01 -6.5605098e-01\n",
      "   -1.9681530e+00 -4.3299365e+02 -2.1212315e+02 -4.3277496e+02\n",
      "    0.0000000e+00 -2.1458553e+04 -1.0403088e+01  2.6761414e+01\n",
      "   -4.6798303e+02 -8.7473462e+02]\n",
      "  [-1.6690795e+00 -1.2518096e+00 -1.2309462e+03 -2.0863494e+03\n",
      "   -8.3453977e-01  0.0000000e+00 -1.2518096e+00 -1.2518096e+00\n",
      "   -3.7554290e+00 -8.2619440e+02 -4.0475180e+02 -8.2577710e+02\n",
      "    0.0000000e+00 -4.0945023e+04 -1.9850113e+01  5.1063404e+01\n",
      "   -8.9295758e+02 -1.6690796e+03]]], shape=(1, 7, 18), dtype=float32)\n",
      "kdiv tf.Tensor([[35989.742 34145.016 35813.79  36438.703 35999.33  35913.438 36220.984]], shape=(1, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[3.6966380e-02 3.0038426e-02 3.2512918e-01 3.5053056e-01 2.1944409e-02\n",
      "   0.0000000e+00 3.0038426e-02 3.0038426e-02 6.1665431e-02 3.0594465e-01\n",
      "   2.7164879e-01 3.0592036e-01 0.0000000e+00 4.9394003e-01 1.2958258e-01\n",
      "   1.7306793e-01 3.0968288e-01 3.3978647e-01]\n",
      "  [3.1124566e-02 2.4955617e-02 3.2517225e-01 3.5175481e-01 1.7925721e-02\n",
      "   0.0000000e+00 2.4955617e-02 2.4955617e-02 5.4056674e-02 3.0509943e-01\n",
      "   2.6922941e-01 3.0507401e-01 0.0000000e+00 5.0186938e-01 1.2163760e-01\n",
      "   1.6645484e-01 3.0901039e-01 3.4051058e-01]\n",
      "  [4.1416258e-02 3.3991005e-02 3.2497981e-01 3.4959647e-01 2.5157360e-02\n",
      "   0.0000000e+00 3.3991005e-02 3.3991005e-02 6.7146964e-02 3.0638611e-01\n",
      "   2.7313933e-01 3.0636257e-01 0.0000000e+00 4.8855704e-01 1.3490477e-01\n",
      "   1.7740490e-01 3.1000936e-01 3.3918458e-01]\n",
      "  [1.3964046e-03 1.0487455e-03 2.8059804e-01 3.4158731e-01 7.0012844e-04\n",
      "   0.0000000e+00 1.0487455e-03 1.0487455e-03 3.1205164e-03 2.3672052e-01\n",
      "   1.6524658e-01 2.3666644e-01 0.0000000e+00 7.0994109e-01 1.5685607e-02\n",
      "   3.6985498e-02 2.4508846e-01 3.1545955e-01]\n",
      "  [2.9375188e-02 2.3457661e-02 3.2514268e-01 3.5212332e-01 1.6765820e-02\n",
      "   0.0000000e+00 2.3457661e-02 2.3457661e-02 5.1673368e-02 3.0477071e-01\n",
      "   2.6837167e-01 3.0474490e-01 0.0000000e+00 5.0450039e-01 1.1898976e-01\n",
      "   1.6421126e-01 3.0873981e-01 3.4071052e-01]\n",
      "  [3.1581409e-02 2.5348648e-02 3.2517639e-01 3.5165882e-01 1.8231904e-02\n",
      "   0.0000000e+00 2.5348648e-02 2.5348648e-02 5.4670598e-02 3.0517879e-01\n",
      "   2.6944196e-01 3.0515346e-01 0.0000000e+00 5.0120461e-01 1.2230630e-01\n",
      "   1.6701820e-01 3.0907512e-01 3.4045699e-01]\n",
      "  [4.4809200e-02 3.7049923e-02 3.2481110e-01 3.4887856e-01 2.7695838e-02\n",
      "   0.0000000e+00 3.7049923e-02 3.7049923e-02 7.1170427e-02 3.0663100e-01\n",
      "   2.7411965e-01 3.0660796e-01 0.0000000e+00 4.8472837e-01 1.3863398e-01\n",
      "   1.8040195e-01 3.1017375e-01 3.3869913e-01]]], shape=(1, 7, 18), dtype=float32)\n",
      "v shape: (1, 18, 7)\n",
      "n shape: (1, 18, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
       " array([[9.7922925e+17, 8.0966167e+17, 7.1021882e+18, 7.6290285e+18,\n",
       "         6.0524301e+17, 0.0000000e+00, 8.0966167e+17, 8.0966167e+17,\n",
       "         1.5553235e+18, 6.7042557e+18, 5.9927380e+18, 6.7037515e+18,\n",
       "         0.0000000e+00, 1.0603152e+19, 3.0297832e+18, 3.9428487e+18,\n",
       "         6.7817976e+18, 7.4061943e+18]], dtype=float32)>,\n",
       " array([[ 4.00000e+00,  3.00000e+00,  2.95000e+03,  5.00000e+03,\n",
       "          2.00000e+00,  0.00000e+00,  3.00000e+00,  3.00000e+00,\n",
       "          9.00000e+00,  1.98000e+03,  9.70000e+02,  1.97900e+03,\n",
       "          0.00000e+00,  9.81260e+04,  4.75714e+01, -1.22375e+02,\n",
       "          2.14000e+03,  4.00000e+03]], dtype=float32))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_rg[15:16]\n",
    "Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x,x,x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n"
     ]
    }
   ],
   "source": [
    "## tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(18))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.math.is_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(x_rg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_116 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_48 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_117 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_49 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = np.array(x_rg)\n",
    "y_rg = np.array(y_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = x_rg.astype(np.float32)\n",
    "y_rg = y_rg.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0221 - accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0218 - accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "676/676 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0214 - accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0210 - accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0204 - accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 4.6572e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0194 - accuracy: 4.6268e-05\n",
      "Epoch 7/30\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 4.6296e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0175 - accuracy: 4.6268e-05\n",
      "Epoch 8/30\n",
      "674/676 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 9.2730e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0145 - accuracy: 9.2537e-05\n",
      "Epoch 9/30\n",
      "676/676 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.8507e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0108 - accuracy: 1.8507e-04\n",
      "Epoch 10/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 1.8629e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0084 - accuracy: 1.8507e-04\n",
      "Epoch 11/30\n",
      "673/676 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 1.8574e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0063 - accuracy: 1.8507e-04\n",
      "Epoch 12/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 1.3972e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0046 - accuracy: 1.3881e-04\n",
      "Epoch 13/30\n",
      "676/676 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.3881e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0026 - accuracy: 1.3881e-04\n",
      "Epoch 14/30\n",
      "673/676 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 9.2868e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0018 - accuracy: 9.2537e-05\n",
      "Epoch 15/30\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 9.2593e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0014 - accuracy: 9.2537e-05\n",
      "Epoch 16/30\n",
      "675/676 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 9.2593e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0012 - accuracy: 9.2537e-05\n",
      "Epoch 17/30\n",
      "676/676 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 9.2537e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.0011 - accuracy: 9.2537e-05\n",
      "Epoch 18/30\n",
      "674/676 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 9.2730e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0011 - accuracy: 9.2537e-05\n",
      "Epoch 19/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 9.1755e-04 - accuracy: 1.3972e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 9.1422e-04 - accuracy: 1.3881e-04\n",
      "Epoch 20/30\n",
      "675/676 [============================>.] - ETA: 0s - loss: 8.1693e-04 - accuracy: 9.2593e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 8.1666e-04 - accuracy: 9.2537e-05\n",
      "Epoch 21/30\n",
      "672/676 [============================>.] - ETA: 0s - loss: 7.2967e-04 - accuracy: 1.3951e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 7.2891e-04 - accuracy: 1.3881e-04\n",
      "Epoch 22/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 6.7885e-04 - accuracy: 1.8629e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 6.7684e-04 - accuracy: 1.8507e-04\n",
      "Epoch 23/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 6.9487e-04 - accuracy: 1.8629e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 6.9307e-04 - accuracy: 1.8507e-04\n",
      "Epoch 24/30\n",
      "671/676 [============================>.] - ETA: 0s - loss: 6.3376e-04 - accuracy: 2.3286e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 6.3319e-04 - accuracy: 2.3134e-04\n",
      "Epoch 25/30\n",
      "675/676 [============================>.] - ETA: 0s - loss: 6.1968e-04 - accuracy: 2.3148e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 6.1978e-04 - accuracy: 2.3134e-04\n",
      "Epoch 26/30\n",
      "672/676 [============================>.] - ETA: 0s - loss: 5.8289e-04 - accuracy: 2.3251e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 5.8180e-04 - accuracy: 2.3134e-04\n",
      "Epoch 27/30\n",
      "670/676 [============================>.] - ETA: 0s - loss: 5.8900e-04 - accuracy: 2.3321e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 5.8858e-04 - accuracy: 2.3134e-04\n",
      "Epoch 28/30\n",
      "673/676 [============================>.] - ETA: 0s - loss: 5.6761e-04 - accuracy: 2.7860e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 5.6774e-04 - accuracy: 2.7761e-04\n",
      "Epoch 29/30\n",
      "676/676 [==============================] - ETA: 0s - loss: 5.4943e-04 - accuracy: 2.7761e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 5.4943e-04 - accuracy: 2.7761e-04\n",
      "Epoch 30/30\n",
      "673/676 [============================>.] - ETA: 0s - loss: 5.3331e-04 - accuracy: 3.2504e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 5.3449e-04 - accuracy: 3.2388e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff27fade8d0>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), callbacks = callbacks, shuffle=True , epochs=30, batch_size=32, verbose=1)\n",
    "# modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = modelANN.predict(np.log(np.abs(x_rg)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5294644 ],\n",
       "       [0.46715382],\n",
       "       [0.5347007 ],\n",
       "       ...,\n",
       "       [0.5334146 ],\n",
       "       [0.5299744 ],\n",
       "       [0.5346126 ]], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "# plt.hist(y_pre, histtype='step')\n",
    "# plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "plt.xlabel(\"Model Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.scatter(y_pre,np.log(np.abs(y_rg)+1))\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\")\n",
    "plt.hist(np.log(np.abs(y_rg)+1), histtype='step',  label = \"target\")\n",
    "plt.legend()\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28)\n",
      "(None, 784)\n",
      "n shape: (None, 784, 100)\n",
      "v shape: (None, 100)\n",
      "(None, 100)\n",
      "v shape: (None, 100, 7)\n",
      "n shape: (None, 100, 7)\n",
      "(None, 100)\n",
      "(None, 100)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = inputs\n",
    "# x = tf.cast(x, tf.float64)\n",
    "print(x.shape)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "x = Data_Selection(node = 100, num_out=20,rank=tf.rank(x))(x,x,x)\n",
    "print(x.shape)\n",
    "\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# c = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# c = tf.squeeze(c, axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "# print(x.shape)\n",
    "# a = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([x,b], axis=-1)\n",
    "# c = tf.concat([x,c], axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# c = Operator_Basis(num_out=1,rank=tf.rank(c))(c, c, c)\n",
    "# print(\"a:\",a.shape)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "\n",
    "# x = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([b,c], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(b))(b, b, b)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "print(x.shape)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "data__selection_16 (Data_Sel (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_45 (Sym (None, 100)               70        \n",
      "_________________________________________________________________\n",
      "operator__basis_30 (Operator (None, 100)               30        \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,510\n",
      "Trainable params: 1,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [ for i in y_train]\n",
    "y2 = []\n",
    "for i in y_train:\n",
    "    vec = np.zeros([10])    \n",
    "    vec[i]=1\n",
    "    y2.append(vec)\n",
    "y2=np.array(y2)    \n",
    "y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1954 - accuracy: 0.2388\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1695 - accuracy: 0.2695\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1632 - accuracy: 0.2755\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 53s 29ms/step - loss: 2.1611 - accuracy: 0.2781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4141d8550>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# modelANN.fit(x_train, y2 , callbacks = callbacks, shuffle=True , epochs=400, batch_size=32, verbose=1)\n",
    "modelANN.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Block\n",
    "class Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(Selection, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "#         self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540412\n",
      "0.9305041\n",
      "0.90742856\n",
      "0.8848088\n",
      "0.862639\n",
      "0.8409134\n",
      "0.8196262\n",
      "0.79877156\n",
      "0.7783437\n",
      "0.7583367\n",
      "0.73874485\n",
      "0.7195623\n",
      "0.70078325\n",
      "0.68240196\n",
      "0.66441256\n",
      "0.64680934\n",
      "0.6295866\n",
      "0.6127385\n",
      "0.59625936\n",
      "0.5801435\n",
      "0.5643853\n",
      "0.54897904\n",
      "0.5339191\n",
      "0.5191999\n",
      "0.50481594\n",
      "0.4907616\n",
      "0.47703144\n",
      "0.46361995\n",
      "0.4505217\n",
      "0.43773136\n",
      "0.4252435\n",
      "0.41305286\n",
      "0.40115413\n",
      "0.3895421\n",
      "0.3782116\n",
      "0.36715743\n",
      "0.35637453\n",
      "0.34585783\n",
      "0.33560234\n",
      "0.3256031\n",
      "0.3158552\n",
      "0.30635378\n",
      "0.29709405\n",
      "0.28807122\n",
      "0.2792806\n",
      "0.2707176\n",
      "0.26237753\n",
      "0.25425592\n",
      "0.24634825\n",
      "0.23865008\n",
      "0.23115706\n",
      "0.22386485\n",
      "0.21676919\n",
      "0.20986587\n",
      "0.20315073\n",
      "0.1966197\n",
      "0.19026873\n",
      "0.18409383\n",
      "0.1780911\n",
      "0.17225665\n",
      "0.16658668\n",
      "0.16107745\n",
      "0.15572527\n",
      "0.1505265\n",
      "0.14547755\n",
      "0.14057492\n",
      "0.13581514\n",
      "0.13119482\n",
      "0.12671058\n",
      "0.12235916\n",
      "0.11813731\n",
      "0.11404186\n",
      "0.11006968\n",
      "0.10621771\n",
      "0.102482945\n",
      "0.09886242\n"
     ]
    }
   ],
   "source": [
    "while var1.numpy()>0.1:\n",
    "    opt.minimize(loss, [var1]).numpy()\n",
    "    print(var1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,1],[2,2],[3,3]])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [4, 4],\n",
       "       [9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry Variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: m<=n\n",
    "def find_N(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    n = a[-1:].numpy()\n",
    "    n = n[0]\n",
    "    return n\n",
    "\n",
    "def Tile_reshape(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    b = a*0+1\n",
    "    a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "    return a\n",
    "def VP(m, cn): # m: order,  cn: input tensor, k: range\n",
    "    cn = tf.cast(cn, tf.float64)\n",
    "    vp = tf.math.pow(cn,m)\n",
    "    vp = tf.reduce_sum(vp, axis = -1)\n",
    "    vp = tf.expand_dims(vp, axis = -1)\n",
    "    vp = tf.tile(vp, Tile_reshape(cn))\n",
    "    return vp\n",
    " \n",
    "def VC1(cn):\n",
    "    vc = tf.reduce_sum(cn, axis = -1)\n",
    "    vc = tf.expand_dims(vc, axis=-1)\n",
    "    vc = tf.tile(vc, Tile_reshape(cn))\n",
    "    vc = tf.cast(vc, tf.float64)\n",
    "    return vc\n",
    "def VC2(cn):\n",
    "    vc = (VC1(cn)**2 - VP(2, cn))/2\n",
    "    return vc\n",
    "def VC3(cn):\n",
    "    vc1 = VC1(cn)\n",
    "    vp2 = VP(2,cn)\n",
    "    vp3 = VP(3,cn)\n",
    "    vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "    return vc\n",
    "def VC4(cn):\n",
    "    n = find_N(cn)\n",
    "#     vc = (VC3(cn)*VP(0,cn) - 3/(n-2)*VC2(cn)*VP(1,cn) + 3/(n-2)*2/(n-1)*VC1(cn)*VP(3,cn) - 3/(n-2)*2/(n-1)*VP(4,cn) )/(n-3)\n",
    "    vc = (VC3(cn)*VP(1,cn) - VC2(cn)*VP(2,cn) + VC1(cn)*VP(3,cn) - VP(4,cn) )/4\n",
    "    return vc\n",
    "\n",
    "## VCN: \n",
    "# vcn = 0\n",
    "# for i in range(N):\n",
    "#     vcn += VC(N-i-1)VP(i+1)*(-1)**i\n",
    "# vcn = vcn/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Con(n,k):\n",
    "    fc=1\n",
    "    for i in range(k):\n",
    "        fc *=(n-i)\n",
    "        fc /= (i+1)\n",
    "    return fc\n",
    "def text(cn):\n",
    "    vc = (VC2(cn)*VP(1, cn) - VC1(cn)*VP(2,cn) + VP(3,cn))/3\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "n = a[-1:].numpy()\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561.5,  561.5,  561.5,  561.5,  561.5],\n",
       "       [   5. ,    5. ,    5. ,    5. ,    5. ],\n",
       "       [3616.5, 3616.5, 3616.5, 3616.5, 3616.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = tf.constant([[1,2,3,4,5],[1,1,1,1,1],[3,4,5,6,7]])\n",
    "# cn = tf.constant([[1,2,3,4],[1,1,1,1],[3,4,5,6]])\n",
    "\n",
    "# cn.numpy()\n",
    "VC4(cn).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "fc=1\n",
    "for i in range(N):\n",
    "    fc*=(i+1)\n",
    "    \n",
    "a = 0\n",
    "for i in range(N):\n",
    "    a += fc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-887b695135f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \"\"\"\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.math.multiply(VC3(cn),VC1(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "b = a*0+1\n",
    "a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(cn, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
