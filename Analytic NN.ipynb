{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.optimize as opt\n",
    "# import sys, os, random, gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras import metrics\n",
    "# from keras.utils import np_utils\n",
    "# import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "# ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(10):\n",
    "for example in ds.take(i):\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "#         x.append(image)\n",
    "#         y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(3):\n",
    "    image, label = example[\"image\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PandasArray>\n",
       "[7129300520, 6414100192, 5631500400, 2487200875, 1954400510, 7237550310,\n",
       " 1321400060, 2008000270, 2414600126, 3793500160,\n",
       " ...\n",
       " 7852140040, 9834201367, 3448900210, 7936000429, 2997800021,  263000018,\n",
       " 6600060120, 1523300141,  291310100, 1523300157]\n",
       "Length: 21613, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"id\"].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_ALIASES',\n",
       " '_AXIS_IALIASES',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_NAMES',\n",
       " '_AXIS_NUMBERS',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_numeric_operations',\n",
       " '_add_series_or_dataframe_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_aggregate',\n",
       " '_aggregate_multiple_funcs',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_box_col_values',\n",
       " '_box_item_values',\n",
       " '_builtin_table',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_combine_frame',\n",
       " '_combine_match_index',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_dict_from',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_create_indexer',\n",
       " '_cython_table',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_from_arrays',\n",
       " '_from_axes',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_cython_func',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_iget_item_cache',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_internal_get_values',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_builtin_func',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_datelike_mixed_type',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_numeric_mixed_type',\n",
       " '_is_view',\n",
       " '_ix',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_needs_reindex_multi',\n",
       " '_obj_with_exclusions',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_selected_obj',\n",
       " '_selection',\n",
       " '_selection_list',\n",
       " '_selection_name',\n",
       " '_series',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_setup_axes',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_try_aggregate_string_function',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " '_xs',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'condition',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'date',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'floordiv',\n",
       " 'floors',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'grade',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'id',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'lat',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'long',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'price',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'sqft_living',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot',\n",
       " 'sqft_lot15',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tshift',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'waterfront',\n",
       " 'where',\n",
       " 'xs',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg = x_rg[:,2]\n",
    "x_rg = x_rg[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 18), (21613,))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape, y_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(tf.keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQV(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(KQV, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "        wk_init = tf.random_normal_initializer()\n",
    "        wv_init = tf.random_normal_initializer()\n",
    "        \n",
    "        self.wq = tf.Variable(initial_value=wq_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wk = tf.Variable(initial_value=wk_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wv = tf.Variable(initial_value=wv_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "\n",
    "        \n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(self.units,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        q = tf.matmul(self.wq,inputs)\n",
    "        k = tf.matmul(self.wk,inputs)\n",
    "        v = tf.matmul(self.wv, inputs)\n",
    "\n",
    "        return k, q, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "#         a = tf.constant(a)\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "#         cn = tf.cast(cn, tf.float64)\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "#         vc = tf.cast(vc, tf.float64)\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "#         out_num = self.order*2\n",
    "#         v = tf.expand_dims(v, axis = -1)\n",
    "#         v = tf.tile(v, self.Tile_reshape(out_num))\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"vc shape:\", vc1.shape)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        print(\"v shape:\", v.shape)\n",
    "#         v = tf.Variable(self.rui(shape = tf.shape(v)), dtype=tf.float32)*v\n",
    "        \n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        q = self.wq(q)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        k = self.wk(v)\n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         print(\"wk\",k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         n = tf.matmul(q,k) ##tooooooooooo slow\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##--------------------------------------------------------------------normalize----------\n",
    "#         k = tf.math.log(tf.math.abs(k+1e-10)+1)\n",
    "#         q = tf.math.log(tf.math.abs(q+1e-10)+1)\n",
    "\n",
    "#         print(\"kdiv\",tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))\n",
    "\n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "#         n = k*q\n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##-----------------------------------------------top k version------------------------------\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "##------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "#         n = k*q\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=1000, num_out=100, rank=2):\n",
    "        super(Data_Selection, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, q, k, v):\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        n = k*q\n",
    "##------------------------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.expand_dims(v, axis=-1)\n",
    "        v = n*v\n",
    "        v = tf.reduce_sum(v, axis=-2)\n",
    "        print(\"v shape:\", v.shape)\n",
    "\n",
    "##-----------------------------------------------------\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(tf.rank(x))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train, axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(np.sum(x_train, axis = -1), axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "\n",
    "x_train = x_train/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (1, 18)\n",
      "vc shape: (1, 18)\n",
      "v shape: (1, 18, 7)\n",
      "wk tf.Tensor(\n",
      "[[[ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]]], shape=(1, 18, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[ 2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19]\n",
      "  [-8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18]\n",
      "  [ 2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19]\n",
      "  [ 3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19]\n",
      "  [-2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19]\n",
      "  [ 2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19]\n",
      "  [-3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[ 1.1536372e+00  8.6522788e-01  8.5080743e+02  1.4420465e+03\n",
      "    5.7681859e-01  0.0000000e+00  8.6522788e-01  8.6522788e-01\n",
      "    2.5956836e+00  5.7105042e+02  2.7975702e+02  5.7076196e+02\n",
      "    0.0000000e+00  2.8300451e+04  1.3720034e+01 -3.5294086e+01\n",
      "    6.1719586e+02  1.1536372e+03]\n",
      "  [-8.5340548e-01 -6.4005411e-01 -6.2938654e+02 -1.0667568e+03\n",
      "   -4.2670274e-01  0.0000000e+00 -6.4005411e-01 -6.4005411e-01\n",
      "   -1.9201623e+00 -4.2243570e+02 -2.0695082e+02 -4.2222235e+02\n",
      "    0.0000000e+00 -2.0935316e+04 -1.0149424e+01  2.6108873e+01\n",
      "   -4.5657193e+02 -8.5340546e+02]\n",
      "  [ 1.4279835e+00  1.0709877e+00  1.0531378e+03  1.7849794e+03\n",
      "    7.1399176e-01  0.0000000e+00  1.0709877e+00  1.0709877e+00\n",
      "    3.2129629e+00  7.0685187e+02  3.4628601e+02  7.0649487e+02\n",
      "    0.0000000e+00  3.5030578e+04  1.6982794e+01 -4.3687370e+01\n",
      "    7.6397119e+02  1.4279835e+03]\n",
      "  [-1.1096001e-02 -8.3220005e-03 -8.1833000e+00 -1.3870001e+01\n",
      "   -5.5480003e-03  0.0000000e+00 -8.3220005e-03 -8.3220005e-03\n",
      "   -2.4966002e-02 -5.4925203e+00 -2.6907802e+00 -5.4897461e+00\n",
      "    0.0000000e+00 -2.7220154e+02 -1.3196307e-01  3.3946827e-01\n",
      "   -5.9363604e+00 -1.1096001e+01]\n",
      "  [-7.7478671e-01 -5.8109003e-01 -5.7140521e+02 -9.6848340e+02\n",
      "   -3.8739336e-01  0.0000000e+00 -5.8109003e-01 -5.8109003e-01\n",
      "   -1.7432702e+00 -3.8351941e+02 -1.8788577e+02 -3.8332571e+02\n",
      "    0.0000000e+00 -1.9006680e+04 -9.2144222e+00  2.3703630e+01\n",
      "   -4.1451089e+02 -7.7478668e+02]\n",
      "  [-8.7473464e-01 -6.5605098e-01 -6.4511682e+02 -1.0934183e+03\n",
      "   -4.3736732e-01  0.0000000e+00 -6.5605098e-01 -6.5605098e-01\n",
      "   -1.9681530e+00 -4.3299365e+02 -2.1212315e+02 -4.3277496e+02\n",
      "    0.0000000e+00 -2.1458553e+04 -1.0403088e+01  2.6761414e+01\n",
      "   -4.6798303e+02 -8.7473462e+02]\n",
      "  [-1.6690795e+00 -1.2518096e+00 -1.2309462e+03 -2.0863494e+03\n",
      "   -8.3453977e-01  0.0000000e+00 -1.2518096e+00 -1.2518096e+00\n",
      "   -3.7554290e+00 -8.2619440e+02 -4.0475180e+02 -8.2577710e+02\n",
      "    0.0000000e+00 -4.0945023e+04 -1.9850113e+01  5.1063404e+01\n",
      "   -8.9295758e+02 -1.6690796e+03]]], shape=(1, 7, 18), dtype=float32)\n",
      "kdiv tf.Tensor([[35989.742 34145.016 35813.79  36438.703 35999.33  35913.438 36220.984]], shape=(1, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[3.6966380e-02 3.0038426e-02 3.2512918e-01 3.5053056e-01 2.1944409e-02\n",
      "   0.0000000e+00 3.0038426e-02 3.0038426e-02 6.1665431e-02 3.0594465e-01\n",
      "   2.7164879e-01 3.0592036e-01 0.0000000e+00 4.9394003e-01 1.2958258e-01\n",
      "   1.7306793e-01 3.0968288e-01 3.3978647e-01]\n",
      "  [3.1124566e-02 2.4955617e-02 3.2517225e-01 3.5175481e-01 1.7925721e-02\n",
      "   0.0000000e+00 2.4955617e-02 2.4955617e-02 5.4056674e-02 3.0509943e-01\n",
      "   2.6922941e-01 3.0507401e-01 0.0000000e+00 5.0186938e-01 1.2163760e-01\n",
      "   1.6645484e-01 3.0901039e-01 3.4051058e-01]\n",
      "  [4.1416258e-02 3.3991005e-02 3.2497981e-01 3.4959647e-01 2.5157360e-02\n",
      "   0.0000000e+00 3.3991005e-02 3.3991005e-02 6.7146964e-02 3.0638611e-01\n",
      "   2.7313933e-01 3.0636257e-01 0.0000000e+00 4.8855704e-01 1.3490477e-01\n",
      "   1.7740490e-01 3.1000936e-01 3.3918458e-01]\n",
      "  [1.3964046e-03 1.0487455e-03 2.8059804e-01 3.4158731e-01 7.0012844e-04\n",
      "   0.0000000e+00 1.0487455e-03 1.0487455e-03 3.1205164e-03 2.3672052e-01\n",
      "   1.6524658e-01 2.3666644e-01 0.0000000e+00 7.0994109e-01 1.5685607e-02\n",
      "   3.6985498e-02 2.4508846e-01 3.1545955e-01]\n",
      "  [2.9375188e-02 2.3457661e-02 3.2514268e-01 3.5212332e-01 1.6765820e-02\n",
      "   0.0000000e+00 2.3457661e-02 2.3457661e-02 5.1673368e-02 3.0477071e-01\n",
      "   2.6837167e-01 3.0474490e-01 0.0000000e+00 5.0450039e-01 1.1898976e-01\n",
      "   1.6421126e-01 3.0873981e-01 3.4071052e-01]\n",
      "  [3.1581409e-02 2.5348648e-02 3.2517639e-01 3.5165882e-01 1.8231904e-02\n",
      "   0.0000000e+00 2.5348648e-02 2.5348648e-02 5.4670598e-02 3.0517879e-01\n",
      "   2.6944196e-01 3.0515346e-01 0.0000000e+00 5.0120461e-01 1.2230630e-01\n",
      "   1.6701820e-01 3.0907512e-01 3.4045699e-01]\n",
      "  [4.4809200e-02 3.7049923e-02 3.2481110e-01 3.4887856e-01 2.7695838e-02\n",
      "   0.0000000e+00 3.7049923e-02 3.7049923e-02 7.1170427e-02 3.0663100e-01\n",
      "   2.7411965e-01 3.0660796e-01 0.0000000e+00 4.8472837e-01 1.3863398e-01\n",
      "   1.8040195e-01 3.1017375e-01 3.3869913e-01]]], shape=(1, 7, 18), dtype=float32)\n",
      "v shape: (1, 18, 7)\n",
      "n shape: (1, 18, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
       " array([[9.7922925e+17, 8.0966167e+17, 7.1021882e+18, 7.6290285e+18,\n",
       "         6.0524301e+17, 0.0000000e+00, 8.0966167e+17, 8.0966167e+17,\n",
       "         1.5553235e+18, 6.7042557e+18, 5.9927380e+18, 6.7037515e+18,\n",
       "         0.0000000e+00, 1.0603152e+19, 3.0297832e+18, 3.9428487e+18,\n",
       "         6.7817976e+18, 7.4061943e+18]], dtype=float32)>,\n",
       " array([[ 4.00000e+00,  3.00000e+00,  2.95000e+03,  5.00000e+03,\n",
       "          2.00000e+00,  0.00000e+00,  3.00000e+00,  3.00000e+00,\n",
       "          9.00000e+00,  1.98000e+03,  9.70000e+02,  1.97900e+03,\n",
       "          0.00000e+00,  9.81260e+04,  4.75714e+01, -1.22375e+02,\n",
       "          2.14000e+03,  4.00000e+03]], dtype=float32))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_rg[15:16]\n",
    "Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x,x,x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n"
     ]
    }
   ],
   "source": [
    "## tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(18))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.math.is_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(x_rg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_116 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_48 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_117 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_49 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = np.array(x_rg)\n",
    "y_rg = np.array(y_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = x_rg.astype(np.float32)\n",
    "y_rg = y_rg.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 4.0819e-04 - accuracy: 3.7258e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 4.1865e-04 - accuracy: 4.1642e-04\n",
      "Epoch 2/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 4.1447e-04 - accuracy: 4.1915e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 4.1344e-04 - accuracy: 4.1642e-04\n",
      "Epoch 3/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 4.0816e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 4.0741e-04 - accuracy: 4.6268e-04\n",
      "Epoch 4/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 3.9885e-04 - accuracy: 4.6503e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.9795e-04 - accuracy: 4.6268e-04\n",
      "Epoch 5/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 4.0092e-04 - accuracy: 4.6296e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 4.0073e-04 - accuracy: 4.6268e-04\n",
      "Epoch 6/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 3.7856e-04 - accuracy: 4.6268e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.7856e-04 - accuracy: 4.6268e-04\n",
      "Epoch 7/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 3.7168e-04 - accuracy: 4.6268e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 3.7168e-04 - accuracy: 4.6268e-04\n",
      "Epoch 8/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 3.7647e-04 - accuracy: 4.6365e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.7603e-04 - accuracy: 4.6268e-04\n",
      "Epoch 9/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 3.4915e-04 - accuracy: 4.6296e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.4902e-04 - accuracy: 4.6268e-04\n",
      "Epoch 10/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 3.4561e-04 - accuracy: 4.6503e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.4581e-04 - accuracy: 4.6268e-04\n",
      "Epoch 11/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 3.2776e-04 - accuracy: 4.6268e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.2776e-04 - accuracy: 4.6268e-04\n",
      "Epoch 12/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 3.2493e-04 - accuracy: 4.6365e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.2475e-04 - accuracy: 4.6268e-04\n",
      "Epoch 13/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 3.1181e-04 - accuracy: 4.6365e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.1155e-04 - accuracy: 4.6268e-04\n",
      "Epoch 14/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 3.2001e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.1871e-04 - accuracy: 4.6268e-04\n",
      "Epoch 15/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 3.0803e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.0716e-04 - accuracy: 4.6268e-04\n",
      "Epoch 16/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 2.8799e-04 - accuracy: 4.6503e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.8767e-04 - accuracy: 4.6268e-04\n",
      "Epoch 17/20\n",
      "673/676 [============================>.] - ETA: 0s - loss: 2.9504e-04 - accuracy: 4.6434e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.9461e-04 - accuracy: 4.6268e-04\n",
      "Epoch 18/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 2.8501e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.8401e-04 - accuracy: 4.6268e-04\n",
      "Epoch 19/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 2.6937e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.6829e-04 - accuracy: 4.6268e-04\n",
      "Epoch 20/20\n",
      "670/676 [============================>.] - ETA: 0s - loss: 2.7700e-04 - accuracy: 4.6642e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.7596e-04 - accuracy: 4.6268e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff27f8459e8>"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), callbacks = callbacks, shuffle=True , epochs=20, batch_size=32, verbose=1)\n",
    "# modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = modelANN.predict(np.log(np.abs(x_rg)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5294644 ],\n",
       "       [0.46715382],\n",
       "       [0.5347007 ],\n",
       "       ...,\n",
       "       [0.5334146 ],\n",
       "       [0.5299744 ],\n",
       "       [0.5346126 ]], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "# plt.hist(y_pre, histtype='step')\n",
    "# plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "plt.xlabel(\"Model Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.scatter(y_pre,np.log(np.abs(y_rg)+1))\n",
    "# plt.xlim([0,2.5])\n",
    "plt.savefig(\"./plot/Regression_Scatter.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\", bins = 50)\n",
    "plt.hist(np.log(np.abs(y_rg)+1), histtype='step',  label = \"target\", bins = 50)\n",
    "plt.legend()\n",
    "plt.savefig(\"./plot/Regression_Hist.png\")\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28)\n",
      "(None, 784)\n",
      "n shape: (None, 784, 100)\n",
      "v shape: (None, 100)\n",
      "(None, 100)\n",
      "v shape: (None, 100, 7)\n",
      "n shape: (None, 100, 7)\n",
      "(None, 100)\n",
      "(None, 100)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = inputs\n",
    "# x = tf.cast(x, tf.float64)\n",
    "print(x.shape)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "x = Data_Selection(node = 100, num_out=20,rank=tf.rank(x))(x,x,x)\n",
    "print(x.shape)\n",
    "\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# c = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# c = tf.squeeze(c, axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "# print(x.shape)\n",
    "# a = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([x,b], axis=-1)\n",
    "# c = tf.concat([x,c], axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# c = Operator_Basis(num_out=1,rank=tf.rank(c))(c, c, c)\n",
    "# print(\"a:\",a.shape)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "\n",
    "# x = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([b,c], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(b))(b, b, b)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "print(x.shape)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "data__selection_16 (Data_Sel (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_45 (Sym (None, 100)               70        \n",
      "_________________________________________________________________\n",
      "operator__basis_30 (Operator (None, 100)               30        \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,510\n",
      "Trainable params: 1,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [ for i in y_train]\n",
    "y2 = []\n",
    "for i in y_train:\n",
    "    vec = np.zeros([10])    \n",
    "    vec[i]=1\n",
    "    y2.append(vec)\n",
    "y2=np.array(y2)    \n",
    "y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1954 - accuracy: 0.2388\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1695 - accuracy: 0.2695\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1632 - accuracy: 0.2755\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 53s 29ms/step - loss: 2.1611 - accuracy: 0.2781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4141d8550>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# modelANN.fit(x_train, y2 , callbacks = callbacks, shuffle=True , epochs=400, batch_size=32, verbose=1)\n",
    "modelANN.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Block\n",
    "class Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(Selection, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "#         self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540412\n",
      "0.9305041\n",
      "0.90742856\n",
      "0.8848088\n",
      "0.862639\n",
      "0.8409134\n",
      "0.8196262\n",
      "0.79877156\n",
      "0.7783437\n",
      "0.7583367\n",
      "0.73874485\n",
      "0.7195623\n",
      "0.70078325\n",
      "0.68240196\n",
      "0.66441256\n",
      "0.64680934\n",
      "0.6295866\n",
      "0.6127385\n",
      "0.59625936\n",
      "0.5801435\n",
      "0.5643853\n",
      "0.54897904\n",
      "0.5339191\n",
      "0.5191999\n",
      "0.50481594\n",
      "0.4907616\n",
      "0.47703144\n",
      "0.46361995\n",
      "0.4505217\n",
      "0.43773136\n",
      "0.4252435\n",
      "0.41305286\n",
      "0.40115413\n",
      "0.3895421\n",
      "0.3782116\n",
      "0.36715743\n",
      "0.35637453\n",
      "0.34585783\n",
      "0.33560234\n",
      "0.3256031\n",
      "0.3158552\n",
      "0.30635378\n",
      "0.29709405\n",
      "0.28807122\n",
      "0.2792806\n",
      "0.2707176\n",
      "0.26237753\n",
      "0.25425592\n",
      "0.24634825\n",
      "0.23865008\n",
      "0.23115706\n",
      "0.22386485\n",
      "0.21676919\n",
      "0.20986587\n",
      "0.20315073\n",
      "0.1966197\n",
      "0.19026873\n",
      "0.18409383\n",
      "0.1780911\n",
      "0.17225665\n",
      "0.16658668\n",
      "0.16107745\n",
      "0.15572527\n",
      "0.1505265\n",
      "0.14547755\n",
      "0.14057492\n",
      "0.13581514\n",
      "0.13119482\n",
      "0.12671058\n",
      "0.12235916\n",
      "0.11813731\n",
      "0.11404186\n",
      "0.11006968\n",
      "0.10621771\n",
      "0.102482945\n",
      "0.09886242\n"
     ]
    }
   ],
   "source": [
    "while var1.numpy()>0.1:\n",
    "    opt.minimize(loss, [var1]).numpy()\n",
    "    print(var1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,1],[2,2],[3,3]])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [4, 4],\n",
       "       [9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry Variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: m<=n\n",
    "def find_N(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    n = a[-1:].numpy()\n",
    "    n = n[0]\n",
    "    return n\n",
    "\n",
    "def Tile_reshape(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    b = a*0+1\n",
    "    a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "    return a\n",
    "def VP(m, cn): # m: order,  cn: input tensor, k: range\n",
    "    cn = tf.cast(cn, tf.float64)\n",
    "    vp = tf.math.pow(cn,m)\n",
    "    vp = tf.reduce_sum(vp, axis = -1)\n",
    "    vp = tf.expand_dims(vp, axis = -1)\n",
    "    vp = tf.tile(vp, Tile_reshape(cn))\n",
    "    return vp\n",
    " \n",
    "def VC1(cn):\n",
    "    vc = tf.reduce_sum(cn, axis = -1)\n",
    "    vc = tf.expand_dims(vc, axis=-1)\n",
    "    vc = tf.tile(vc, Tile_reshape(cn))\n",
    "    vc = tf.cast(vc, tf.float64)\n",
    "    return vc\n",
    "def VC2(cn):\n",
    "    vc = (VC1(cn)**2 - VP(2, cn))/2\n",
    "    return vc\n",
    "def VC3(cn):\n",
    "    vc1 = VC1(cn)\n",
    "    vp2 = VP(2,cn)\n",
    "    vp3 = VP(3,cn)\n",
    "    vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "    return vc\n",
    "def VC4(cn):\n",
    "    n = find_N(cn)\n",
    "#     vc = (VC3(cn)*VP(0,cn) - 3/(n-2)*VC2(cn)*VP(1,cn) + 3/(n-2)*2/(n-1)*VC1(cn)*VP(3,cn) - 3/(n-2)*2/(n-1)*VP(4,cn) )/(n-3)\n",
    "    vc = (VC3(cn)*VP(1,cn) - VC2(cn)*VP(2,cn) + VC1(cn)*VP(3,cn) - VP(4,cn) )/4\n",
    "    return vc\n",
    "\n",
    "## VCN: \n",
    "# vcn = 0\n",
    "# for i in range(N):\n",
    "#     vcn += VC(N-i-1)VP(i+1)*(-1)**i\n",
    "# vcn = vcn/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Con(n,k):\n",
    "    fc=1\n",
    "    for i in range(k):\n",
    "        fc *=(n-i)\n",
    "        fc /= (i+1)\n",
    "    return fc\n",
    "def text(cn):\n",
    "    vc = (VC2(cn)*VP(1, cn) - VC1(cn)*VP(2,cn) + VP(3,cn))/3\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "n = a[-1:].numpy()\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561.5,  561.5,  561.5,  561.5,  561.5],\n",
       "       [   5. ,    5. ,    5. ,    5. ,    5. ],\n",
       "       [3616.5, 3616.5, 3616.5, 3616.5, 3616.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = tf.constant([[1,2,3,4,5],[1,1,1,1,1],[3,4,5,6,7]])\n",
    "# cn = tf.constant([[1,2,3,4],[1,1,1,1],[3,4,5,6]])\n",
    "\n",
    "# cn.numpy()\n",
    "VC4(cn).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "fc=1\n",
    "for i in range(N):\n",
    "    fc*=(i+1)\n",
    "    \n",
    "a = 0\n",
    "for i in range(N):\n",
    "    a += fc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-887b695135f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \"\"\"\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.math.multiply(VC3(cn),VC1(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "b = a*0+1\n",
    "a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(cn, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
