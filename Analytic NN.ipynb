{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.optimize as opt\n",
    "# import sys, os, random, gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras import metrics\n",
    "# from keras.utils import np_utils\n",
    "# import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "# ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(10):\n",
    "for example in ds.take(i):\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "#         x.append(image)\n",
    "#         y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(3):\n",
    "    image, label = example[\"image\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PandasArray>\n",
       "[7129300520, 6414100192, 5631500400, 2487200875, 1954400510, 7237550310,\n",
       " 1321400060, 2008000270, 2414600126, 3793500160,\n",
       " ...\n",
       " 7852140040, 9834201367, 3448900210, 7936000429, 2997800021,  263000018,\n",
       " 6600060120, 1523300141,  291310100, 1523300157]\n",
       "Length: 21613, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"id\"].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_ALIASES',\n",
       " '_AXIS_IALIASES',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_NAMES',\n",
       " '_AXIS_NUMBERS',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_numeric_operations',\n",
       " '_add_series_or_dataframe_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_aggregate',\n",
       " '_aggregate_multiple_funcs',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_box_col_values',\n",
       " '_box_item_values',\n",
       " '_builtin_table',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_combine_frame',\n",
       " '_combine_match_index',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_dict_from',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_create_indexer',\n",
       " '_cython_table',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_from_arrays',\n",
       " '_from_axes',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_cython_func',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_iget_item_cache',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_internal_get_values',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_builtin_func',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_datelike_mixed_type',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_numeric_mixed_type',\n",
       " '_is_view',\n",
       " '_ix',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_needs_reindex_multi',\n",
       " '_obj_with_exclusions',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_selected_obj',\n",
       " '_selection',\n",
       " '_selection_list',\n",
       " '_selection_name',\n",
       " '_series',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_setup_axes',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_try_aggregate_string_function',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " '_xs',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'condition',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'date',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'floordiv',\n",
       " 'floors',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'grade',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'id',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'lat',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'long',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'price',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'sqft_living',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot',\n",
       " 'sqft_lot15',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tshift',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'waterfront',\n",
       " 'where',\n",
       " 'xs',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg = x_rg[:,2]\n",
    "x_rg = x_rg[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 18), (21613,))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape, y_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(tf.keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQV(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(KQV, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "        wk_init = tf.random_normal_initializer()\n",
    "        wv_init = tf.random_normal_initializer()\n",
    "        \n",
    "        self.wq = tf.Variable(initial_value=wq_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wk = tf.Variable(initial_value=wk_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wv = tf.Variable(initial_value=wv_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "\n",
    "        \n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(self.units,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        q = tf.matmul(self.wq,inputs)\n",
    "        k = tf.matmul(self.wk,inputs)\n",
    "        v = tf.matmul(self.wv, inputs)\n",
    "\n",
    "        return k, q, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "#         a = tf.constant(a)\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "#         cn = tf.cast(cn, tf.float64)\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "#         vc = tf.cast(vc, tf.float64)\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "#         out_num = self.order*2\n",
    "#         v = tf.expand_dims(v, axis = -1)\n",
    "#         v = tf.tile(v, self.Tile_reshape(out_num))\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"vc shape:\", vc1.shape)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        print(\"v shape:\", v.shape)\n",
    "#         v = tf.Variable(self.rui(shape = tf.shape(v)), dtype=tf.float32)*v\n",
    "        \n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        q = self.wq(q)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        k = self.wk(v)\n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         print(\"wk\",k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         n = tf.matmul(q,k) ##tooooooooooo slow\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##--------------------------------------------------------------------normalize----------\n",
    "#         k = tf.math.log(tf.math.abs(k+1e-10)+1)\n",
    "#         q = tf.math.log(tf.math.abs(q+1e-10)+1)\n",
    "\n",
    "#         print(\"kdiv\",tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))\n",
    "\n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "#         n = k*q\n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##-----------------------------------------------top k version------------------------------\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "##------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "#         n = k*q\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=1000, num_out=100, rank=2):\n",
    "        super(Data_Selection, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, q, k, v):\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        n = k*q\n",
    "##------------------------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.expand_dims(v, axis=-1)\n",
    "        v = n*v\n",
    "        v = tf.reduce_sum(v, axis=-2)\n",
    "        print(\"v shape:\", v.shape)\n",
    "\n",
    "##-----------------------------------------------------\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(tf.rank(x))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train, axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(np.sum(x_train, axis = -1), axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "\n",
    "x_train = x_train/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (1, 18)\n",
      "vc shape: (1, 18)\n",
      "v shape: (1, 18, 7)\n",
      "wk tf.Tensor(\n",
      "[[[ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]]], shape=(1, 18, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[ 2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19]\n",
      "  [-8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18]\n",
      "  [ 2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19]\n",
      "  [ 3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19]\n",
      "  [-2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19]\n",
      "  [ 2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19]\n",
      "  [-3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[ 1.1536372e+00  8.6522788e-01  8.5080743e+02  1.4420465e+03\n",
      "    5.7681859e-01  0.0000000e+00  8.6522788e-01  8.6522788e-01\n",
      "    2.5956836e+00  5.7105042e+02  2.7975702e+02  5.7076196e+02\n",
      "    0.0000000e+00  2.8300451e+04  1.3720034e+01 -3.5294086e+01\n",
      "    6.1719586e+02  1.1536372e+03]\n",
      "  [-8.5340548e-01 -6.4005411e-01 -6.2938654e+02 -1.0667568e+03\n",
      "   -4.2670274e-01  0.0000000e+00 -6.4005411e-01 -6.4005411e-01\n",
      "   -1.9201623e+00 -4.2243570e+02 -2.0695082e+02 -4.2222235e+02\n",
      "    0.0000000e+00 -2.0935316e+04 -1.0149424e+01  2.6108873e+01\n",
      "   -4.5657193e+02 -8.5340546e+02]\n",
      "  [ 1.4279835e+00  1.0709877e+00  1.0531378e+03  1.7849794e+03\n",
      "    7.1399176e-01  0.0000000e+00  1.0709877e+00  1.0709877e+00\n",
      "    3.2129629e+00  7.0685187e+02  3.4628601e+02  7.0649487e+02\n",
      "    0.0000000e+00  3.5030578e+04  1.6982794e+01 -4.3687370e+01\n",
      "    7.6397119e+02  1.4279835e+03]\n",
      "  [-1.1096001e-02 -8.3220005e-03 -8.1833000e+00 -1.3870001e+01\n",
      "   -5.5480003e-03  0.0000000e+00 -8.3220005e-03 -8.3220005e-03\n",
      "   -2.4966002e-02 -5.4925203e+00 -2.6907802e+00 -5.4897461e+00\n",
      "    0.0000000e+00 -2.7220154e+02 -1.3196307e-01  3.3946827e-01\n",
      "   -5.9363604e+00 -1.1096001e+01]\n",
      "  [-7.7478671e-01 -5.8109003e-01 -5.7140521e+02 -9.6848340e+02\n",
      "   -3.8739336e-01  0.0000000e+00 -5.8109003e-01 -5.8109003e-01\n",
      "   -1.7432702e+00 -3.8351941e+02 -1.8788577e+02 -3.8332571e+02\n",
      "    0.0000000e+00 -1.9006680e+04 -9.2144222e+00  2.3703630e+01\n",
      "   -4.1451089e+02 -7.7478668e+02]\n",
      "  [-8.7473464e-01 -6.5605098e-01 -6.4511682e+02 -1.0934183e+03\n",
      "   -4.3736732e-01  0.0000000e+00 -6.5605098e-01 -6.5605098e-01\n",
      "   -1.9681530e+00 -4.3299365e+02 -2.1212315e+02 -4.3277496e+02\n",
      "    0.0000000e+00 -2.1458553e+04 -1.0403088e+01  2.6761414e+01\n",
      "   -4.6798303e+02 -8.7473462e+02]\n",
      "  [-1.6690795e+00 -1.2518096e+00 -1.2309462e+03 -2.0863494e+03\n",
      "   -8.3453977e-01  0.0000000e+00 -1.2518096e+00 -1.2518096e+00\n",
      "   -3.7554290e+00 -8.2619440e+02 -4.0475180e+02 -8.2577710e+02\n",
      "    0.0000000e+00 -4.0945023e+04 -1.9850113e+01  5.1063404e+01\n",
      "   -8.9295758e+02 -1.6690796e+03]]], shape=(1, 7, 18), dtype=float32)\n",
      "kdiv tf.Tensor([[35989.742 34145.016 35813.79  36438.703 35999.33  35913.438 36220.984]], shape=(1, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[3.6966380e-02 3.0038426e-02 3.2512918e-01 3.5053056e-01 2.1944409e-02\n",
      "   0.0000000e+00 3.0038426e-02 3.0038426e-02 6.1665431e-02 3.0594465e-01\n",
      "   2.7164879e-01 3.0592036e-01 0.0000000e+00 4.9394003e-01 1.2958258e-01\n",
      "   1.7306793e-01 3.0968288e-01 3.3978647e-01]\n",
      "  [3.1124566e-02 2.4955617e-02 3.2517225e-01 3.5175481e-01 1.7925721e-02\n",
      "   0.0000000e+00 2.4955617e-02 2.4955617e-02 5.4056674e-02 3.0509943e-01\n",
      "   2.6922941e-01 3.0507401e-01 0.0000000e+00 5.0186938e-01 1.2163760e-01\n",
      "   1.6645484e-01 3.0901039e-01 3.4051058e-01]\n",
      "  [4.1416258e-02 3.3991005e-02 3.2497981e-01 3.4959647e-01 2.5157360e-02\n",
      "   0.0000000e+00 3.3991005e-02 3.3991005e-02 6.7146964e-02 3.0638611e-01\n",
      "   2.7313933e-01 3.0636257e-01 0.0000000e+00 4.8855704e-01 1.3490477e-01\n",
      "   1.7740490e-01 3.1000936e-01 3.3918458e-01]\n",
      "  [1.3964046e-03 1.0487455e-03 2.8059804e-01 3.4158731e-01 7.0012844e-04\n",
      "   0.0000000e+00 1.0487455e-03 1.0487455e-03 3.1205164e-03 2.3672052e-01\n",
      "   1.6524658e-01 2.3666644e-01 0.0000000e+00 7.0994109e-01 1.5685607e-02\n",
      "   3.6985498e-02 2.4508846e-01 3.1545955e-01]\n",
      "  [2.9375188e-02 2.3457661e-02 3.2514268e-01 3.5212332e-01 1.6765820e-02\n",
      "   0.0000000e+00 2.3457661e-02 2.3457661e-02 5.1673368e-02 3.0477071e-01\n",
      "   2.6837167e-01 3.0474490e-01 0.0000000e+00 5.0450039e-01 1.1898976e-01\n",
      "   1.6421126e-01 3.0873981e-01 3.4071052e-01]\n",
      "  [3.1581409e-02 2.5348648e-02 3.2517639e-01 3.5165882e-01 1.8231904e-02\n",
      "   0.0000000e+00 2.5348648e-02 2.5348648e-02 5.4670598e-02 3.0517879e-01\n",
      "   2.6944196e-01 3.0515346e-01 0.0000000e+00 5.0120461e-01 1.2230630e-01\n",
      "   1.6701820e-01 3.0907512e-01 3.4045699e-01]\n",
      "  [4.4809200e-02 3.7049923e-02 3.2481110e-01 3.4887856e-01 2.7695838e-02\n",
      "   0.0000000e+00 3.7049923e-02 3.7049923e-02 7.1170427e-02 3.0663100e-01\n",
      "   2.7411965e-01 3.0660796e-01 0.0000000e+00 4.8472837e-01 1.3863398e-01\n",
      "   1.8040195e-01 3.1017375e-01 3.3869913e-01]]], shape=(1, 7, 18), dtype=float32)\n",
      "v shape: (1, 18, 7)\n",
      "n shape: (1, 18, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
       " array([[9.7922925e+17, 8.0966167e+17, 7.1021882e+18, 7.6290285e+18,\n",
       "         6.0524301e+17, 0.0000000e+00, 8.0966167e+17, 8.0966167e+17,\n",
       "         1.5553235e+18, 6.7042557e+18, 5.9927380e+18, 6.7037515e+18,\n",
       "         0.0000000e+00, 1.0603152e+19, 3.0297832e+18, 3.9428487e+18,\n",
       "         6.7817976e+18, 7.4061943e+18]], dtype=float32)>,\n",
       " array([[ 4.00000e+00,  3.00000e+00,  2.95000e+03,  5.00000e+03,\n",
       "          2.00000e+00,  0.00000e+00,  3.00000e+00,  3.00000e+00,\n",
       "          9.00000e+00,  1.98000e+03,  9.70000e+02,  1.97900e+03,\n",
       "          0.00000e+00,  9.81260e+04,  4.75714e+01, -1.22375e+02,\n",
       "          2.14000e+03,  4.00000e+03]], dtype=float32))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_rg[15:16]\n",
    "Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x,x,x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n"
     ]
    }
   ],
   "source": [
    "## tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(18))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.math.is_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(x_rg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_116 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_48 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_117 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_49 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = np.array(x_rg)\n",
    "y_rg = np.array(y_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = x_rg.astype(np.float32)\n",
    "y_rg = y_rg.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 4.0819e-04 - accuracy: 3.7258e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 4.1865e-04 - accuracy: 4.1642e-04\n",
      "Epoch 2/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 4.1447e-04 - accuracy: 4.1915e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 4.1344e-04 - accuracy: 4.1642e-04\n",
      "Epoch 3/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 4.0816e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 4.0741e-04 - accuracy: 4.6268e-04\n",
      "Epoch 4/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 3.9885e-04 - accuracy: 4.6503e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.9795e-04 - accuracy: 4.6268e-04\n",
      "Epoch 5/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 4.0092e-04 - accuracy: 4.6296e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 4.0073e-04 - accuracy: 4.6268e-04\n",
      "Epoch 6/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 3.7856e-04 - accuracy: 4.6268e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.7856e-04 - accuracy: 4.6268e-04\n",
      "Epoch 7/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 3.7168e-04 - accuracy: 4.6268e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 3.7168e-04 - accuracy: 4.6268e-04\n",
      "Epoch 8/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 3.7647e-04 - accuracy: 4.6365e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.7603e-04 - accuracy: 4.6268e-04\n",
      "Epoch 9/20\n",
      "675/676 [============================>.] - ETA: 0s - loss: 3.4915e-04 - accuracy: 4.6296e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.4902e-04 - accuracy: 4.6268e-04\n",
      "Epoch 10/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 3.4561e-04 - accuracy: 4.6503e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.4581e-04 - accuracy: 4.6268e-04\n",
      "Epoch 11/20\n",
      "676/676 [==============================] - ETA: 0s - loss: 3.2776e-04 - accuracy: 4.6268e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.2776e-04 - accuracy: 4.6268e-04\n",
      "Epoch 12/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 3.2493e-04 - accuracy: 4.6365e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.2475e-04 - accuracy: 4.6268e-04\n",
      "Epoch 13/20\n",
      "674/676 [============================>.] - ETA: 0s - loss: 3.1181e-04 - accuracy: 4.6365e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.1155e-04 - accuracy: 4.6268e-04\n",
      "Epoch 14/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 3.2001e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.1871e-04 - accuracy: 4.6268e-04\n",
      "Epoch 15/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 3.0803e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 3.0716e-04 - accuracy: 4.6268e-04\n",
      "Epoch 16/20\n",
      "672/676 [============================>.] - ETA: 0s - loss: 2.8799e-04 - accuracy: 4.6503e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.8767e-04 - accuracy: 4.6268e-04\n",
      "Epoch 17/20\n",
      "673/676 [============================>.] - ETA: 0s - loss: 2.9504e-04 - accuracy: 4.6434e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.9461e-04 - accuracy: 4.6268e-04\n",
      "Epoch 18/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 2.8501e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.8401e-04 - accuracy: 4.6268e-04\n",
      "Epoch 19/20\n",
      "671/676 [============================>.] - ETA: 0s - loss: 2.6937e-04 - accuracy: 4.6572e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.6829e-04 - accuracy: 4.6268e-04\n",
      "Epoch 20/20\n",
      "670/676 [============================>.] - ETA: 0s - loss: 2.7700e-04 - accuracy: 4.6642e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 2.7596e-04 - accuracy: 4.6268e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff27f8459e8>"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), callbacks = callbacks, shuffle=True , epochs=20, batch_size=32, verbose=1)\n",
    "# modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = modelANN.predict(np.log(np.abs(x_rg)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5294644 ],\n",
       "       [0.46715382],\n",
       "       [0.5347007 ],\n",
       "       ...,\n",
       "       [0.5334146 ],\n",
       "       [0.5299744 ],\n",
       "       [0.5346126 ]], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "# plt.hist(y_pre, histtype='step')\n",
    "# plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "plt.xlabel(\"Model Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.scatter(y_pre,np.log(np.abs(y_rg)+1))\n",
    "plt.plot([0,2.5],[0,2], color = 'k', linestyle='--')\n",
    "# plt.xlim([0,2.5])\n",
    "# plt.savefig(\"./plot/Regrssion_Scatter.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\", bins = 50)\n",
    "plt.hist(np.log(np.abs(y_rg)+1), histtype='step',  label = \"target\", bins = 50)\n",
    "plt.legend()\n",
    "plt.savefig(\"./plot/Regression_Hist.png\")\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff2a00b8518>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff282ec5128>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff282e8d668>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff282daf898>, because it is not built.\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./pre_train_models/ANN/assets\n"
     ]
    }
   ],
   "source": [
    "modelANN.save(\"./pre_train_models/ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28)\n",
      "(None, 784)\n",
      "n shape: (None, 784, 100)\n",
      "v shape: (None, 100)\n",
      "(None, 100)\n",
      "v shape: (None, 100, 7)\n",
      "n shape: (None, 100, 7)\n",
      "(None, 100)\n",
      "(None, 100)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = inputs\n",
    "# x = tf.cast(x, tf.float64)\n",
    "print(x.shape)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "x = Data_Selection(node = 100, num_out=20,rank=tf.rank(x))(x,x,x)\n",
    "print(x.shape)\n",
    "\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# c = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# c = tf.squeeze(c, axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "# print(x.shape)\n",
    "# a = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([x,b], axis=-1)\n",
    "# c = tf.concat([x,c], axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# c = Operator_Basis(num_out=1,rank=tf.rank(c))(c, c, c)\n",
    "# print(\"a:\",a.shape)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "\n",
    "# x = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([b,c], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(b))(b, b, b)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "print(x.shape)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "data__selection_16 (Data_Sel (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_45 (Sym (None, 100)               70        \n",
      "_________________________________________________________________\n",
      "operator__basis_30 (Operator (None, 100)               30        \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,510\n",
      "Trainable params: 1,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [ for i in y_train]\n",
    "y2 = []\n",
    "for i in y_train:\n",
    "    vec = np.zeros([10])    \n",
    "    vec[i]=1\n",
    "    y2.append(vec)\n",
    "y2=np.array(y2)    \n",
    "y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1954 - accuracy: 0.2388\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1695 - accuracy: 0.2695\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1632 - accuracy: 0.2755\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 53s 29ms/step - loss: 2.1611 - accuracy: 0.2781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4141d8550>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# modelANN.fit(x_train, y2 , callbacks = callbacks, shuffle=True , epochs=400, batch_size=32, verbose=1)\n",
    "modelANN.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Block\n",
    "class Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(Selection, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "#         self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540412\n",
      "0.9305041\n",
      "0.90742856\n",
      "0.8848088\n",
      "0.862639\n",
      "0.8409134\n",
      "0.8196262\n",
      "0.79877156\n",
      "0.7783437\n",
      "0.7583367\n",
      "0.73874485\n",
      "0.7195623\n",
      "0.70078325\n",
      "0.68240196\n",
      "0.66441256\n",
      "0.64680934\n",
      "0.6295866\n",
      "0.6127385\n",
      "0.59625936\n",
      "0.5801435\n",
      "0.5643853\n",
      "0.54897904\n",
      "0.5339191\n",
      "0.5191999\n",
      "0.50481594\n",
      "0.4907616\n",
      "0.47703144\n",
      "0.46361995\n",
      "0.4505217\n",
      "0.43773136\n",
      "0.4252435\n",
      "0.41305286\n",
      "0.40115413\n",
      "0.3895421\n",
      "0.3782116\n",
      "0.36715743\n",
      "0.35637453\n",
      "0.34585783\n",
      "0.33560234\n",
      "0.3256031\n",
      "0.3158552\n",
      "0.30635378\n",
      "0.29709405\n",
      "0.28807122\n",
      "0.2792806\n",
      "0.2707176\n",
      "0.26237753\n",
      "0.25425592\n",
      "0.24634825\n",
      "0.23865008\n",
      "0.23115706\n",
      "0.22386485\n",
      "0.21676919\n",
      "0.20986587\n",
      "0.20315073\n",
      "0.1966197\n",
      "0.19026873\n",
      "0.18409383\n",
      "0.1780911\n",
      "0.17225665\n",
      "0.16658668\n",
      "0.16107745\n",
      "0.15572527\n",
      "0.1505265\n",
      "0.14547755\n",
      "0.14057492\n",
      "0.13581514\n",
      "0.13119482\n",
      "0.12671058\n",
      "0.12235916\n",
      "0.11813731\n",
      "0.11404186\n",
      "0.11006968\n",
      "0.10621771\n",
      "0.102482945\n",
      "0.09886242\n"
     ]
    }
   ],
   "source": [
    "while var1.numpy()>0.1:\n",
    "    opt.minimize(loss, [var1]).numpy()\n",
    "    print(var1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,1],[2,2],[3,3]])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [4, 4],\n",
       "       [9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry Variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: m<=n\n",
    "def find_N(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    n = a[-1:].numpy()\n",
    "    n = n[0]\n",
    "    return n\n",
    "\n",
    "def Tile_reshape(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    b = a*0+1\n",
    "    a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "    return a\n",
    "def VP(m, cn): # m: order,  cn: input tensor, k: range\n",
    "    cn = tf.cast(cn, tf.float64)\n",
    "    vp = tf.math.pow(cn,m)\n",
    "    vp = tf.reduce_sum(vp, axis = -1)\n",
    "    vp = tf.expand_dims(vp, axis = -1)\n",
    "    vp = tf.tile(vp, Tile_reshape(cn))\n",
    "    return vp\n",
    " \n",
    "def VC1(cn):\n",
    "    vc = tf.reduce_sum(cn, axis = -1)\n",
    "    vc = tf.expand_dims(vc, axis=-1)\n",
    "    vc = tf.tile(vc, Tile_reshape(cn))\n",
    "    vc = tf.cast(vc, tf.float64)\n",
    "    return vc\n",
    "def VC2(cn):\n",
    "    vc = (VC1(cn)**2 - VP(2, cn))/2\n",
    "    return vc\n",
    "def VC3(cn):\n",
    "    vc1 = VC1(cn)\n",
    "    vp2 = VP(2,cn)\n",
    "    vp3 = VP(3,cn)\n",
    "    vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "    return vc\n",
    "def VC4(cn):\n",
    "    n = find_N(cn)\n",
    "#     vc = (VC3(cn)*VP(0,cn) - 3/(n-2)*VC2(cn)*VP(1,cn) + 3/(n-2)*2/(n-1)*VC1(cn)*VP(3,cn) - 3/(n-2)*2/(n-1)*VP(4,cn) )/(n-3)\n",
    "    vc = (VC3(cn)*VP(1,cn) - VC2(cn)*VP(2,cn) + VC1(cn)*VP(3,cn) - VP(4,cn) )/4\n",
    "    return vc\n",
    "\n",
    "## VCN: \n",
    "# vcn = 0\n",
    "# for i in range(N):\n",
    "#     vcn += VC(N-i-1)VP(i+1)*(-1)**i\n",
    "# vcn = vcn/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Con(n,k):\n",
    "    fc=1\n",
    "    for i in range(k):\n",
    "        fc *=(n-i)\n",
    "        fc /= (i+1)\n",
    "    return fc\n",
    "def text(cn):\n",
    "    vc = (VC2(cn)*VP(1, cn) - VC1(cn)*VP(2,cn) + VP(3,cn))/3\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "n = a[-1:].numpy()\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561.5,  561.5,  561.5,  561.5,  561.5],\n",
       "       [   5. ,    5. ,    5. ,    5. ,    5. ],\n",
       "       [3616.5, 3616.5, 3616.5, 3616.5, 3616.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = tf.constant([[1,2,3,4,5],[1,1,1,1,1],[3,4,5,6,7]])\n",
    "# cn = tf.constant([[1,2,3,4],[1,1,1,1],[3,4,5,6]])\n",
    "\n",
    "# cn.numpy()\n",
    "VC4(cn).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "fc=1\n",
    "for i in range(N):\n",
    "    fc*=(i+1)\n",
    "    \n",
    "a = 0\n",
    "for i in range(N):\n",
    "    a += fc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-887b695135f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \"\"\"\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.math.multiply(VC3(cn),VC1(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "b = a*0+1\n",
    "a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(cn, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
