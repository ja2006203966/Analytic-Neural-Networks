{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.optimize as opt\n",
    "# import sys, os, random, gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras import metrics\n",
    "# from keras.utils import np_utils\n",
    "# import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "# ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(10):\n",
    "for example in ds.take(i):\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "#         x.append(image)\n",
    "#         y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(3):\n",
    "    image, label = example[\"image\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets.Load_data import Load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg, y_rg = Load_data(\"./data/kc_house_data.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 18), (21613,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape, y_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(tf.keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQV(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(KQV, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "        wk_init = tf.random_normal_initializer()\n",
    "        wv_init = tf.random_normal_initializer()\n",
    "        \n",
    "        self.wq = tf.Variable(initial_value=wq_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wk = tf.Variable(initial_value=wk_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wv = tf.Variable(initial_value=wv_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "\n",
    "        \n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(self.units,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        q = tf.matmul(self.wq,inputs)\n",
    "        k = tf.matmul(self.wk,inputs)\n",
    "        v = tf.matmul(self.wv, inputs)\n",
    "\n",
    "        return k, q, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2, input_shape = 1):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(input_shape)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "#         a = tf.constant(a)\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "#         cn = tf.cast(cn, tf.float64)\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "#         vc = tf.cast(vc, tf.float64)\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "#         out_num = self.order*2\n",
    "#         v = tf.expand_dims(v, axis = -1)\n",
    "#         v = tf.tile(v, self.Tile_reshape(out_num))\n",
    "        v = self.wq2(v)\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "#         print(\"vc shape:\", vc1.shape)\n",
    "##-------------------------------------------------------- normalization \n",
    "#         vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "#         vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "#         vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "#         vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "#         vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "#         vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "##-------------------------------------------------------\n",
    "#         w = self.add_weight(\"v weights\", shape = [18 , 18])\n",
    "#         v = self.wq2(v)\n",
    "#----------------------------------------------------------\n",
    "#         print(\"v shape:\", v.shape)\n",
    "#         v = tf.Variable(self.rui(shape = tf.shape(v)), dtype=tf.float32)*v\n",
    "        \n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        q = self.wq(q)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        k = self.wk(v)\n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         print(\"wk\",k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         n = tf.matmul(q,k) ##tooooooooooo slow\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##--------------------------------------------------------------------normalize----------\n",
    "#         k = tf.math.log(tf.math.abs(k+1e-10)+1)\n",
    "#         q = tf.math.log(tf.math.abs(q+1e-10)+1)\n",
    "\n",
    "#         print(\"kdiv\",tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))\n",
    "\n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "#         n = k*q\n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##-----------------------------------------------top k version------------------------------\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "##------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2, input_shape = 1):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(input_shape)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        v = self.wq2(v)\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "#         n = k*q\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompletedGraph(tf.keras.layers.Layer):\n",
    "    def __init__(self, rank=2):\n",
    "        super(CompletedGraph, self).__init__()\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, x, t):\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        t = tf.expand_dims(t, axis=-1)\n",
    "        t = tf.transpose(t, perm=self.p)\n",
    "        x = tf.matmul(x,t)\n",
    "#         print(x.shape)\n",
    "#         x = tf.reshape(x, x.shape[:-2]+tf.TensorShape(x.shape[-1]*x.shape[-2]) )\n",
    "#         print(x.shape[-2]+tf.TensorShape(x.shape[-1]*x.shape[-2]))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierSeries(tf.keras.layers.Layer):\n",
    "    def __init__(self, rank=2, node = 10):\n",
    "        super(FourierSeries, self).__init__()\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.node = node\n",
    "    def call(self, cn):\n",
    "        m = self.node\n",
    "        n = tf.cast(tf.rank(cn), tf.int32)\n",
    "        one = tf.constant(1, dtype=tf.float32)\n",
    "        tileshape = tf.concat( [tf.cast(tf.linspace(one, one, n), tf.int32), tf.constant([m]) ], axis=0)\n",
    "        order = tf.linspace(one, m, m)\n",
    "        order = tf.reshape(order, tileshape)\n",
    "        vp = tf.expand_dims(cn, axis=-1)\n",
    "        vp = tf.tile(vp, tileshape)\n",
    "        order = tf.tile(order, tf.concat([tf.shape(vp)[:-1], [1]], axis=-1))\n",
    "        order = tf.cast(order, tf.float32)\n",
    "#         order = order/self.step\n",
    "        vsin = tf.math.sin(np.pi*2*order*vp)\n",
    "        vcos = tf.math.cos(np.pi*2*order*vp)\n",
    "        v0 = tf.reduce_min(vp*0, axis=-1)\n",
    "        v0 = tf.expand_dims(v0, axis=-1)\n",
    "        vp = tf.concat([v0, vsin, vcos], axis=-1)\n",
    "        return vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([324])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.TensorShape(inputs.shape[-1]*inputs.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer version2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Customer Class\n",
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, order=4, num_out=1, rank=2, activation=False, step = 1):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.step = step\n",
    "        self.order = order\n",
    "        self.activation = activation\n",
    "        self.node = order*2\n",
    "        self.wq = tf.keras.layers.Dense(self.node)\n",
    "        self.wq2 = tf.keras.layers.Dense(self.node)\n",
    "        self.wk = tf.keras.layers.Dense(self.node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    def MultiVP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "        n = tf.cast(tf.rank(cn), tf.int32)\n",
    "        one = tf.constant(1, dtype=tf.float32)\n",
    "        tileshape = tf.concat( [tf.cast(tf.linspace(one, one, n), tf.int32), tf.constant([m]) ], axis=0)\n",
    "        order = tf.linspace(one, m, m)\n",
    "        order = tf.reshape(order, tileshape)\n",
    "        vp = tf.expand_dims(cn, axis=-1)\n",
    "        vp = tf.tile(vp, tileshape)\n",
    "        order = tf.tile(order, tf.concat([tf.shape(vp)[:-1], [1]], axis=-1))\n",
    "        order = tf.cast(order, tf.float32)\n",
    "        order = order/self.step\n",
    "        vp = tf.pow(tf.math.abs(vp), order)*tf.math.sign(vp) if self.step!=1 else tf.pow(vp, order)\n",
    "        vp = vp/tf.math.exp(tf.math.lgamma(order+1))/cn.shape[-1]\n",
    "        vp = tf.reduce_sum(vp, axis=-2)\n",
    "        return vp\n",
    "    def MultiVCN(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "        n = tf.cast(tf.rank(cn)-1, tf.int32)\n",
    "        one = tf.constant(1, dtype=tf.float32)\n",
    "        tileshape = tf.concat( [tf.cast(tf.linspace(one, one, n), tf.int32), tf.constant([m]) ], axis=0)\n",
    "        order = tf.linspace(one,m,m)\n",
    "        order = tf.reshape(order, tileshape)\n",
    "        vcn = tf.expand_dims(cn, axis=-1)\n",
    "        vcn = tf.reduce_sum(vcn, axis=-2)\n",
    "        vcn = tf.tile(vcn, tileshape)\n",
    "        order = tf.tile(order, tf.concat([tf.shape(vcn)[:-1], [1]], axis=-1))\n",
    "        order = tf.cast(order, tf.float32)\n",
    "        order = order/self.step\n",
    "        vcn = tf.pow(tf.math.abs(vcn)/cn.shape[-1], order)*tf.math.sign(vcn) if self.step!=1 else tf.pow(vcn, order)\n",
    "        vcn = vcn/tf.math.exp(tf.math.lgamma(order+1))\n",
    "        return vcn\n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    # def VC(self, m, cn):\n",
    "    #   if m==0:\n",
    "    #     return 1\n",
    "    #   if m==1:\n",
    "    #     return VP(1,m)\n",
    "    #   else:\n",
    "        \n",
    "    def call(self, q, k, v):\n",
    "        # vc1 = self.VC1(v)\n",
    "        # vc2 = self.VC2(v)\n",
    "        # vc3 = self.VC3(v)\n",
    "        # vc4 = self.VC4(v)\n",
    "        # vp2 = self.VP(2,v)\n",
    "        # vp3 = self.VP(3,v)\n",
    "        # vp4 = self.VP(4,v)\n",
    "##-------------------------------------------------------- this block is to prevent divergence\n",
    "        # vc2 = tf.math.pow(tf.math.abs(vc2),tf.constant(1/2) ) *tf.math.sign(vc2)\n",
    "        # vc3 = tf.math.pow(tf.math.abs(vc3),tf.constant(1/3))*tf.math.sign(vc3)\n",
    "        # vc4 = tf.math.pow(tf.math.abs(vc4),tf.constant(1/4))*tf.math.sign(vc4)\n",
    "        # vp2 = tf.math.pow(tf.math.abs(vp2),tf.constant(1/2))*tf.math.sign(vp2)\n",
    "        # vp3 = tf.math.pow(tf.math.abs(vp3),tf.constant(1/3))*tf.math.sign(vp3)\n",
    "        # vp4 = tf.math.pow(tf.math.abs(vp4),tf.constant(1/4))*tf.math.sign(vp4)\n",
    "##----------------------------------------------------------\n",
    "        # vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        # vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        # vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        # vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        # vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        # vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        # vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "        # print(vc1.shape)\n",
    "        \n",
    "        vp = self.MultiVP(self.order,v)\n",
    "        vcn = self.MultiVCN(self.order,v)\n",
    "        v = tf.concat([vp, vcn], axis=-1)\n",
    "        # print(\"v: \", v.shape)\n",
    "\n",
    "        v = tf.expand_dims(v,axis=-1)\n",
    "        # print(\"v: \", v.shape)\n",
    "        v = tf.keras.activations.tanh(v) if self.activation else v\n",
    "        # print(\"v: \", v.shape)\n",
    "        # v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        # q = tf.expand_dims(q, axis=-1)\n",
    "        q = tf.transpose(q, perm=self.p)\n",
    "        # print(\"q: \", q.shape) \n",
    "        # print(\"q: \",k.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        # print(\"k: \",k.shape)\n",
    "        k = tf.transpose(k, perm=self.p)\n",
    "        # print(\"k: \", k.shape) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-8, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-8, axis=-1)\n",
    "        # n = tf.matmul(k,q)\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "        # print(\"n: \",n.shape)\n",
    "        # n = tf.transpose(n, perm=self.p)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "        return v\n",
    "\n",
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        # k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "        \n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=1000, num_out=100, rank=2):\n",
    "        super(Data_Selection, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, q, k, v):\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        n = k*q\n",
    "##------------------------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "        v = tf.expand_dims(v, axis=-1)\n",
    "        v = n*v\n",
    "        v = tf.reduce_sum(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##-----------------------------------------------------\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(np.sum(x_train, axis = -1), axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "\n",
    "x_train = x_train/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (1, 18)\n",
      "vc shape: (1, 18)\n",
      "v shape: (1, 18, 7)\n",
      "wk tf.Tensor(\n",
      "[[[ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]]], shape=(1, 18, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[ 2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19]\n",
      "  [-8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18]\n",
      "  [ 2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19]\n",
      "  [ 3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19]\n",
      "  [-2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19]\n",
      "  [ 2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19]\n",
      "  [-3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[ 1.1536372e+00  8.6522788e-01  8.5080743e+02  1.4420465e+03\n",
      "    5.7681859e-01  0.0000000e+00  8.6522788e-01  8.6522788e-01\n",
      "    2.5956836e+00  5.7105042e+02  2.7975702e+02  5.7076196e+02\n",
      "    0.0000000e+00  2.8300451e+04  1.3720034e+01 -3.5294086e+01\n",
      "    6.1719586e+02  1.1536372e+03]\n",
      "  [-8.5340548e-01 -6.4005411e-01 -6.2938654e+02 -1.0667568e+03\n",
      "   -4.2670274e-01  0.0000000e+00 -6.4005411e-01 -6.4005411e-01\n",
      "   -1.9201623e+00 -4.2243570e+02 -2.0695082e+02 -4.2222235e+02\n",
      "    0.0000000e+00 -2.0935316e+04 -1.0149424e+01  2.6108873e+01\n",
      "   -4.5657193e+02 -8.5340546e+02]\n",
      "  [ 1.4279835e+00  1.0709877e+00  1.0531378e+03  1.7849794e+03\n",
      "    7.1399176e-01  0.0000000e+00  1.0709877e+00  1.0709877e+00\n",
      "    3.2129629e+00  7.0685187e+02  3.4628601e+02  7.0649487e+02\n",
      "    0.0000000e+00  3.5030578e+04  1.6982794e+01 -4.3687370e+01\n",
      "    7.6397119e+02  1.4279835e+03]\n",
      "  [-1.1096001e-02 -8.3220005e-03 -8.1833000e+00 -1.3870001e+01\n",
      "   -5.5480003e-03  0.0000000e+00 -8.3220005e-03 -8.3220005e-03\n",
      "   -2.4966002e-02 -5.4925203e+00 -2.6907802e+00 -5.4897461e+00\n",
      "    0.0000000e+00 -2.7220154e+02 -1.3196307e-01  3.3946827e-01\n",
      "   -5.9363604e+00 -1.1096001e+01]\n",
      "  [-7.7478671e-01 -5.8109003e-01 -5.7140521e+02 -9.6848340e+02\n",
      "   -3.8739336e-01  0.0000000e+00 -5.8109003e-01 -5.8109003e-01\n",
      "   -1.7432702e+00 -3.8351941e+02 -1.8788577e+02 -3.8332571e+02\n",
      "    0.0000000e+00 -1.9006680e+04 -9.2144222e+00  2.3703630e+01\n",
      "   -4.1451089e+02 -7.7478668e+02]\n",
      "  [-8.7473464e-01 -6.5605098e-01 -6.4511682e+02 -1.0934183e+03\n",
      "   -4.3736732e-01  0.0000000e+00 -6.5605098e-01 -6.5605098e-01\n",
      "   -1.9681530e+00 -4.3299365e+02 -2.1212315e+02 -4.3277496e+02\n",
      "    0.0000000e+00 -2.1458553e+04 -1.0403088e+01  2.6761414e+01\n",
      "   -4.6798303e+02 -8.7473462e+02]\n",
      "  [-1.6690795e+00 -1.2518096e+00 -1.2309462e+03 -2.0863494e+03\n",
      "   -8.3453977e-01  0.0000000e+00 -1.2518096e+00 -1.2518096e+00\n",
      "   -3.7554290e+00 -8.2619440e+02 -4.0475180e+02 -8.2577710e+02\n",
      "    0.0000000e+00 -4.0945023e+04 -1.9850113e+01  5.1063404e+01\n",
      "   -8.9295758e+02 -1.6690796e+03]]], shape=(1, 7, 18), dtype=float32)\n",
      "kdiv tf.Tensor([[35989.742 34145.016 35813.79  36438.703 35999.33  35913.438 36220.984]], shape=(1, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[3.6966380e-02 3.0038426e-02 3.2512918e-01 3.5053056e-01 2.1944409e-02\n",
      "   0.0000000e+00 3.0038426e-02 3.0038426e-02 6.1665431e-02 3.0594465e-01\n",
      "   2.7164879e-01 3.0592036e-01 0.0000000e+00 4.9394003e-01 1.2958258e-01\n",
      "   1.7306793e-01 3.0968288e-01 3.3978647e-01]\n",
      "  [3.1124566e-02 2.4955617e-02 3.2517225e-01 3.5175481e-01 1.7925721e-02\n",
      "   0.0000000e+00 2.4955617e-02 2.4955617e-02 5.4056674e-02 3.0509943e-01\n",
      "   2.6922941e-01 3.0507401e-01 0.0000000e+00 5.0186938e-01 1.2163760e-01\n",
      "   1.6645484e-01 3.0901039e-01 3.4051058e-01]\n",
      "  [4.1416258e-02 3.3991005e-02 3.2497981e-01 3.4959647e-01 2.5157360e-02\n",
      "   0.0000000e+00 3.3991005e-02 3.3991005e-02 6.7146964e-02 3.0638611e-01\n",
      "   2.7313933e-01 3.0636257e-01 0.0000000e+00 4.8855704e-01 1.3490477e-01\n",
      "   1.7740490e-01 3.1000936e-01 3.3918458e-01]\n",
      "  [1.3964046e-03 1.0487455e-03 2.8059804e-01 3.4158731e-01 7.0012844e-04\n",
      "   0.0000000e+00 1.0487455e-03 1.0487455e-03 3.1205164e-03 2.3672052e-01\n",
      "   1.6524658e-01 2.3666644e-01 0.0000000e+00 7.0994109e-01 1.5685607e-02\n",
      "   3.6985498e-02 2.4508846e-01 3.1545955e-01]\n",
      "  [2.9375188e-02 2.3457661e-02 3.2514268e-01 3.5212332e-01 1.6765820e-02\n",
      "   0.0000000e+00 2.3457661e-02 2.3457661e-02 5.1673368e-02 3.0477071e-01\n",
      "   2.6837167e-01 3.0474490e-01 0.0000000e+00 5.0450039e-01 1.1898976e-01\n",
      "   1.6421126e-01 3.0873981e-01 3.4071052e-01]\n",
      "  [3.1581409e-02 2.5348648e-02 3.2517639e-01 3.5165882e-01 1.8231904e-02\n",
      "   0.0000000e+00 2.5348648e-02 2.5348648e-02 5.4670598e-02 3.0517879e-01\n",
      "   2.6944196e-01 3.0515346e-01 0.0000000e+00 5.0120461e-01 1.2230630e-01\n",
      "   1.6701820e-01 3.0907512e-01 3.4045699e-01]\n",
      "  [4.4809200e-02 3.7049923e-02 3.2481110e-01 3.4887856e-01 2.7695838e-02\n",
      "   0.0000000e+00 3.7049923e-02 3.7049923e-02 7.1170427e-02 3.0663100e-01\n",
      "   2.7411965e-01 3.0660796e-01 0.0000000e+00 4.8472837e-01 1.3863398e-01\n",
      "   1.8040195e-01 3.1017375e-01 3.3869913e-01]]], shape=(1, 7, 18), dtype=float32)\n",
      "v shape: (1, 18, 7)\n",
      "n shape: (1, 18, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
       " array([[9.7922925e+17, 8.0966167e+17, 7.1021882e+18, 7.6290285e+18,\n",
       "         6.0524301e+17, 0.0000000e+00, 8.0966167e+17, 8.0966167e+17,\n",
       "         1.5553235e+18, 6.7042557e+18, 5.9927380e+18, 6.7037515e+18,\n",
       "         0.0000000e+00, 1.0603152e+19, 3.0297832e+18, 3.9428487e+18,\n",
       "         6.7817976e+18, 7.4061943e+18]], dtype=float32)>,\n",
       " array([[ 4.00000e+00,  3.00000e+00,  2.95000e+03,  5.00000e+03,\n",
       "          2.00000e+00,  0.00000e+00,  3.00000e+00,  3.00000e+00,\n",
       "          9.00000e+00,  1.98000e+03,  9.70000e+02,  1.97900e+03,\n",
       "          0.00000e+00,  9.81260e+04,  4.75714e+01, -1.22375e+02,\n",
       "          2.14000e+03,  4.00000e+03]], dtype=float32))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_rg[15:16]\n",
    "Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x,x,x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 18]),\n",
       " <tf.Tensor 'Shape_16:0' shape=(2,) dtype=int32>,\n",
       " TensorShape([None, 18]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, tf.shape(inputs), tf.TensorShape(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape to a Tensor: (None, 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2972\u001b[0m         shape = constant_op._tensor_shape_tensor_conversion_function(\n\u001b[0;32m-> 2973\u001b[0;31m             tensor_shape.TensorShape(shape))\n\u001b[0m\u001b[1;32m   2974\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[0;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m     raise ValueError(\n\u001b[0;32m--> 338\u001b[0;31m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0m\u001b[1;32m    339\u001b[0m   \u001b[0ms_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (None, 18)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-c168a36a796c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tf.keras.layers.Layer.add_weight(\"v_weights\", shape = inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOnes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_numpy_compatible\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected numeric or boolean dtype, got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2974\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m         \u001b[0;31m# Happens when shape is a list with tensor elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2976\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2977\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it's a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[0;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     raise ValueError(\n\u001b[0;32m--> 338\u001b[0;31m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0m\u001b[1;32m    339\u001b[0m   \u001b[0ms_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mint64_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (None, 18)"
     ]
    }
   ],
   "source": [
    "# tf.keras.layers.Layer.add_weight(\"v_weights\", shape = inputs.shape)\n",
    "tf.Variable(initial_value = tf.keras.initializers.Ones()(shape = inputs.shape ), shape = inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n",
      "(None, 18, 201)\n",
      "(None, 3618)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(18))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "\n",
    "x = FourierSeries(node=100, rank = tf.rank(x))(x)\n",
    "# b = tf.reduce_min(x, axis=-1)\n",
    "# b = tf.expand_dims(b, axis=-1)\n",
    "# x = tf.concat([b*0+1, x], axis=-1)\n",
    "# a1=x\n",
    "print(x.shape)\n",
    "# x = CompletedGraph( rank=tf.rank(x))(x,x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# a2=x\n",
    "# x = Data_Selection(node=18, num_out=100, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# b = tf.reduce_min(x, axis=-1)\n",
    "# b = tf.expand_dims(b, axis=-1)\n",
    "# x = tf.concat([b*0+1, x], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = CompletedGraph( rank=tf.rank(x))(x,a1)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Data_Selection(node=18, num_out=100, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# a3 = Symmetry_Set_Basis(num_out=1, rank=tf.rank(a1), input_shape = a1.shape[-1])(a1, a1, a1)\n",
    "# print(x.shape)\n",
    "# a2 = a3\n",
    "# a3 = Operator_Basis(num_out=1,rank=tf.rank(a3), input_shape = a3.shape[-1])(a3, a3, a3)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = tf.concat([a1,a2,a3,x], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "# a3 = x\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x), input_shape = x.shape[-1])(x, x, x)\n",
    "# print(x.shape)\n",
    "# a4 = x\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x), input_shape = x.shape[-1])(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = tf.concat([a1, a2, a3, a4, x], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "# a5 = x\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x), input_shape = x.shape[-1])(x, x, x)\n",
    "# print(x.shape)\n",
    "# a6 = x\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x), input_shape = x.shape[-1])(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.concat([a1, a2, a3, a4, a5, a6, x], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a0,a1,a2,a3,a4], axis=-1)\n",
    "\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dropout(0.3)(x)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "print(x.shape)\n",
    "\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.math.is_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN_Regression\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=10, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_91 (InputLayer)        [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "fourier_series_7 (FourierSer (None, 18, 201)           0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 3618)              0         \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 1)                 3619      \n",
      "=================================================================\n",
      "Total params: 3,619\n",
      "Trainable params: 3,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = np.array(x_rg)\n",
    "y_rg = np.array(y_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = x_rg.astype(np.float32)\n",
    "y_rg = y_rg.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_rg[:18000], y_rg[:18000]\n",
    "x_val, y_val = x_rg[18000:], y_rg[18000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "556/563 [============================>.] - ETA: 0s - loss: 2.3889 - accuracy: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 0.15645, saving model to ./test1/ANN_Regression_model_\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2.3628 - accuracy: 0.0000e+00 - val_loss: 0.1565 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "556/563 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.0000e+00\n",
      "Epoch 00002: val_loss improved from 0.15645 to 0.08068, saving model to ./test1/ANN_Regression_model_\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1008 - accuracy: 0.0000e+00 - val_loss: 0.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "555/563 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.0000e+00\n",
      "Epoch 00003: val_loss improved from 0.08068 to 0.07386, saving model to ./test1/ANN_Regression_model_\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.0000e+00 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "561/563 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.0000e+00\n",
      "Epoch 00004: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.0765 - accuracy: 0.0000e+00 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "553/563 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.0000e+00\n",
      "Epoch 00005: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.0000e+00 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "552/563 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.0000e+00\n",
      "Epoch 00006: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.0852 - accuracy: 0.0000e+00 - val_loss: 0.0868 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "560/563 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.0000e+00\n",
      "Epoch 00007: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.0915 - accuracy: 0.0000e+00 - val_loss: 0.0858 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "560/563 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.0000e+00\n",
      "Epoch 00008: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.0000e+00 - val_loss: 0.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "556/563 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.0000e+00\n",
      "Epoch 00009: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.0974 - accuracy: 0.0000e+00 - val_loss: 0.1144 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "554/563 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.0000e+00\n",
      "Epoch 00010: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.1045 - accuracy: 0.0000e+00 - val_loss: 0.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "554/563 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.0000e+00\n",
      "Epoch 00011: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.0998 - accuracy: 0.0000e+00 - val_loss: 0.0874 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "556/563 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.0000e+00\n",
      "Epoch 00012: val_loss did not improve from 0.07386\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.0000e+00 - val_loss: 0.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "560/563 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.0000e+00\n",
      "Epoch 00013: val_loss did not improve from 0.07386\n",
      "Restoring model weights from the end of the best epoch.\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.1009 - accuracy: 0.0000e+00 - val_loss: 0.0972 - val_accuracy: 0.0000e+00\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cc4772780>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelANN.fit(np.log(np.abs(x_train)+1), np.log(np.abs(y_train)+1), validation_data=(np.log(np.abs(x_val)+1), np.log(np.abs(y_val)+1)), callbacks = callbacks, shuffle=True , epochs=40, batch_size=32, verbose=1)\n",
    "# modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = modelANN.predict(np.log(np.abs(x_rg)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "# plt.hist(y_pre, histtype='step')\n",
    "# plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "plt.xlabel(\"Model Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.scatter(y_pre,np.log(np.abs(y_rg)+1))\n",
    "plt.plot([0,16],[0,16], color = 'k', linestyle='--')\n",
    "# plt.xlim([0,2.5])\n",
    "# plt.savefig(\"./plot/Regression_Scatter3.png\")\n",
    "# plt.savefig(\"./plot/DNN_Regression_Scatter1.png\")\n",
    "plt.savefig(\"./plot/FourierSeries_Scatter1.png\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\", bins = 200)\n",
    "plt.hist(np.log(np.abs(y_rg)+1), histtype='step',  label = \"target\", bins = 200)\n",
    "plt.legend()\n",
    "# plt.savefig(\"./plot/Regression_Hist3.png\")\n",
    "# plt.savefig(\"./plot/DNN_Regression_Hist1.png\")\n",
    "plt.savefig(\"./plot/FourierSeries_Regression_Hist1.png\")\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./pre_train_models/ANN_Lite/assets\n"
     ]
    }
   ],
   "source": [
    "modelANN.save(\"./pre_train_models/ANN_Lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28)\n",
      "(None, 28, 28)\n",
      "(None, 784)\n",
      "(None, 784)\n",
      "(None, 784)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "x = tf.math.log(tf.math.abs(x)+1)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "# x = Data_Selection(node = 100, num_out=20,rank=tf.rank(x))(x,x,x)\n",
    "# print(x.shape)\n",
    "\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# c = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# c = tf.squeeze(c, axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "# print(x.shape)\n",
    "# a = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([x,b], axis=-1)\n",
    "# c = tf.concat([x,c], axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# c = Operator_Basis(num_out=1,rank=tf.rank(c))(c, c, c)\n",
    "# print(\"a:\",a.shape)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "\n",
    "# x = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([b,c], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(b))(b, b, b)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "print(x.shape)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_93 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Abs_3 (TensorFlo [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorF [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Log_4 (TensorFlo [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_139 (Sy (None, 784)               70        \n",
      "_________________________________________________________________\n",
      "operator__basis_71 (Operator (None, 784)               20        \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,940\n",
      "Trainable params: 7,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [ for i in y_train]\n",
    "y2 = []\n",
    "for i in y_train:\n",
    "    vec = np.zeros([10])    \n",
    "    vec[i]=1\n",
    "    y2.append(vec)\n",
    "y2=np.array(y2)    \n",
    "y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[40000:]\n",
    "y_val = y_train[40000:]\n",
    "x_train = x_train[:40000]\n",
    "y_train = y_train[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.1097 - accuracy: 0.6270\n",
      "Epoch 00001: val_loss improved from inf to 1.90848, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 2.1097 - accuracy: 0.6270 - val_loss: 1.9085 - val_accuracy: 0.7388\n",
      "Epoch 2/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7684 - accuracy: 0.8091\n",
      "Epoch 00002: val_loss improved from 1.90848 to 1.69493, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.7684 - accuracy: 0.8092 - val_loss: 1.6949 - val_accuracy: 0.8493\n",
      "Epoch 3/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6715 - accuracy: 0.8586\n",
      "Epoch 00003: val_loss improved from 1.69493 to 1.63996, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6715 - accuracy: 0.8586 - val_loss: 1.6400 - val_accuracy: 0.8724\n",
      "Epoch 4/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6304 - accuracy: 0.8763\n",
      "Epoch 00004: val_loss improved from 1.63996 to 1.61236, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6304 - accuracy: 0.8763 - val_loss: 1.6124 - val_accuracy: 0.8851\n",
      "Epoch 5/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.6071 - accuracy: 0.8875\n",
      "Epoch 00005: val_loss improved from 1.61236 to 1.59547, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6071 - accuracy: 0.8874 - val_loss: 1.5955 - val_accuracy: 0.8927\n",
      "Epoch 6/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5919 - accuracy: 0.8943\n",
      "Epoch 00006: val_loss improved from 1.59547 to 1.58405, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5920 - accuracy: 0.8942 - val_loss: 1.5841 - val_accuracy: 0.8971\n",
      "Epoch 7/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5813 - accuracy: 0.8990\n",
      "Epoch 00007: val_loss improved from 1.58405 to 1.57602, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5813 - accuracy: 0.8989 - val_loss: 1.5760 - val_accuracy: 0.9004\n",
      "Epoch 8/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5733 - accuracy: 0.9031\n",
      "Epoch 00008: val_loss improved from 1.57602 to 1.57004, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5732 - accuracy: 0.9032 - val_loss: 1.5700 - val_accuracy: 0.9035\n",
      "Epoch 9/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5670 - accuracy: 0.9069\n",
      "Epoch 00009: val_loss improved from 1.57004 to 1.56534, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5671 - accuracy: 0.9068 - val_loss: 1.5653 - val_accuracy: 0.9063\n",
      "Epoch 10/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5650 - accuracy: 0.9094\n",
      "Epoch 00010: val_loss improved from 1.56534 to 1.56158, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.5650 - accuracy: 0.9094 - val_loss: 1.5616 - val_accuracy: 0.9079\n",
      "Epoch 11/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5579 - accuracy: 0.9120\n",
      "Epoch 00011: val_loss improved from 1.56158 to 1.55885, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5580 - accuracy: 0.9119 - val_loss: 1.5588 - val_accuracy: 0.9089\n",
      "Epoch 12/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.9142\n",
      "Epoch 00012: val_loss improved from 1.55885 to 1.55651, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5547 - accuracy: 0.9142 - val_loss: 1.5565 - val_accuracy: 0.9104\n",
      "Epoch 13/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5519 - accuracy: 0.9160\n",
      "Epoch 00013: val_loss improved from 1.55651 to 1.55473, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5519 - accuracy: 0.9160 - val_loss: 1.5547 - val_accuracy: 0.9117\n",
      "Epoch 14/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5495 - accuracy: 0.9178\n",
      "Epoch 00014: val_loss improved from 1.55473 to 1.55299, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5495 - accuracy: 0.9178 - val_loss: 1.5530 - val_accuracy: 0.9127\n",
      "Epoch 15/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5474 - accuracy: 0.9187\n",
      "Epoch 00015: val_loss improved from 1.55299 to 1.55178, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5474 - accuracy: 0.9187 - val_loss: 1.5518 - val_accuracy: 0.9135\n",
      "Epoch 16/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5457 - accuracy: 0.9204\n",
      "Epoch 00016: val_loss improved from 1.55178 to 1.55039, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5457 - accuracy: 0.9203 - val_loss: 1.5504 - val_accuracy: 0.9137\n",
      "Epoch 17/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5440 - accuracy: 0.9213\n",
      "Epoch 00017: val_loss improved from 1.55039 to 1.54942, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5440 - accuracy: 0.9214 - val_loss: 1.5494 - val_accuracy: 0.9147\n",
      "Epoch 18/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5425 - accuracy: 0.9229\n",
      "Epoch 00018: val_loss improved from 1.54942 to 1.54879, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5426 - accuracy: 0.9229 - val_loss: 1.5488 - val_accuracy: 0.9150\n",
      "Epoch 19/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5412 - accuracy: 0.9241\n",
      "Epoch 00019: val_loss improved from 1.54879 to 1.54786, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5413 - accuracy: 0.9240 - val_loss: 1.5479 - val_accuracy: 0.9166\n",
      "Epoch 20/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5400 - accuracy: 0.9254\n",
      "Epoch 00020: val_loss improved from 1.54786 to 1.54713, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5400 - accuracy: 0.9254 - val_loss: 1.5471 - val_accuracy: 0.9170\n",
      "Epoch 21/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5389 - accuracy: 0.9264\n",
      "Epoch 00021: val_loss improved from 1.54713 to 1.54643, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5389 - accuracy: 0.9265 - val_loss: 1.5464 - val_accuracy: 0.9176\n",
      "Epoch 22/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.9269\n",
      "Epoch 00022: val_loss improved from 1.54643 to 1.54609, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5378 - accuracy: 0.9269 - val_loss: 1.5461 - val_accuracy: 0.9168\n",
      "Epoch 23/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5369 - accuracy: 0.9280\n",
      "Epoch 00023: val_loss improved from 1.54609 to 1.54529, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5368 - accuracy: 0.9281 - val_loss: 1.5453 - val_accuracy: 0.9184\n",
      "Epoch 24/400\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.9286\n",
      "Epoch 00024: val_loss improved from 1.54529 to 1.54492, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5359 - accuracy: 0.9285 - val_loss: 1.5449 - val_accuracy: 0.9184\n",
      "Epoch 25/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.9294\n",
      "Epoch 00025: val_loss improved from 1.54492 to 1.54452, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5350 - accuracy: 0.9294 - val_loss: 1.5445 - val_accuracy: 0.9186\n",
      "Epoch 26/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.9303\n",
      "Epoch 00026: val_loss improved from 1.54452 to 1.54404, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5342 - accuracy: 0.9303 - val_loss: 1.5440 - val_accuracy: 0.9184\n",
      "Epoch 27/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5334 - accuracy: 0.9308\n",
      "Epoch 00027: val_loss improved from 1.54404 to 1.54375, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5334 - accuracy: 0.9308 - val_loss: 1.5438 - val_accuracy: 0.9191\n",
      "Epoch 28/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5327 - accuracy: 0.9316\n",
      "Epoch 00028: val_loss improved from 1.54375 to 1.54369, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5327 - accuracy: 0.9316 - val_loss: 1.5437 - val_accuracy: 0.9191\n",
      "Epoch 29/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.9323\n",
      "Epoch 00029: val_loss improved from 1.54369 to 1.54306, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5320 - accuracy: 0.9323 - val_loss: 1.5431 - val_accuracy: 0.9191\n",
      "Epoch 30/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.9330\n",
      "Epoch 00030: val_loss did not improve from 1.54306\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5313 - accuracy: 0.9331 - val_loss: 1.5432 - val_accuracy: 0.9191\n",
      "Epoch 31/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.9335\n",
      "Epoch 00031: val_loss improved from 1.54306 to 1.54289, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5307 - accuracy: 0.9335 - val_loss: 1.5429 - val_accuracy: 0.9187\n",
      "Epoch 32/400\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.9344\n",
      "Epoch 00032: val_loss improved from 1.54289 to 1.54288, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5300 - accuracy: 0.9344 - val_loss: 1.5429 - val_accuracy: 0.9189\n",
      "Epoch 33/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.9345\n",
      "Epoch 00033: val_loss improved from 1.54288 to 1.54226, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5296 - accuracy: 0.9345 - val_loss: 1.5423 - val_accuracy: 0.9194\n",
      "Epoch 34/400\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.9349\n",
      "Epoch 00034: val_loss did not improve from 1.54226\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5290 - accuracy: 0.9349 - val_loss: 1.5427 - val_accuracy: 0.9191\n",
      "Epoch 35/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.9356\n",
      "Epoch 00035: val_loss improved from 1.54226 to 1.54202, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5285 - accuracy: 0.9356 - val_loss: 1.5420 - val_accuracy: 0.9192\n",
      "Epoch 36/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.9361\n",
      "Epoch 00036: val_loss improved from 1.54202 to 1.54188, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5280 - accuracy: 0.9361 - val_loss: 1.5419 - val_accuracy: 0.9196\n",
      "Epoch 37/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5275 - accuracy: 0.9366\n",
      "Epoch 00037: val_loss did not improve from 1.54188\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5275 - accuracy: 0.9366 - val_loss: 1.5421 - val_accuracy: 0.9193\n",
      "Epoch 38/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.9370\n",
      "Epoch 00038: val_loss improved from 1.54188 to 1.54163, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5271 - accuracy: 0.9370 - val_loss: 1.5416 - val_accuracy: 0.9197\n",
      "Epoch 39/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.9372\n",
      "Epoch 00039: val_loss did not improve from 1.54163\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5266 - accuracy: 0.9372 - val_loss: 1.5421 - val_accuracy: 0.9194\n",
      "Epoch 40/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5261 - accuracy: 0.9380\n",
      "Epoch 00040: val_loss did not improve from 1.54163\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5262 - accuracy: 0.9379 - val_loss: 1.5417 - val_accuracy: 0.9201\n",
      "Epoch 41/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5258 - accuracy: 0.9380\n",
      "Epoch 00041: val_loss did not improve from 1.54163\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5258 - accuracy: 0.9379 - val_loss: 1.5416 - val_accuracy: 0.9197\n",
      "Epoch 00041: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5d672fb70>"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelANN.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks = callbacks, shuffle=True , epochs=10, batch_size=32)\n",
    "# modelANN.fit(x_train, y2 , callbacks = callbacks, shuffle=True , epochs=400, batch_size=32, verbose=1)\n",
    "# modelANN.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[for i in y_pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = [j for i in y_pre for j in range(10) if i[j]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.00000000e+00, 6.99999833e+00, 1.26924266e-22, ...,\n",
       "       5.00000000e+00, 5.99999714e+00, 8.00000000e+00])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.22881704e-29, 4.33907548e-33, ...,\n",
       "        1.00000000e+00, 2.84216566e-24, 3.79430916e-14],\n",
       "       [9.28732970e-26, 7.56170243e-33, 1.88351688e-37, ...,\n",
       "        9.99999881e-01, 4.03849002e-21, 6.14584650e-08],\n",
       "       [1.00000000e+00, 1.04838766e-36, 6.37808476e-21, ...,\n",
       "        1.40937411e-18, 1.34531557e-12, 2.05731644e-20],\n",
       "       ...,\n",
       "       [1.06471102e-20, 1.83538311e-24, 5.42189415e-37, ...,\n",
       "        6.64631997e-20, 5.24529808e-10, 9.85660874e-17],\n",
       "       [3.12992410e-10, 9.96973659e-27, 1.20822297e-13, ...,\n",
       "        2.65224969e-19, 1.09845135e-17, 2.95451079e-20],\n",
       "       [5.35354205e-09, 2.00367073e-22, 1.56277877e-13, ...,\n",
       "        2.91524362e-16, 1.00000000e+00, 2.24257448e-08]], dtype=float32)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = modelANN.predict(x_val)\n",
    "basis = np.linspace(0,9,10)\n",
    "y_pre = np.sum(basis*(y_pre**2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pre = modelANN.predict(x_val)\n",
    "basis = np.linspace(0,9,10)\n",
    "y_pre = np.sum(basis*(y_pre**2), axis=-1)\n",
    "plt.title(\"Analytic NN - Classification(input(28,28))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\", bins = 50)\n",
    "plt.hist(y_val, histtype='step',  label = \"target\", bins = 50, color='r')\n",
    "plt.legend()\n",
    "plt.savefig(\"./plot/Classification_Hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./pre_train_models/ANN_Number_Classification/assets\n"
     ]
    }
   ],
   "source": [
    "modelANN.save(\"./pre_train_models/ANN_Number_Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Analytic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis_Reconstruct(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2, weights = [[],[],[],[]]):\n",
    "        super(Symmetry_Set_Basis_Reconstruct, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node, weights = [weights[0], weights[1]])\n",
    "        self.wk = tf.keras.layers.Dense(node, weights = [weights[2], weights[3]])\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "        return v, n\n",
    "        \n",
    "class Operator_Basis_Reconstruct(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2, weights = [[],[],[],[],[],[]]):\n",
    "        super(Operator_Basis_Reconstruct, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node, weights = [weights[0], weights[1]])\n",
    "        self.wk = tf.keras.layers.Dense(node, weights = [weights[2], weights[3]])\n",
    "        self.alpha = tf.keras.layers.Dense(1, weights = [weights[4], weights[5]])\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "        return v, n, self.alpha.weights\n",
    "        \n",
    "\n",
    "def Selection_Reconstruct(n, r = 0.01, ind=[False]):\n",
    "    n = tf.reduce_mean(n,axis=0)\n",
    "#     n = tf.reduce_sum(n, axis=0)\n",
    "    sl1 = tf.reduce_max(tf.math.abs(n), axis = -1)\n",
    "    sl1 = sl1.numpy()\n",
    "    node = len(sl1)\n",
    "    dl = np.max(np.abs(sl1))*r\n",
    "    index = np.linspace(0, node-1, node)[np.abs(sl1)>dl] \n",
    "\n",
    "    index = (set(ind))&(set(index)) if np.any(ind) else index\n",
    "\n",
    "    index = np.array(list(index))\n",
    "    index = index.astype(np.int32)\n",
    "    n = n.numpy()\n",
    "    n = np.take(n, index, axis=0)\n",
    "#     n = np.sum(n, axis = 0)\n",
    "    return n, index\n",
    "def rgsn_Reconstruct(rgsn):\n",
    "    return tf.squeeze(rgsn[0]).numpy(), tf.squeeze(rgsn[1]).numpy() # weight, bias\n",
    "\n",
    "def Out_Analytic_Set(x, n, index, rgsnw=1, rgsnb=0, mode = \"SSB\", digits=2):\n",
    "    n = np.around(n, digits)\n",
    "    rgsnw = np.around(rgsnw, digits)\n",
    "    rgsnb = np.around(rgsnb, digits)\n",
    "    n = n.astype(np.str)\n",
    "    SSB_keys = [\"vc1\", \"vc2\", \"vc3\", \"vc4\", \"vp2\", \"vp3\", \"vp4\"]\n",
    "    OB_keys = [\"sqrt\", \"ln\", \"rgsn\"]\n",
    "    x0 = np.empty(x.shape, dtype=np.str) \n",
    "    x0 = x0.astype(np.dtype('<U1000'))\n",
    "    for i in range(len(x)):\n",
    "        if i in index:\n",
    "            \n",
    "            w = np.take(n, np.linspace(0, len(index)-1, len(index))[index==i].astype(np.int32), axis=0)\n",
    "            w = w.astype(np.str)\n",
    "            w = np.squeeze(w)\n",
    "            if mode == \"SSB\":\n",
    "                for j in range(len(SSB_keys)):\n",
    "                    x0[i] =x0[i] +\"+\"+ w[j]+\"*\"+SSB_keys[j]+\"(\"+x[i]+\")\"\n",
    "            if mode == \"OB\":\n",
    "                for j in range(len(OB_keys)):\n",
    "                    if OB_keys[j] == \"rgsn\":\n",
    "                        x0[i] = x0[i]+\"+\" + w[j]+\"*\"+str(rgsnw)+\"*\"+\"(\"+x[i]+\")\"+str(rgsnb)\n",
    "                    else:\n",
    "                        x0[i] = x0[i]+\"+\" + w[j]+\"*\"+OB_keys[j]+\"(\"+x[i]+\")\"\n",
    "    return x0\n",
    "                    \n",
    "# def Dense_Reconstruct(w, b, ind):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.layers[3].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = tf.keras.models.load_model(\"./pre_train_models/ANN\")\n",
    "test = tf.keras.models.load_model(\"./pre_train_models/ANN_Lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f273b4e0a20>,\n",
       " <tensorflow.python.keras.saving.saved_model.load.Symmetry_Set_Basis at 0x7f273b4e09b0>,\n",
       " <tensorflow.python.keras.saving.saved_model.load.Operator_Basis at 0x7f273b4e0ac8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f273b4d20f0>]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Symmetry_Set_Basis_Reconstruct at 0x7f28a846e8d0>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x), weights =test.layers[1].get_weights() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '',\n",
       "       '+-0.03*sqrt(+0.03*vc1()+0.03*vc2()+0.03*vc3()+0.03*vc4()+0.03*vp2()+-0.03*vp3()+0.03*vp4())+-0.03*ln(+0.03*vc1()+0.03*vc2()+0.03*vc3()+0.03*vc4()+0.03*vp2()+-0.03*vp3()+0.03*vp4())+-0.03*1.15*(+0.03*vc1()+0.03*vc2()+0.03*vc3()+0.03*vc4()+0.03*vp2()+-0.03*vp3()+0.03*vp4())-0.04',\n",
       "       '', '', '', '', '', '', '', '', '',\n",
       "       '+-0.95*sqrt(+0.23*vc1()+0.23*vc2()+0.23*vc3()+0.23*vc4()+0.23*vp2()+-0.23*vp3()+0.23*vp4())+-0.95*ln(+0.23*vc1()+0.23*vc2()+0.23*vc3()+0.23*vc4()+0.23*vp2()+-0.23*vp3()+0.23*vp4())+-0.95*1.15*(+0.23*vc1()+0.23*vc2()+0.23*vc3()+0.23*vc4()+0.23*vp2()+-0.23*vp3()+0.23*vp4())-0.04',\n",
       "       '', '', '',\n",
       "       '+-0.02*sqrt(+0.02*vc1()+0.02*vc2()+0.02*vc3()+0.02*vc4()+0.02*vp2()+-0.02*vp3()+0.02*vp4())+-0.02*ln(+0.02*vc1()+0.02*vc2()+0.02*vc3()+0.02*vc4()+0.02*vp2()+-0.02*vp3()+0.02*vp4())+-0.02*1.15*(+0.02*vc1()+0.02*vc2()+0.02*vc3()+0.02*vc4()+0.02*vp2()+-0.02*vp3()+0.02*vp4())-0.04'],\n",
       "      dtype='<U1000')"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def: K = vc1+vc2+vc3+vc4+vp2-vp3+vp4\n",
    "-sqrt(0.23*K) -ln(0.23*K)-1.2*K-0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty([18], dtype=np.str)\n",
    "x, y = tf.constant(x_rg), tf.constant(y_rg)\n",
    "x, n = Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x), weights =test.layers[1].get_weights())(x, x, x)\n",
    "n1, ind1 = Selection_Reconstruct(n)\n",
    "a = Out_Analytic_Set(a, n1, ind1, rgsnw=1, rgsnb=0, mode = \"SSB\")\n",
    "x, n, rgsn = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x), weights =test.layers[2].get_weights())(x, x, x)\n",
    "n2, ind2 = Selection_Reconstruct(n, ind=ind1)\n",
    "rgsnw1, rgsnb1 = rgsn_Reconstruct(rgsn)\n",
    "a = Out_Analytic_Set(a, n2, ind2, rgsnw=rgsnw1, rgsnb=rgsnb1, mode = \"OB\")\n",
    "\n",
    "# x, n = Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x), weights =test.layers[3].get_weights())(x, x, x)\n",
    "# n1, ind1 = Selection_Reconstruct(n, ind=ind2)\n",
    "# a = Out_Analytic_Set(a, n1, ind1, rgsnw=1, rgsnb=0, mode = \"SSB\")\n",
    "# x, n, rgsn = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x), weights =test.layers[4].get_weights())(x, x, x)\n",
    "# n2, ind2 = Selection_Reconstruct(n, ind=ind1)\n",
    "# rgsnw1, rgsnb1 = rgsn_Reconstruct(rgsn)\n",
    "# a = Out_Analytic_Set(a, n2, ind2, rgsnw=rgsnw1, rgsnb=rgsnb1, mode = \"OB\")\n",
    "\n",
    "# x = tf.keras.layers.Dense(1, weights =test.layers[5].get_weights())(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', '0.0287*sqrt(0.0265*vc1()0.0225*v', '', '', '', '', '',\n",
       "       '', '', '', '', '0.9497*sqrt(0.2281*vc1()0.1196*v', '', '', '',\n",
       "       '0.0203*sqrt(0.024*vc1()0.0199*vc'], dtype='<U32')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "print(x.shape)\n",
    "\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-527-0cdf587fca8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test=[i[1] for i in yim_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfpr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpr\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The area under the curves are:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 776\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "y_score = modelANN.predict(x_val)[:,0]\n",
    "y_score = np.hstack(y_score)\n",
    "# test=[i[1] for i in yim_test]\n",
    "fpr , tpr , thresholds = roc_curve ( y_val , y_score)\n",
    "roc_auc = auc(tpr,fpr )\n",
    "print(\"The area under the curves are:\")\n",
    "print(\"AUC:{0:.9f}\".format(roc_auc))\n",
    "if roc_auc<0.5:\n",
    "    a = tpr\n",
    "    tpr = fpr\n",
    "    fpr = a\n",
    "    roc_auc = 1 - roc_auc\n",
    "    print(\"AUC:{0:.9f}\".format(roc_auc))\n",
    "    \n",
    "# FalsePositiveFull, TruePositiveFull, ThresholdFull = metrics.roc_curve(y_test,Predictions)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(tpr,fpr, label='Fully supervised: AUC={0:.5f}'.format(roc_auc))\n",
    "plt.ylabel('False Positive Rate',fontsize=20)\n",
    "plt.xlabel('True Positive Rate',fontsize=20)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.legend()\n",
    "# plt.legend(bbox_to_anchor=(0.8, -0.17),ncol=2)\n",
    "\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Block\n",
    "class Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(Selection, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "#         self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540412\n",
      "0.9305041\n",
      "0.90742856\n",
      "0.8848088\n",
      "0.862639\n",
      "0.8409134\n",
      "0.8196262\n",
      "0.79877156\n",
      "0.7783437\n",
      "0.7583367\n",
      "0.73874485\n",
      "0.7195623\n",
      "0.70078325\n",
      "0.68240196\n",
      "0.66441256\n",
      "0.64680934\n",
      "0.6295866\n",
      "0.6127385\n",
      "0.59625936\n",
      "0.5801435\n",
      "0.5643853\n",
      "0.54897904\n",
      "0.5339191\n",
      "0.5191999\n",
      "0.50481594\n",
      "0.4907616\n",
      "0.47703144\n",
      "0.46361995\n",
      "0.4505217\n",
      "0.43773136\n",
      "0.4252435\n",
      "0.41305286\n",
      "0.40115413\n",
      "0.3895421\n",
      "0.3782116\n",
      "0.36715743\n",
      "0.35637453\n",
      "0.34585783\n",
      "0.33560234\n",
      "0.3256031\n",
      "0.3158552\n",
      "0.30635378\n",
      "0.29709405\n",
      "0.28807122\n",
      "0.2792806\n",
      "0.2707176\n",
      "0.26237753\n",
      "0.25425592\n",
      "0.24634825\n",
      "0.23865008\n",
      "0.23115706\n",
      "0.22386485\n",
      "0.21676919\n",
      "0.20986587\n",
      "0.20315073\n",
      "0.1966197\n",
      "0.19026873\n",
      "0.18409383\n",
      "0.1780911\n",
      "0.17225665\n",
      "0.16658668\n",
      "0.16107745\n",
      "0.15572527\n",
      "0.1505265\n",
      "0.14547755\n",
      "0.14057492\n",
      "0.13581514\n",
      "0.13119482\n",
      "0.12671058\n",
      "0.12235916\n",
      "0.11813731\n",
      "0.11404186\n",
      "0.11006968\n",
      "0.10621771\n",
      "0.102482945\n",
      "0.09886242\n"
     ]
    }
   ],
   "source": [
    "while var1.numpy()>0.1:\n",
    "    opt.minimize(loss, [var1]).numpy()\n",
    "    print(var1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,1],[2,2],[3,3]])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [4, 4],\n",
       "       [9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry Variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: m<=n\n",
    "def find_N(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    n = a[-1:].numpy()\n",
    "    n = n[0]\n",
    "    return n\n",
    "\n",
    "def Tile_reshape(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    b = a*0+1\n",
    "    a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "    return a\n",
    "def VP(m, cn): # m: order,  cn: input tensor, k: range\n",
    "    cn = tf.cast(cn, tf.float64)\n",
    "    vp = tf.math.pow(cn,m)\n",
    "    vp = tf.reduce_sum(vp, axis = -1)\n",
    "    vp = tf.expand_dims(vp, axis = -1)\n",
    "    vp = tf.tile(vp, Tile_reshape(cn))\n",
    "    return vp\n",
    " \n",
    "def VC1(cn):\n",
    "    vc = tf.reduce_sum(cn, axis = -1)\n",
    "    vc = tf.expand_dims(vc, axis=-1)\n",
    "    vc = tf.tile(vc, Tile_reshape(cn))\n",
    "    vc = tf.cast(vc, tf.float64)\n",
    "    return vc\n",
    "def VC2(cn):\n",
    "    vc = (VC1(cn)**2 - VP(2, cn))/2\n",
    "    return vc\n",
    "def VC3(cn):\n",
    "    vc1 = VC1(cn)\n",
    "    vp2 = VP(2,cn)\n",
    "    vp3 = VP(3,cn)\n",
    "    vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "    return vc\n",
    "def VC4(cn):\n",
    "    n = find_N(cn)\n",
    "#     vc = (VC3(cn)*VP(0,cn) - 3/(n-2)*VC2(cn)*VP(1,cn) + 3/(n-2)*2/(n-1)*VC1(cn)*VP(3,cn) - 3/(n-2)*2/(n-1)*VP(4,cn) )/(n-3)\n",
    "    vc = (VC3(cn)*VP(1,cn) - VC2(cn)*VP(2,cn) + VC1(cn)*VP(3,cn) - VP(4,cn) )/4\n",
    "    return vc\n",
    "\n",
    "## VCN: \n",
    "# vcn = 0\n",
    "# for i in range(N):\n",
    "#     vcn += VC(N-i-1)VP(i+1)*(-1)**i\n",
    "# vcn = vcn/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Con(n,k):\n",
    "    fc=1\n",
    "    for i in range(k):\n",
    "        fc *=(n-i)\n",
    "        fc /= (i+1)\n",
    "    return fc\n",
    "def text(cn):\n",
    "    vc = (VC2(cn)*VP(1, cn) - VC1(cn)*VP(2,cn) + VP(3,cn))/3\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "n = a[-1:].numpy()\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561.5,  561.5,  561.5,  561.5,  561.5],\n",
       "       [   5. ,    5. ,    5. ,    5. ,    5. ],\n",
       "       [3616.5, 3616.5, 3616.5, 3616.5, 3616.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = tf.constant([[1,2,3,4,5],[1,1,1,1,1],[3,4,5,6,7]])\n",
    "# cn = tf.constant([[1,2,3,4],[1,1,1,1],[3,4,5,6]])\n",
    "\n",
    "# cn.numpy()\n",
    "VC4(cn).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "fc=1\n",
    "for i in range(N):\n",
    "    fc*=(i+1)\n",
    "    \n",
    "a = 0\n",
    "for i in range(N):\n",
    "    a += fc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-887b695135f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \"\"\"\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.math.multiply(VC3(cn),VC1(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "b = a*0+1\n",
    "a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(cn, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
