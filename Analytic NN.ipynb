{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.optimize as opt\n",
    "# import sys, os, random, gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras import metrics\n",
    "# from keras.utils import np_utils\n",
    "# import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "# ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(10):\n",
    "for example in ds.take(i):\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "#         x.append(image)\n",
    "#         y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(3):\n",
    "    image, label = example[\"image\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets.Load_data import Load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg, y_rg = Load_data(\"./data/kc_house_data.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 18), (21613,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape, y_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(tf.keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQV(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(KQV, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "        wk_init = tf.random_normal_initializer()\n",
    "        wv_init = tf.random_normal_initializer()\n",
    "        \n",
    "        self.wq = tf.Variable(initial_value=wq_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wk = tf.Variable(initial_value=wk_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wv = tf.Variable(initial_value=wv_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "\n",
    "        \n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(self.units,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        q = tf.matmul(self.wq,inputs)\n",
    "        k = tf.matmul(self.wk,inputs)\n",
    "        v = tf.matmul(self.wv, inputs)\n",
    "\n",
    "        return k, q, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "#         a = tf.constant(a)\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "#         cn = tf.cast(cn, tf.float64)\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "#         vc = tf.cast(vc, tf.float64)\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "#         out_num = self.order*2\n",
    "#         v = tf.expand_dims(v, axis = -1)\n",
    "#         v = tf.tile(v, self.Tile_reshape(out_num))\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "#         print(\"vc shape:\", vc1.shape)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "#         v = tf.Variable(self.rui(shape = tf.shape(v)), dtype=tf.float32)*v\n",
    "        \n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        q = self.wq(q)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        k = self.wk(v)\n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         print(\"wk\",k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         n = tf.matmul(q,k) ##tooooooooooo slow\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##--------------------------------------------------------------------normalize----------\n",
    "#         k = tf.math.log(tf.math.abs(k+1e-10)+1)\n",
    "#         q = tf.math.log(tf.math.abs(q+1e-10)+1)\n",
    "\n",
    "#         print(\"kdiv\",tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))\n",
    "\n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "#         n = k*q\n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##-----------------------------------------------top k version------------------------------\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "##------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "#         n = k*q\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=1000, num_out=100, rank=2):\n",
    "        super(Data_Selection, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, q, k, v):\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        n = k*q\n",
    "##------------------------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "        v = tf.expand_dims(v, axis=-1)\n",
    "        v = n*v\n",
    "        v = tf.reduce_sum(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##-----------------------------------------------------\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(np.sum(x_train, axis = -1), axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "\n",
    "x_train = x_train/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (1, 18)\n",
      "vc shape: (1, 18)\n",
      "v shape: (1, 18, 7)\n",
      "wk tf.Tensor(\n",
      "[[[ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]]], shape=(1, 18, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[ 2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19]\n",
      "  [-8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18]\n",
      "  [ 2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19]\n",
      "  [ 3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19]\n",
      "  [-2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19]\n",
      "  [ 2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19]\n",
      "  [-3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[ 1.1536372e+00  8.6522788e-01  8.5080743e+02  1.4420465e+03\n",
      "    5.7681859e-01  0.0000000e+00  8.6522788e-01  8.6522788e-01\n",
      "    2.5956836e+00  5.7105042e+02  2.7975702e+02  5.7076196e+02\n",
      "    0.0000000e+00  2.8300451e+04  1.3720034e+01 -3.5294086e+01\n",
      "    6.1719586e+02  1.1536372e+03]\n",
      "  [-8.5340548e-01 -6.4005411e-01 -6.2938654e+02 -1.0667568e+03\n",
      "   -4.2670274e-01  0.0000000e+00 -6.4005411e-01 -6.4005411e-01\n",
      "   -1.9201623e+00 -4.2243570e+02 -2.0695082e+02 -4.2222235e+02\n",
      "    0.0000000e+00 -2.0935316e+04 -1.0149424e+01  2.6108873e+01\n",
      "   -4.5657193e+02 -8.5340546e+02]\n",
      "  [ 1.4279835e+00  1.0709877e+00  1.0531378e+03  1.7849794e+03\n",
      "    7.1399176e-01  0.0000000e+00  1.0709877e+00  1.0709877e+00\n",
      "    3.2129629e+00  7.0685187e+02  3.4628601e+02  7.0649487e+02\n",
      "    0.0000000e+00  3.5030578e+04  1.6982794e+01 -4.3687370e+01\n",
      "    7.6397119e+02  1.4279835e+03]\n",
      "  [-1.1096001e-02 -8.3220005e-03 -8.1833000e+00 -1.3870001e+01\n",
      "   -5.5480003e-03  0.0000000e+00 -8.3220005e-03 -8.3220005e-03\n",
      "   -2.4966002e-02 -5.4925203e+00 -2.6907802e+00 -5.4897461e+00\n",
      "    0.0000000e+00 -2.7220154e+02 -1.3196307e-01  3.3946827e-01\n",
      "   -5.9363604e+00 -1.1096001e+01]\n",
      "  [-7.7478671e-01 -5.8109003e-01 -5.7140521e+02 -9.6848340e+02\n",
      "   -3.8739336e-01  0.0000000e+00 -5.8109003e-01 -5.8109003e-01\n",
      "   -1.7432702e+00 -3.8351941e+02 -1.8788577e+02 -3.8332571e+02\n",
      "    0.0000000e+00 -1.9006680e+04 -9.2144222e+00  2.3703630e+01\n",
      "   -4.1451089e+02 -7.7478668e+02]\n",
      "  [-8.7473464e-01 -6.5605098e-01 -6.4511682e+02 -1.0934183e+03\n",
      "   -4.3736732e-01  0.0000000e+00 -6.5605098e-01 -6.5605098e-01\n",
      "   -1.9681530e+00 -4.3299365e+02 -2.1212315e+02 -4.3277496e+02\n",
      "    0.0000000e+00 -2.1458553e+04 -1.0403088e+01  2.6761414e+01\n",
      "   -4.6798303e+02 -8.7473462e+02]\n",
      "  [-1.6690795e+00 -1.2518096e+00 -1.2309462e+03 -2.0863494e+03\n",
      "   -8.3453977e-01  0.0000000e+00 -1.2518096e+00 -1.2518096e+00\n",
      "   -3.7554290e+00 -8.2619440e+02 -4.0475180e+02 -8.2577710e+02\n",
      "    0.0000000e+00 -4.0945023e+04 -1.9850113e+01  5.1063404e+01\n",
      "   -8.9295758e+02 -1.6690796e+03]]], shape=(1, 7, 18), dtype=float32)\n",
      "kdiv tf.Tensor([[35989.742 34145.016 35813.79  36438.703 35999.33  35913.438 36220.984]], shape=(1, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[3.6966380e-02 3.0038426e-02 3.2512918e-01 3.5053056e-01 2.1944409e-02\n",
      "   0.0000000e+00 3.0038426e-02 3.0038426e-02 6.1665431e-02 3.0594465e-01\n",
      "   2.7164879e-01 3.0592036e-01 0.0000000e+00 4.9394003e-01 1.2958258e-01\n",
      "   1.7306793e-01 3.0968288e-01 3.3978647e-01]\n",
      "  [3.1124566e-02 2.4955617e-02 3.2517225e-01 3.5175481e-01 1.7925721e-02\n",
      "   0.0000000e+00 2.4955617e-02 2.4955617e-02 5.4056674e-02 3.0509943e-01\n",
      "   2.6922941e-01 3.0507401e-01 0.0000000e+00 5.0186938e-01 1.2163760e-01\n",
      "   1.6645484e-01 3.0901039e-01 3.4051058e-01]\n",
      "  [4.1416258e-02 3.3991005e-02 3.2497981e-01 3.4959647e-01 2.5157360e-02\n",
      "   0.0000000e+00 3.3991005e-02 3.3991005e-02 6.7146964e-02 3.0638611e-01\n",
      "   2.7313933e-01 3.0636257e-01 0.0000000e+00 4.8855704e-01 1.3490477e-01\n",
      "   1.7740490e-01 3.1000936e-01 3.3918458e-01]\n",
      "  [1.3964046e-03 1.0487455e-03 2.8059804e-01 3.4158731e-01 7.0012844e-04\n",
      "   0.0000000e+00 1.0487455e-03 1.0487455e-03 3.1205164e-03 2.3672052e-01\n",
      "   1.6524658e-01 2.3666644e-01 0.0000000e+00 7.0994109e-01 1.5685607e-02\n",
      "   3.6985498e-02 2.4508846e-01 3.1545955e-01]\n",
      "  [2.9375188e-02 2.3457661e-02 3.2514268e-01 3.5212332e-01 1.6765820e-02\n",
      "   0.0000000e+00 2.3457661e-02 2.3457661e-02 5.1673368e-02 3.0477071e-01\n",
      "   2.6837167e-01 3.0474490e-01 0.0000000e+00 5.0450039e-01 1.1898976e-01\n",
      "   1.6421126e-01 3.0873981e-01 3.4071052e-01]\n",
      "  [3.1581409e-02 2.5348648e-02 3.2517639e-01 3.5165882e-01 1.8231904e-02\n",
      "   0.0000000e+00 2.5348648e-02 2.5348648e-02 5.4670598e-02 3.0517879e-01\n",
      "   2.6944196e-01 3.0515346e-01 0.0000000e+00 5.0120461e-01 1.2230630e-01\n",
      "   1.6701820e-01 3.0907512e-01 3.4045699e-01]\n",
      "  [4.4809200e-02 3.7049923e-02 3.2481110e-01 3.4887856e-01 2.7695838e-02\n",
      "   0.0000000e+00 3.7049923e-02 3.7049923e-02 7.1170427e-02 3.0663100e-01\n",
      "   2.7411965e-01 3.0660796e-01 0.0000000e+00 4.8472837e-01 1.3863398e-01\n",
      "   1.8040195e-01 3.1017375e-01 3.3869913e-01]]], shape=(1, 7, 18), dtype=float32)\n",
      "v shape: (1, 18, 7)\n",
      "n shape: (1, 18, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
       " array([[9.7922925e+17, 8.0966167e+17, 7.1021882e+18, 7.6290285e+18,\n",
       "         6.0524301e+17, 0.0000000e+00, 8.0966167e+17, 8.0966167e+17,\n",
       "         1.5553235e+18, 6.7042557e+18, 5.9927380e+18, 6.7037515e+18,\n",
       "         0.0000000e+00, 1.0603152e+19, 3.0297832e+18, 3.9428487e+18,\n",
       "         6.7817976e+18, 7.4061943e+18]], dtype=float32)>,\n",
       " array([[ 4.00000e+00,  3.00000e+00,  2.95000e+03,  5.00000e+03,\n",
       "          2.00000e+00,  0.00000e+00,  3.00000e+00,  3.00000e+00,\n",
       "          9.00000e+00,  1.98000e+03,  9.70000e+02,  1.97900e+03,\n",
       "          0.00000e+00,  9.81260e+04,  4.75714e+01, -1.22375e+02,\n",
       "          2.14000e+03,  4.00000e+03]], dtype=float32))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_rg[15:16]\n",
    "Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x,x,x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n",
      "(None, 18)\n",
      "(None, 18)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "## tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(18))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# print(x.shape)\n",
    "# a0=x\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "# a1 = x\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "# a2 =x\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# a3 =x\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# a4=x\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# x = tf.concat([x,a0,a1,a2,a3,a4], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "print(x.shape)\n",
    "\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.math.is_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN_Regression\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_22 (Sym (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_21 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 109\n",
      "Trainable params: 109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = np.array(x_rg)\n",
    "y_rg = np.array(y_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = x_rg.astype(np.float32)\n",
    "y_rg = y_rg.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 18)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_rg[:18000], y_rg[:18000]\n",
    "x_val, y_val = x_rg[18000:], y_rg[18000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "557/563 [============================>.] - ETA: 0s - loss: 99.8956 - accuracy: 0.0000e+00 \n",
      "Epoch 00001: val_loss improved from inf to 0.54794, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 8s 14ms/step - loss: 98.9235 - accuracy: 0.0000e+00 - val_loss: 0.5479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "557/563 [============================>.] - ETA: 0s - loss: 0.4484 - accuracy: 0.0000e+00\n",
      "Epoch 00002: val_loss improved from 0.54794 to 0.39209, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.4470 - accuracy: 0.0000e+00 - val_loss: 0.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "552/563 [============================>.] - ETA: 0s - loss: 0.3284 - accuracy: 0.0000e+00\n",
      "Epoch 00003: val_loss improved from 0.39209 to 0.26131, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 8s 15ms/step - loss: 0.3273 - accuracy: 0.0000e+00 - val_loss: 0.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "557/563 [============================>.] - ETA: 0s - loss: 0.2385 - accuracy: 0.0000e+00\n",
      "Epoch 00004: val_loss improved from 0.26131 to 0.18039, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.2380 - accuracy: 0.0000e+00 - val_loss: 0.1804 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "558/563 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.0000e+00\n",
      "Epoch 00005: val_loss improved from 0.18039 to 0.14532, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.1882 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "555/563 [============================>.] - ETA: 0s - loss: 0.1653 - accuracy: 0.0000e+00\n",
      "Epoch 00006: val_loss improved from 0.14532 to 0.13658, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 13ms/step - loss: 0.1655 - accuracy: 0.0000e+00 - val_loss: 0.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "561/563 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.0000e+00\n",
      "Epoch 00007: val_loss improved from 0.13658 to 0.13390, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.1551 - accuracy: 0.0000e+00 - val_loss: 0.1339 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "552/563 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.0000e+00\n",
      "Epoch 00008: val_loss improved from 0.13390 to 0.13171, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.1493 - accuracy: 0.0000e+00 - val_loss: 0.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.0000e+00\n",
      "Epoch 00009: val_loss improved from 0.13171 to 0.12916, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 8s 15ms/step - loss: 0.1452 - accuracy: 0.0000e+00 - val_loss: 0.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "555/563 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.0000e+00\n",
      "Epoch 00010: val_loss improved from 0.12916 to 0.12775, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.1416 - accuracy: 0.0000e+00 - val_loss: 0.1278 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "554/563 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 0.0000e+00\n",
      "Epoch 00011: val_loss did not improve from 0.12775\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1388 - accuracy: 0.0000e+00 - val_loss: 0.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.0000e+00\n",
      "Epoch 00012: val_loss improved from 0.12775 to 0.12440, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1244 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "557/563 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.0000e+00\n",
      "Epoch 00013: val_loss did not improve from 0.12440\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1350 - accuracy: 0.0000e+00 - val_loss: 0.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "563/563 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.0000e+00\n",
      "Epoch 00014: val_loss did not improve from 0.12440\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.0000e+00 - val_loss: 0.1275 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "559/563 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.0000e+00\n",
      "Epoch 00015: val_loss improved from 0.12440 to 0.12300, saving model to ./test1/ANN_Regression_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_Regression_model_/assets\n",
      "563/563 [==============================] - 7s 12ms/step - loss: 0.1324 - accuracy: 0.0000e+00 - val_loss: 0.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "559/563 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.0000e+00\n",
      "Epoch 00016: val_loss did not improve from 0.12300\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.0000e+00 - val_loss: 0.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "557/563 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.0000e+00\n",
      "Epoch 00017: val_loss did not improve from 0.12300\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.0000e+00 - val_loss: 0.1245 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "561/563 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.0000e+00\n",
      "Epoch 00018: val_loss did not improve from 0.12300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 0.1306 - accuracy: 0.0000e+00 - val_loss: 0.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f26b5425320>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelANN.fit(np.log(np.abs(x_train)+1), np.log(np.abs(y_train)+1), validation_data=(np.log(np.abs(x_val)+1), np.log(np.abs(y_val)+1)), callbacks = callbacks, shuffle=True , epochs=40, batch_size=32, verbose=1)\n",
    "# modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = modelANN.predict(np.log(np.abs(x_rg)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "# plt.hist(y_pre, histtype='step')\n",
    "# plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "plt.xlabel(\"Model Prediction\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.scatter(y_pre,np.log(np.abs(y_rg)+1))\n",
    "plt.plot([0,16],[0,16], color = 'k', linestyle='--')\n",
    "# plt.xlim([0,2.5])\n",
    "# plt.savefig(\"./plot/Regression_Scatter3.png\")\n",
    "# plt.savefig(\"./plot/DNN_Regression_Scatter1.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xUZb3H8c8XRMELYN4yEOEYZnJN0ThiXlNLUdLj9ZChVnTKLCstMktMjpHWMe167CamKAkeMy9lauoBzQsKiIodNURIDREIFBTkd/5Ya4bFsGf2bNiz5/Z9v177tWfdnnlm7dnrt57Leh5FBGZmZgCdqp0BMzOrHQ4KZmaW56BgZmZ5DgpmZpbnoGBmZnkOCmZmluegYABIGi/puk089kOSnm3vPFnLJK2U9C/tlNZnJP0gfd0nTbtze6S9ifmZIekDFUj3WElTCtZNk/TR9n6veuegUIck3SdpqaStqvT+Iem9ueWI+N+IeN8mpDM+TevkzLot0nV90+Vr0uX9M/u8V9ImP2CTpvl2egF8XdKfJO21qel1tIjYNiJe2Nx0JG0JXAhcnqa7IE37nc1Nu4z3ni/pwwXrjgVWRMQTRY45WdKDkt6UdF8L2w+T9Likf0p6QdLY3LaI+D0wQNLgzCHfBSa0ywdqIA4KdSa9WH4ICOC4qmamfbwOXNzK3enrtP8/72URsS3QC1gE/LKd00fSFu2dZjsbBcyLiEXVzkjqP4DflNj+OvADYGLhBkldgP8B/hvoAZwC/JekIZndbgCygeIRoLukYZuf9cbhoFB/PgH8BbgGGJPdkN4B/1jS7ZJWSHpY0h6Z7VdKeim9k5op6UMtvUF6/DkF6+ZIOl7SA+mq2emd9imSDpG0MLPvbpJulrRY0hJJPyrxef4AvA18vMQ+k4DBkg4usc8miYhVwG+Bobl1kt6TVi0slvQ3SV/IbOsmaVJaUntG0lcLPvt8SV+TNAd4Iy35DE/vcJdJmi3pkMz+Z6R3tSvS9xqdrn+vpPslLZf0WrbqI1tSk9RD0rVpXl+UdKGkTpm0p0v6XprfvxVUl3wUuD+Tbt807S3S5fskXZJW6ayQdJekHQv2HSvp75JelnReJq1rJE3ILOe/I5J+A/QBfp9+h76alloOy+anhb/V3RHxW+DvLWx+F9Ad+E0kHgWeAfbO7HMfcEzBcS2ta2oOCvXnE8D16c9RknYp2H4qcDGwPfAc8J+ZbY+SXPzeBUwGbpLUtYX3mETmIp3ebfUCbo+Ig9LVQ9KqhsJ62s7AbcCLQN/0uBtLfJ4AvglclN7tteRN4NKCz9IuJG0DnEZyrkgvqL8HZpPk/XDgXElHpYdcRPK5/gU4gpaD2WkkF5qewC7A7SQlnXcB5wHTJO2UvvdVwEcjYjvgAGBWmsYlwF0kf8fewA+LfIQfktwZ/wtwMMn348zM9g8CzwI7ApcBv5SkdNugdFsp/56mtzOwZZr/rEOB/sCRwNcKq4RaEhGnAwuAY9Pv0GVpGusiYmHpo4um+SpJSeBMSZ0l/SuwOzA9s9szQF9J3QvWZUsTTc9BoY5IOpDki/7biJgJPE/yT5v1PxHxSESsJQkc+TvgiLguIpZExNqI+D6wFdBSW8CtwJ6S+qfLpwNTIuLtMrK5P/Ae4PyIeCMiVkfE9FIHRMStwGLgUyV2+2+gj9qvYfA8ScuAFcCBJJ8RYD9gp4j4dkS8ndbd/5wk2AKcDFwaEUvTC9hVLaR9VUS8lJZCPg7cERF3RMS6iPgT8BhwdLrvOmCgpG4R8XJEPJWuX0Pyt35PsXOYBuBTga9HxIqImA98P/NZAF6MiJ+n7QSTgF1JAhUkQWtFK+fp1xHx15ZKVKmL07/zk8CvSQLipignL625AfgW8Bbwv8A3IuKlzPZc+j0L1mWXm56DQn0ZA9wVEa+ly5MpqEICXsm8fhPYNrcg6by0ymN5ekHsQXIHuYGIWA1MAT6e3jmfRum63qzdSC5Ea8vcP+dC4BtASyUXIuItkrvnS0olIml0WiWxUtKdJXb9XkT0JLnrX8X64Lg78J60qmdZep4uYP2F9D1A9kKTfd3Sut2BkwrSOxDYNSLeIKn7/g/g5bTaLtfg/VVAwCOSnpJ0VgvvsyPQhaRUlvMiSQknJ/99iIg305e578RSYLsW0s0q+n1KZT/riyTnZ1OUk5ei0vN2I0lJaUtgAPBVSdmqoVz6ywrWZZebnoNCnZDUjeQu9WBJr0h6BfgSMEQbNqYVO/5DJBeak4Ht0wvicpILT0smAaNJqk/ejIiHyszqSyR39G1qZE3voJ8DPldit1+T3NWdUCKd69MqiW0jotVSRUQsAL4IXJme45eAv0VEz8zPdhGRu7N/maQ6J2e3lpLNvH6JpJ47m942ETExff8/RsQRJHfw80hKJUTEKxHx6Yh4D/AZ4CfK9PhKvcb6EkVOH5KG83LMAfYsc99isp+/D+vr+98Ats5se3fBcYW9x54DJKkXm2Yg8Nf0fK6LiGdJqu2y34H3A/Mj4p8F62Zv4ns2JAeF+vEx4B2ShrOh6c/7SYrJnyjj+O2AtSTVNFtI+hZJw1yL0iCwjqQ6orCU8CpJHXZLHiG5cE6UtI2krpJGlJE/SEoKXy2Rp7UkdfpfKzO9sqQB6e8kPVMeAVakjcXd0vrpgZL2S3f/LfB1SdunF7DPt5L8dcCxko5K0+qaNrr2lrSLpFFp28JbwEqSc46kkyTlgs9SkovouoJ8v5Pm5z8lbSdpd+DL6XuW4w6SdojN8U1JW0saQNL2kGtjmgUcLeldkt4NnFtw3AbfobRq8u5sftLzFJnlzmkb2BZAp/Rc5tqhngD6K+mWKiUdLEaSBL6cg4HC0mNL65qag0L9GENSv7sgvYt8JSJeAX4EjC7jzvyPJD19/kpSzF9Ny1UfWdeSNEYWXmTGA5PS6pCTsxvSC9WxwHtJGhMXklSRtCoiZpBclEu5gSTotLfLSQLSFiQXk6HA30juxn9BUtUG8G2Sz/Q3kovYVJILeovSOu1RJFVQi0nO+fkk/3udSC7ifyfpbnkw8Nn00P2AhyWtJGnj+WKRZxPOIbkrf4GkUXUy8KsyP/Pvgb0kbWqVDyS9hZ4D7iGpkrsrXf8bkjvw+SQN5lMKjvsOcGH6Hco1Xv83G7aH7AY8mFk+naSq76ck3bJXsb5k9TxwFkkbzz/TfE0j+dvlnJa+BwBpoF+Zdk21lDzJjhUj6RPA2Ig4sNp5qVWSPgucGhHt3l22Iyh5wGvviCi8k2/tuL4kgbHLJrQflUp3BvD5iHhC0i+AmyLij+2Q7rHA6RGRfVByGvDLiLhjc9NvJA4K1iJJWwP3Aj+JiGurnZ9aIWlXkmqPh0i6Ud4O/CgiflDVjHWwSgUFqz5XH9lG0j75i0nqfSdXOTu1ZkuSKogVJEHzd8BPqpojs3bkkoKZmeW5pGBmZnm1PmBXSTvuuGP07du32tkwM6srM2fOfC0idmppW10Hhb59+/LYY49VOxtmZnVF0ovFtrn6yMzM8hwUzMwsz0HBzMzy6rpNwcw235o1a1i4cCGrV6+udlasnXXt2pXevXvTpUuxqUo25qBg1uQWLlzIdtttR9++fVk//47Vu4hgyZIlLFy4kH79+pV9nKuPzJrc6tWr2WGHHRwQGowkdthhhzaXAB0UzMwBoUFtyt/VQcHMzPLcpmBmGxgx8V4WLVvVbun16tmNGeMOa7f0WpN7qHXHHTeaabZN+2yu+fPnM3LkSObOnctjjz3Gtddey1VXtTSld+LSSy/lggsuyC8fcMABPPjgg0X3rxQHBat72YtYR1+AGtGiZauYP/GY1ncsU99xt7dbWrVg7dq1bLFF2y6dw4YNY9iwYSX3KQwK1QgI4OojawC5i9j8ice06x2udYz58+ez1157ccYZZ7DnnnsyevRo7r77bkaMGEH//v155JFkYrTXX3+dj33sYwwePJjhw4czZ04y0+aSJUs48sgjGTBgAJ/61KfIjvx83XXXsf/++zN06FA+85nP8M4775TMy7bbbsuXvvQlBgwYwOGHH87ixYsBOOSQQzj33HMZNmwYV155JTNnzuTggw9m33335aijjuLll5PJAGfOnMmQIUMYMmQIP/7xj/Pp3nfffYwcORKAlStXcuaZZzJo0CAGDx7MtGnTGDduHKtWrWLo0KGMHj06nxdIehGdf/75DBw4kEGDBjFlypR8mocccggnnngie+21F6NHj6Y9Rr12UDCzqnvuuef4yle+wrx585g3bx6TJ09m+vTpfO973+PSSy8F4KKLLuIDH/gAc+bM4dJLL+UTn0imJr/44os58MADeeqppzj++ONZsGABAM888wxTpkxhxowZzJo1i86dO3P99deXzMcbb7zBsGHDeOqppzj44IO5+OKL89vefvttHnvsMb7whS9wzjnnMHXqVGbOnMlZZ53FN77xDQDOPPNMfvjDHzJ79uyi73HJJZfQo0cPnnzySebMmcNhhx3GxIkT6datG7NmzdoojzfffDOzZs1i9uzZ3H333Zx//vn5IPTEE0/wgx/8gKeffpoXXniBGTNmtPHMb8zVR2ZWdf369WPQoEEA+bt0SQwaNIj58+cDMH36dKZNmwbAYYcdxpIlS/jnP//JAw88wM033wzAMcccw/bbbw/APffcw8yZM9lvv/0AWLVqFTvvvHPJfHTq1IlTTkmmFP/4xz/OCSeckN+WW//ss88yd+5cjjjiCADeeecddt11V5YtW8ayZcs46KCDADj99NO58847N3qPu+++mxtvvDG/nMtvMdOnT+e0006jc+fO7LLLLhx88ME8+uijdO/enf3335/evXsDMHToUObPn8+BB27e7LkOCtaQcu0MbmOoD1tttVX+dadOnfLLnTp1Yu3aTZvtMyIYM2YM3/nOdzY5X9kundtss00+3QEDBvDQQw9tsO+yZcs2+X02Vfa8de7ceZPPVZarj6wh5doZ3MbQOD70oQ/lq1buu+8+dtxxR7p3785BBx3E5MnJrLF33nknS5cuBeDwww9n6tSp/OMf/wCSNokXXyw6YjQA69atY+rUqQBMnjy5xbvu973vfSxevDgfFNasWcNTTz1Fz5496dmzJ9OnTwcoWlV1xBFHbNDekMtvly5dWLNmTYufe8qUKbzzzjssXryYBx54gP3337/k59gcLimY2QZ69ezWrj2GevXs1i7pjB8/nrPOOovBgwez9dZbM2nSJCBpazjttNMYMGAABxxwAH369AFg7733ZsKECRx55JGsW7eOLl268OMf/5jdd9+96Htss802PPLII0yYMIGdd94536ibteWWWzJ16lS+8IUvsHz5ctauXcu5557LgAED+PWvf81ZZ52FJI488sgW3+PCCy/k7LPPZuDAgXTu3JmLLrqIE044gbFjxzJ48GD22WefDQLK8ccfz0MPPcSQIUOQxGWXXca73/1u5s2btzmns6i6nqN52LBh4Ul2rO+42/NdKHOvC39bcc888wzvf//7q52NmrDtttuycuXKamejXbX095U0MyJa7CPr6iNrKLm73Pa6OzVrNq4+sobiRmXbHI1WStgUDgrWGK4YBMuT/un06ANferK6+TGrUw4KVrey3U5ZvgDGL082jO9R3YyZ1TEHBatbG4zRM76qWTFrGG5oNjOzPJcUzGxD2faZ9tBKG8+yZcuYPHkyn/vc59rvPVtwyy23sOeee7L33ntX9H3qnYOC1Z0N2hLagxupN5Rtn2kPrbTxLFu2jJ/85CdlB4WIICLo1KltFR233HILI0eOdFBohYOC1Z22jPeffTq36DhIbqSuqnHjxvH8888zdOhQDj30UObMmcPSpUtZs2YNEyZMYNSoUcyfP5+jjjqKD37wg8ycOZM77riDa6+9luuuu46ddtqJ3XbbjX333ZfzzjuP559/nrPPPpvFixez9dZb8/Of/5zXX3+dW2+9lfvvv58JEyYwbdo09thjj2p/9JrkoGANLRsEGm2yl0YxceJE5s6dy6xZs1i7di1vvvkm3bt357XXXmP48OEcd9xxAPzf//0fkyZNYvjw4Tz66KNMmzaN2bNns2bNGvbZZx/23XdfAMaOHcvPfvYz+vfvz8MPP8znPvc57r33Xo477jhGjhzJiSeeWM2PW/McFMysZkQEF1xwAQ888ACdOnVi0aJFvPrqqwDsvvvuDB8+HIAZM2YwatQounbtSteuXTn22GOB5OGzBx98kJNOOimf5ltvvdXxH6SOOSiYWc24/vrrWbx4MTNnzqRLly707duX1atXA+uHri5l3bp19OzZk1mzZlU6qw2rol1SJX1J0lOS5kq6QVJXSf0kPSzpOUlTJG2Z7rtVuvxcur1vJfNmZrVhu+22Y8WKFQAsX76cnXfemS5duvDnP/+56FDXI0aM4Pe//z2rV69m5cqV3HbbbQB0796dfv36cdNNNwFJySM3C1r2fay4ipUUJPUCvgDsHRGrJP0WOBU4GrgiIm6U9DPgk8BP099LI+K9kk4FvgucUqn8WZ26YhDzuy5IHlZzT6HK6NGnfRvce/QpuXmHHXZgxIgRDBw4kP3224958+YxaNAghg0bxl577dXiMfvttx/HHXccgwcPZpdddmHQoEH06JHk+frrr+ezn/0sEyZMYM2aNZx66qkMGTKEU089lU9/+tNcddVVTJ061Q3NRVS6+mgLoJukNcDWwMvAYcC/p9snkfx7/xQYxfrnUqcCP5KkqOexva39LV9A39WTk95HVwxaf/EqduHJdDedvtWOgIfRblUVAm1ukpxS5s6du8Hyeeedx/jx43nzzTc56KCD8g3N/fr14w9/+MNGx48YMYKnn366fTLcwCoWFCJikaTvAQuAVcBdwExgWUTk5oxbCPRKX/cCXkqPXStpObAD8Fo2XUljgbFAfjINa1LlXLwy3U17u7tpQxk7dixPP/00q1evZsyYMeyzzz7VzlJDqGT10fYkd//9gGXATcBHNjfdiLgauBqSSXY2Nz2rD7kH1uZ3bb+ZvKy+lVO6sLarZEPzh4G/RcTiiFgD3AyMAHpKygWj3sCi9PUiYDeAdHsPYEkF82d1JPvAmudMaH+upW1Mm/J3rWRQWAAMl7S1JAGHA08DfwZyT4+MAX6Xvr41XSbdfq/bE6y99R13OyMm3lvtbNSUrl27smTJEgeGBhMRLFmyhK5du7bpuEq2KTwsaSrwOLAWeIKk2ud24EZJE9J1v0wP+SXwG0nPAa+T9FSyJtfe4xzl5m3eaLyjJta7d28WLlzI4sWLq50Va2ddu3ald+/ebTqmor2PIuIi4KKC1S8A+7ew72rgpML11tzaMs5Rm7T3oG91rEuXLvTr16/a2bAa4fkUzMwsz0HBzMzyHBTMzCzPQcHMzPIcFMzMLM9DZ1vt8LSYZlXnoGC1w9NimlWdq4/MzCzPQcHMzPIcFMzMLM9BwZpObhwlD4xntjEHBWs6uaG3Fy1bVeWcmNUe9z6yptWrZ7dkxNT0tedpMHNQsCaWDQK54GDW7BwUrOP5ITWzmuWgYB2v0g+p9eizPt0mn0DHrK0cFKzxuORhtsnc+8jMzPIcFMzMLM/VR1b7ChumzaxiHBSs9mUbps2solx9ZDWr77jb80NSmFnHcEnBatb8icckL8ZXNRtmTcUlBTMzy3NQMDOzPFcfmWUVPg3tB+GsyTgomGVlg4DnibYm5OojMzPLc1AwM7M8BwUzM8tzUDAzszw3NFvleDIds7pTVlCQdAwwAOiaWxcR365UpqxBVHoyHTNrd61WH0n6GXAKcA4g4CRg9wrny8zMqqCcNoUDIuITwNKIuBj4V2DPymbLrGP16tmNvuNuZ8TEe6udFbOqKqf6aFX6+01J7wGWALtWLkvWVIrMp7wwdqR3B86zPGPcYUAyMqtZMysnKNwmqSdwOfA4EMAvKporax5FGp8PfOuq9aOkmlmHKScoXBYRbwHTJN1G0ti8upzE02DyC2AgSTA5C3gWmAL0BeYDJ0fEUkkCrgSOBt4EzoiIx9v0acwqxT2prEmU06bwUO5FRLwVEcuz61pxJfCHiNgLGAI8A4wD7omI/sA96TLAR4H+6c9Y4KdlvodZ5eV6Uo1fvj44mDWgoiUFSe8GegHdJH2ApOcRQHdg69YSltQDOAg4AyAi3gbeljQKOCTdbRJwH/A1YBRwbUQE8BdJPSXtGhEvt/1jWT0aMfFeFi1LmrBqYsa1Iu0dZo2sVPXRUSQX9N7Af2XWrwAuKCPtfsBi4NeShgAzgS8Cu2Qu9K8Au6SvewEvZY5fmK7bIChIGktSkqBPH/+jNpJFy1bVVjuCq4isCRUNChExCZgk6d8iYtompr0PcE5EPCzpStZXFeXeIyRFWxKNiKuBqwGGDRvWpmOtAxTWvZtZXWm1oTkipm3iE80LgYUR8XC6PJUkKLyaqxaStCvwj3T7ImC3zPG903VWT7JPMWe5KsasLrQaFNInmrcGDiXpSXQi8Ehrx0XEK5JekvS+iHgWOBx4Ov0ZA0xMf/8uPeRW4POSbgQ+CCx3e0IDcVWMWV0op0vqARExWNKciLhY0veBO8tM/xzgeklbAi8AZ5L0ePqtpE8CLwInp/veQdId9TmSLqlntuFzmJlZO6joE80RMQsY1sKmw1vYN4Czy0nXzMwqw080m5lZXjkNzZekL/NPNKcPsJmZWYMp9fDaCSW2ERE3VyZLZtWTGy21V89u+UHyzJpJqZLCsenvnYEDgNyYwocCDwIOCtZwPFqqNbtSD6+dCSDpLmDvXPfQ9NmCazokd2Zm1qHKaWjereB5gVcBP31kDS1XjZR77aokaxblBIV7JP0RuCFdPgW4u3JZsprUZENHZ4NAyaqkJjsv1vjK6X30eUnHk4x4CnB1RPxPZbNlNSc7fEVuuIp2khsdtSZGRm2rCp4Xs2oop6RAGgQcCKwiam50VLMmVs4kO2Zm1iTKKimYVUKHVxt5pFazVpV6eO2eiDhc0ncj4msdmSlrDh1ebeRGYLNWlSop7CrpAOC4dDhrZTdGxOMVzZmZmXW4UkHhW8A32Xg6TkgGxXPHbTOzBlPqieapwFRJ38wMimdmZg2srFFSJR3H+ucU7ouI2yqbLbMa5gZra2DlTMf5HWB/4Pp01RclHRARF1Q0Z2a1yg3W1sDK6ZJ6DDA0ItYBSJoEPAE4KFhT8HDa1kzKfU6hJ/B6+trP8ltT8XDa1kzKCQrfAZ6Q9GeSbqkHAeMqmiszM6uKchqab5B0H7BfuuprEfFKRXNlZmZVUe6AeC8Dt1Y4L1aPskNHQ6u9cXJDWwD1OSqqWYPz2Ee2ebJDR5fBI6Ka1TaPkmpmZnklg4KkzpLmdVRmzMysukpWH0XEO5KeldQnIhaU2tfMMlpqa/FDb1YHymlT2B54StIjwBu5lRFxXMVyZVbvCttaPFWn1YlygsI3K54La1jZ3kbgHkdmta6c5xTul7Q70D8i7pa0NdC58lmzRuDeRmb1pZwB8T4NjAXeBewB9AJ+Bhxe2ayZ1RmPnmoNoJzqo7NJRkl9GCAi/k/SzhXNlVk9ckOyNYBygsJbEfG2lMzGKWkLkpnXzJpKbrTUwnUeOdUaSTlB4X5JFwDdJB0BfA74fWWzZVZ7Wrr4e+RUazTlPNE8DlgMPAl8BrgDuLCSmTIzs+oop/fRunRinYdJqo2ejQhXH5mZNaByeh8dQ9Lb6HmS+RT6SfpMRNxZ6cxZjXIvG7OGVU6bwveBQyPiOQBJewC3Aw4Kzcq9bNquMJD6HFqNKicorMgFhNQLwIpy30BSZ+AxYFFEjJTUD7gR2AGYCZye9m7aCrgW2BdYApwSEfPLfR+zmpYNAh7ywmpY0YZmSSdIOgF4TNIdks6QNIak59GjbXiPLwLPZJa/C1wREe8FlgKfTNd/Eliarr8i3c/MzDpQqd5Hx6Y/XYFXgYOBQ0h6IpU1gI2k3sAxwC/SZQGHAVPTXSYBH0tfj0qXSbcfrtzDEWZm1iGKVh9FxJntkP4PgK8C26XLOwDLImJturyQZNgM0t8vpe+9VtLydP/XsglKGksy7AZ9+riR08ysPZXT+6gfcA7QN7t/a0NnSxoJ/CMiZko6ZPOyuV5EXA1cDTBs2DB3jTUza0flNDTfAvySpC1hXRvSHgEcJ+lokiqo7sCVQE9JW6Slhd7AonT/RcBuwMJ0KI0eJA3OVmeyw2V7qGyz+lJOUFgdEVe1NeGI+DrwdYC0pHBeRIyWdBNwIkkPpDHA79JDbk2XH0q33+uH5OqTh8s2q1/lBIUrJV0E3AW8lVsZEY9v4nt+DbhR0gTgCZJSCOnv30h6DngdOHUT0zczs01UTlAYBJxO0msoV30U6XJZIuI+4L709QskQ3EX7rMaOKncNM3MrP2VExROAv4lIt6udGbM6lWuHcVDaVu9K2eU1LlAz0pnxKye5dpRsvNRm9WjckoKPYF5kh5lwzaFkl1SzawIj4NkNaycoHBRxXNh1kw8DpLVsHLmU7i/IzJiZmbVV84TzStYPyfzlkAX4I2I6F7JjFn9yTa2mll9KqekkBu3KDeg3ShgeCUzZTXiikGwfEHyumAyncKnlmeMO8wPrZk1gHLaFPLSJ4xvSR9mG1eZLFnNWL4Axi9vcVM2AHjyerPGUU710QmZxU7AMGB1xXJkVkd69exG33G3u8rMGkY5JYVjM6/XAvNJqpDMmp4fVLNGU06bQnvMq2BmZnWgaFCQ9K0Sx0VEXFKB/JiZWRWVKim80cK6bUjmUt4BcFAwM2swpabj/H7utaTtgC8CZ5LMg/D9YseZmVn9KtmmIOldwJeB0cAkYJ+IWNoRGbP64R44Zo2jVJvC5cAJJPMhD4qIlR2WK6sr7oGzXi5A5l773Fi9KVVS+ArJqKgXAt9IHmYGQCQNzR7mogl5KIvSskHAD/VZPSrVplDOXAvWZDyUhVlja9MwF2bWzjy3gtUYBwXbUIlB8KwCPLeC1RgHBdtQiUHwzKzxud3AzMzyHBTMzCzPQcHMzPIcFMzMLM8NzeYeRxWSHf6jrCeb3T3VaoCDgrnHUYXkAkHZTza7e6rVAFcfmZlZnoOCmZnlOSiYmVme2xTMapEbna1KHBSalXsc1TY3OmCmu20AAAteSURBVFuVOCg0K/c4MrMWuE3BzMzyXFKwkrIzrXlqSbPG55KClZSbaW3RslXVzkrdyj3ZPGLivdXOilmrXFKwsmSHbLC2afOTzWZVVLGgIGk34FpgFyCAqyPiSknvAqYAfYH5wMkRsVSSgCuBo4E3gTMi4vFK5c/axlVHZs2hktVHa4GvRMTewHDgbEl7A+OAeyKiP3BPugzwUaB/+jMW+GkF82ZmZi2oWEkhIl4GXk5fr5D0DNALGAUcku42CbgP+Fq6/tqICOAvknpK2jVNxzpQrnEZcHWRWZPpkDYFSX2BDwAPA7tkLvSvkFQvQRIwXsoctjBdt0FQkDSWpCRBnz5+6KoSco3LZtZ8Kt77SNK2wDTg3Ij4Z3ZbWiqItqQXEVdHxLCIGLbTTju1Y07NzKyiQUFSF5KAcH1E3JyuflXSrun2XYF/pOsXAbtlDu+drjMzsw5SsaCQ9ib6JfBMRPxXZtOtwJj09Rjgd5n1n1BiOLDc7QnWSHLdev3MgtWySrYpjABOB56UNCtddwEwEfitpE8CLwInp9vuIOmO+hxJl9QzK5g3sw6X7dbrZxasVlWy99F0QEU2H97C/gGcXan8WOuyQ1qYWXPyE82W515HZuaxj8yqwOMhWa1yScGsCjwektUqlxTMzCzPQcHMzPIcFMzMLM9BwczM8tzQ3EyuGATLFySve3gwQTPbmINCM1m+AMYv32i1H1qrnuyMdp7IyGqBg4L5obUqKqtrao8+ML5Hy+u/9GSFcmbNykHBrNYVu/C3FCjMNpMbms3MLM9BwczM8lx9ZFYDcg3OuddtbnTO9izLcruDtZGDQiMq7Hrqi0LN2+y5For0LHO7g7WVg0Ijyl4gfFFobtmeS75BsDI4KJjVq8ILfkuyQcA3CFYGBwWzeuW7fqsABwWzZuGqJCuDg0KjK1LFkBvaAvDwFjWmYkNfuCrJyuCg0CiKDXZX5G7QQ1vUrg6Zlc2lBivCQaFRFOuSWMCD3xngUoMV5aDQZFxCMLNSPMyFWY3KtS2MmHhvtbNiTcQlhSbhaqP6k2tbGDHx3s0bAsOsDRwUmoSrjepXNgjkAkSHBAcPl9KUHBTqmafXbDoV6ZlUrCdStvPCFYPcW6lJOCjUszJ7HJmVlL3AF178W9rHvZUamoNCPXAx3jqKv1tNz0GhHmziqKd+arnxZf/GORVvb/CDbw3NQaHelDMyZsqNy40rOxRG4d+4ok9CQ/HqpiwHi7rloFBv/I9mUDvdUot9H93uULf88JqZmeW5pGDWoArblGqidFE4l7SrmWqOg0Kt2oxnEPz0cnNrqb0h186Q/W50WJAo/C5nu1G7mqnmOChUW+GdU07hP08buIG5ubV0sS8MFBVvjM4q9TxNtuNE4XqXIKrCQaEaSt05mVVAOaWCqpQiil34/QR11dRUUJD0EeBKoDPwi4iYWOUsbZ4KlAJyWvoHdrWRlStXcsi9njHusHwJs0NLEcWUeso6t63YQ51+2HOz1ExQkNQZ+DFwBLAQeFTSrRHxdNUyVerLVeyCn1XBUkDuH7hwBE1XG1k5ig2y127a8DxNq0oFiGJjM7X0sKeDRVlqJigA+wPPRcQLAJJuBEYBlQkKbb2oF9Z7ttO4Q6WK7C09rZqT+weuiR4lVtcKv0MtlSJaK5lu9D2s1AW3WLrF1hcGp5aCSOH+LaVVTkBpkKCjiKh2HgCQdCLwkYj4VLp8OvDBiPh8wX5jgbHp4kBgbodmtDbtCLxW7UzUAJ+HhM+Dz0FOsfOwe0Ts1NIBtVRSKEtEXA1cDSDpsYgYVuUsVZ3PQ8LnIeHz4HOQsynnoZaeaF4E7JZZ7p2uMzOzDlJLQeFRoL+kfpK2BE4Fbq1ynszMmkrNVB9FxFpJnwf+SNIl9VcR8VQrh11d+ZzVBZ+HhM9DwufB5yCnzeehZhqazcys+mqp+sjMzKrMQcHMzPLqJihI+pWkf0iam1l3kqSnJK2T1BTdz4qch8slzZM0R9L/SOpZzTx2hCLn4ZL0HMySdJek91Qzj5XW0jnIbPuKpJC0YzXy1pGKfBfGS1qUfhdmSTq6mnnsCMW+D5LOSa8PT0m6rLV06iYoANcAHylYNxc4AXigw3NTPdew8Xn4EzAwIgYDfwW+3tGZqoJr2Pg8XB4RgyNiKHAb8K0Oz1XHuoaNzwGSdgOOBFp5ZL9hXEML5wG4IiKGpj93dHCequEaCs6DpENJRoYYEhEDgO+1lkjdBIWIeAB4vWDdMxHxbJWyVBVFzsNdEbE2XfwLyTMeDa3IefhnZnEboKF7UbR0DlJXAF+lwT9/Tonz0FSKnIfPAhMj4q10n3+0lk7dBAUr21nAndXORLVI+k9JLwGjafySwkYkjQIWRcTsauelBnw+rU78laTtq52ZKtkT+JCkhyXdL2m/1g5wUGggkr4BrAWur3ZeqiUivhERu5Gcg8+3tn8jkbQ1cAFNGAxb8FNgD2Ao8DLw/epmp2q2AN4FDAfOB34rSaUOcFBoEJLOAEYCo8MPn0ASFP6t2pnoYHsA/YDZkuaTVCM+LundVc1VFUTEqxHxTkSsA35OMgpzM1oI3ByJR4B1JIPkFeWg0ADSyYm+ChwXEW9WOz/VIql/ZnEUMK9aeamGiHgyInaOiL4R0ZfkgrBPRLxS5ax1OEm7ZhaPp3lHU74FOBRA0p7AlrQyemzNDHPRGkk3AIcAO0paCFxE0qjyQ2An4HZJsyLiqOrlsvKKnIevA1sBf0pLhn+JiP+oWiY7QJHzcLSk95HcDb0INN05iIhfVjdXHa/Id+EQSUNJGtvnA5+pWgY7SJHz8CvgV2k31beBMa3VJHiYCzMzy3P1kZmZ5TkomJlZnoOCmZnlOSiYmVmeg4KZmeXVTZdUs7aStANwT7r4buAdYHG6vH9EvN2O79UT+PeI+El7pWlWDe6Sak1B0nhgZUS0OkqkpC0yAwyWm35f4LaIGLhJGTSrEa4+sqYi6dOSHpU0W9K0dLwgJF0j6WeSHgYuk7SHpL9IelLSBEkrM2mcn6YxR9LF6eqJwB7p2P2XF7znNpJuT99zrqRT0vXzJV2Wvscjkt6brj82HcDsCUl3S9olXb+tpF+n+8+R9G/p+iMlPSTpcUk3Sdq24ifSGpaDgjWbmyNiv4gYAjwDfDKzrTdwQER8GbgSuDIiBpEMFwEkF2CgP8lYOkOBfSUdBIwDnk/H7j+/4D0/Avw9IoakJYk/ZLYtT9/jR8AP0nXTgeER8QHgRpIhTAC+mds/nTvj3nQSnQuBD0fEPsBjwJc3/fRYs3ObgjWbgZImAD2BbYE/ZrbdFBHvpK//FfhY+noy6ycnOTL9eSJd3pYkSJSa0OZJ4PuSvktSxfS/mW03ZH5fkb7uDUxJx+/ZEvhbuv7DwKm5AyNiqaSRwN7AjHSIky2Bh0rkxawkBwVrNtcAH4uI2enIsodktr1RxvECvhMR/73ByqRNoUUR8VdJ+wBHAxMk3RMR385tzu6a/v4h8F8RcaukQ4DxreTnTxFxWhl5N2uVq4+s2WwHvCypC8lEPMX8hfVDb5+aWf9H4Kxcvb2kXpJ2BlakaW8knSv6zYi4Drgc2Cez+ZTM79wdfg9gUfp6TGbfPwFnZ9LdPs3niEx7xDbpaJhmm8RBwZrNN4GHgRmUHlr7XODLkuYA7wWWQzL1KUl10kOSngSmAttFxBKSKpy5hQ3NwCDgEUmzSEaunJDZtn36Hl8EvpSuGw/cJGkmGw5zPCHdf66k2cChEbEYOAO4IU3nIWCvss+GWQF3STVrQdoraVVEhKRTgdMiYlQ7v8d8YFhElBzf3qwjuU3BrGX7Aj9Kpy5cRjL3tVnDc0nBzMzy3KZgZmZ5DgpmZpbnoGBmZnkOCmZmluegYGZmef8PT2pvLqmWZVAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Analytic NN - Regression(input(,18))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\", bins = 100)\n",
    "plt.hist(np.log(np.abs(y_rg)+1), histtype='step',  label = \"target\", bins = 100)\n",
    "plt.legend()\n",
    "# plt.savefig(\"./plot/Regression_Hist3.png\")\n",
    "# plt.savefig(\"./plot/DNN_Regression_Hist1.png\")\n",
    "\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b544ada0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f26b5492be0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./pre_train_models/ANN_Lite/assets\n"
     ]
    }
   ],
   "source": [
    "modelANN.save(\"./pre_train_models/ANN_Lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28)\n",
      "(None, 28, 28)\n",
      "(None, 784)\n",
      "(None, 784)\n",
      "(None, 784)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "x = tf.math.log(tf.math.abs(x)+1)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "# x = Data_Selection(node = 100, num_out=20,rank=tf.rank(x))(x,x,x)\n",
    "# print(x.shape)\n",
    "\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# c = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# c = tf.squeeze(c, axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "# print(x.shape)\n",
    "# a = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([x,b], axis=-1)\n",
    "# c = tf.concat([x,c], axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# c = Operator_Basis(num_out=1,rank=tf.rank(c))(c, c, c)\n",
    "# print(\"a:\",a.shape)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "\n",
    "# x = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([b,c], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(b))(b, b, b)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "print(x.shape)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_93 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Abs_3 (TensorFlo [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorF [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Log_4 (TensorFlo [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_139 (Sy (None, 784)               70        \n",
      "_________________________________________________________________\n",
      "operator__basis_71 (Operator (None, 784)               20        \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,940\n",
      "Trainable params: 7,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [ for i in y_train]\n",
    "y2 = []\n",
    "for i in y_train:\n",
    "    vec = np.zeros([10])    \n",
    "    vec[i]=1\n",
    "    y2.append(vec)\n",
    "y2=np.array(y2)    \n",
    "y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[40000:]\n",
    "y_val = y_train[40000:]\n",
    "x_train = x_train[:40000]\n",
    "y_train = y_train[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.1097 - accuracy: 0.6270\n",
      "Epoch 00001: val_loss improved from inf to 1.90848, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 2.1097 - accuracy: 0.6270 - val_loss: 1.9085 - val_accuracy: 0.7388\n",
      "Epoch 2/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7684 - accuracy: 0.8091\n",
      "Epoch 00002: val_loss improved from 1.90848 to 1.69493, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.7684 - accuracy: 0.8092 - val_loss: 1.6949 - val_accuracy: 0.8493\n",
      "Epoch 3/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6715 - accuracy: 0.8586\n",
      "Epoch 00003: val_loss improved from 1.69493 to 1.63996, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6715 - accuracy: 0.8586 - val_loss: 1.6400 - val_accuracy: 0.8724\n",
      "Epoch 4/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6304 - accuracy: 0.8763\n",
      "Epoch 00004: val_loss improved from 1.63996 to 1.61236, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6304 - accuracy: 0.8763 - val_loss: 1.6124 - val_accuracy: 0.8851\n",
      "Epoch 5/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.6071 - accuracy: 0.8875\n",
      "Epoch 00005: val_loss improved from 1.61236 to 1.59547, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6071 - accuracy: 0.8874 - val_loss: 1.5955 - val_accuracy: 0.8927\n",
      "Epoch 6/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5919 - accuracy: 0.8943\n",
      "Epoch 00006: val_loss improved from 1.59547 to 1.58405, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5920 - accuracy: 0.8942 - val_loss: 1.5841 - val_accuracy: 0.8971\n",
      "Epoch 7/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5813 - accuracy: 0.8990\n",
      "Epoch 00007: val_loss improved from 1.58405 to 1.57602, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5813 - accuracy: 0.8989 - val_loss: 1.5760 - val_accuracy: 0.9004\n",
      "Epoch 8/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5733 - accuracy: 0.9031\n",
      "Epoch 00008: val_loss improved from 1.57602 to 1.57004, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5732 - accuracy: 0.9032 - val_loss: 1.5700 - val_accuracy: 0.9035\n",
      "Epoch 9/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5670 - accuracy: 0.9069\n",
      "Epoch 00009: val_loss improved from 1.57004 to 1.56534, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5671 - accuracy: 0.9068 - val_loss: 1.5653 - val_accuracy: 0.9063\n",
      "Epoch 10/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5650 - accuracy: 0.9094\n",
      "Epoch 00010: val_loss improved from 1.56534 to 1.56158, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.5650 - accuracy: 0.9094 - val_loss: 1.5616 - val_accuracy: 0.9079\n",
      "Epoch 11/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5579 - accuracy: 0.9120\n",
      "Epoch 00011: val_loss improved from 1.56158 to 1.55885, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5580 - accuracy: 0.9119 - val_loss: 1.5588 - val_accuracy: 0.9089\n",
      "Epoch 12/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.9142\n",
      "Epoch 00012: val_loss improved from 1.55885 to 1.55651, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5547 - accuracy: 0.9142 - val_loss: 1.5565 - val_accuracy: 0.9104\n",
      "Epoch 13/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5519 - accuracy: 0.9160\n",
      "Epoch 00013: val_loss improved from 1.55651 to 1.55473, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5519 - accuracy: 0.9160 - val_loss: 1.5547 - val_accuracy: 0.9117\n",
      "Epoch 14/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5495 - accuracy: 0.9178\n",
      "Epoch 00014: val_loss improved from 1.55473 to 1.55299, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5495 - accuracy: 0.9178 - val_loss: 1.5530 - val_accuracy: 0.9127\n",
      "Epoch 15/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5474 - accuracy: 0.9187\n",
      "Epoch 00015: val_loss improved from 1.55299 to 1.55178, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5474 - accuracy: 0.9187 - val_loss: 1.5518 - val_accuracy: 0.9135\n",
      "Epoch 16/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5457 - accuracy: 0.9204\n",
      "Epoch 00016: val_loss improved from 1.55178 to 1.55039, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5457 - accuracy: 0.9203 - val_loss: 1.5504 - val_accuracy: 0.9137\n",
      "Epoch 17/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5440 - accuracy: 0.9213\n",
      "Epoch 00017: val_loss improved from 1.55039 to 1.54942, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5440 - accuracy: 0.9214 - val_loss: 1.5494 - val_accuracy: 0.9147\n",
      "Epoch 18/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5425 - accuracy: 0.9229\n",
      "Epoch 00018: val_loss improved from 1.54942 to 1.54879, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5426 - accuracy: 0.9229 - val_loss: 1.5488 - val_accuracy: 0.9150\n",
      "Epoch 19/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5412 - accuracy: 0.9241\n",
      "Epoch 00019: val_loss improved from 1.54879 to 1.54786, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5413 - accuracy: 0.9240 - val_loss: 1.5479 - val_accuracy: 0.9166\n",
      "Epoch 20/400\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5400 - accuracy: 0.9254\n",
      "Epoch 00020: val_loss improved from 1.54786 to 1.54713, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5400 - accuracy: 0.9254 - val_loss: 1.5471 - val_accuracy: 0.9170\n",
      "Epoch 21/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5389 - accuracy: 0.9264\n",
      "Epoch 00021: val_loss improved from 1.54713 to 1.54643, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5389 - accuracy: 0.9265 - val_loss: 1.5464 - val_accuracy: 0.9176\n",
      "Epoch 22/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.9269\n",
      "Epoch 00022: val_loss improved from 1.54643 to 1.54609, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5378 - accuracy: 0.9269 - val_loss: 1.5461 - val_accuracy: 0.9168\n",
      "Epoch 23/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5369 - accuracy: 0.9280\n",
      "Epoch 00023: val_loss improved from 1.54609 to 1.54529, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5368 - accuracy: 0.9281 - val_loss: 1.5453 - val_accuracy: 0.9184\n",
      "Epoch 24/400\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.9286\n",
      "Epoch 00024: val_loss improved from 1.54529 to 1.54492, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5359 - accuracy: 0.9285 - val_loss: 1.5449 - val_accuracy: 0.9184\n",
      "Epoch 25/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.9294\n",
      "Epoch 00025: val_loss improved from 1.54492 to 1.54452, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5350 - accuracy: 0.9294 - val_loss: 1.5445 - val_accuracy: 0.9186\n",
      "Epoch 26/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.9303\n",
      "Epoch 00026: val_loss improved from 1.54452 to 1.54404, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5342 - accuracy: 0.9303 - val_loss: 1.5440 - val_accuracy: 0.9184\n",
      "Epoch 27/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5334 - accuracy: 0.9308\n",
      "Epoch 00027: val_loss improved from 1.54404 to 1.54375, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5334 - accuracy: 0.9308 - val_loss: 1.5438 - val_accuracy: 0.9191\n",
      "Epoch 28/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5327 - accuracy: 0.9316\n",
      "Epoch 00028: val_loss improved from 1.54375 to 1.54369, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5327 - accuracy: 0.9316 - val_loss: 1.5437 - val_accuracy: 0.9191\n",
      "Epoch 29/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.9323\n",
      "Epoch 00029: val_loss improved from 1.54369 to 1.54306, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5320 - accuracy: 0.9323 - val_loss: 1.5431 - val_accuracy: 0.9191\n",
      "Epoch 30/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.9330\n",
      "Epoch 00030: val_loss did not improve from 1.54306\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5313 - accuracy: 0.9331 - val_loss: 1.5432 - val_accuracy: 0.9191\n",
      "Epoch 31/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.9335\n",
      "Epoch 00031: val_loss improved from 1.54306 to 1.54289, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5307 - accuracy: 0.9335 - val_loss: 1.5429 - val_accuracy: 0.9187\n",
      "Epoch 32/400\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.9344\n",
      "Epoch 00032: val_loss improved from 1.54289 to 1.54288, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5300 - accuracy: 0.9344 - val_loss: 1.5429 - val_accuracy: 0.9189\n",
      "Epoch 33/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.9345\n",
      "Epoch 00033: val_loss improved from 1.54288 to 1.54226, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5296 - accuracy: 0.9345 - val_loss: 1.5423 - val_accuracy: 0.9194\n",
      "Epoch 34/400\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.9349\n",
      "Epoch 00034: val_loss did not improve from 1.54226\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5290 - accuracy: 0.9349 - val_loss: 1.5427 - val_accuracy: 0.9191\n",
      "Epoch 35/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.9356\n",
      "Epoch 00035: val_loss improved from 1.54226 to 1.54202, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5285 - accuracy: 0.9356 - val_loss: 1.5420 - val_accuracy: 0.9192\n",
      "Epoch 36/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.9361\n",
      "Epoch 00036: val_loss improved from 1.54202 to 1.54188, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5280 - accuracy: 0.9361 - val_loss: 1.5419 - val_accuracy: 0.9196\n",
      "Epoch 37/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5275 - accuracy: 0.9366\n",
      "Epoch 00037: val_loss did not improve from 1.54188\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5275 - accuracy: 0.9366 - val_loss: 1.5421 - val_accuracy: 0.9193\n",
      "Epoch 38/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.9370\n",
      "Epoch 00038: val_loss improved from 1.54188 to 1.54163, saving model to ./test1/ANN_model_\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./test1/ANN_model_/assets\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5271 - accuracy: 0.9370 - val_loss: 1.5416 - val_accuracy: 0.9197\n",
      "Epoch 39/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.9372\n",
      "Epoch 00039: val_loss did not improve from 1.54163\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5266 - accuracy: 0.9372 - val_loss: 1.5421 - val_accuracy: 0.9194\n",
      "Epoch 40/400\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5261 - accuracy: 0.9380\n",
      "Epoch 00040: val_loss did not improve from 1.54163\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5262 - accuracy: 0.9379 - val_loss: 1.5417 - val_accuracy: 0.9201\n",
      "Epoch 41/400\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5258 - accuracy: 0.9380\n",
      "Epoch 00041: val_loss did not improve from 1.54163\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5258 - accuracy: 0.9379 - val_loss: 1.5416 - val_accuracy: 0.9197\n",
      "Epoch 00041: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5d672fb70>"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelANN.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks = callbacks, shuffle=True , epochs=10, batch_size=32)\n",
    "# modelANN.fit(x_train, y2 , callbacks = callbacks, shuffle=True , epochs=400, batch_size=32, verbose=1)\n",
    "# modelANN.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[for i in y_pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = [j for i in y_pre for j in range(10) if i[j]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.00000000e+00, 6.99999833e+00, 1.26924266e-22, ...,\n",
       "       5.00000000e+00, 5.99999714e+00, 8.00000000e+00])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.22881704e-29, 4.33907548e-33, ...,\n",
       "        1.00000000e+00, 2.84216566e-24, 3.79430916e-14],\n",
       "       [9.28732970e-26, 7.56170243e-33, 1.88351688e-37, ...,\n",
       "        9.99999881e-01, 4.03849002e-21, 6.14584650e-08],\n",
       "       [1.00000000e+00, 1.04838766e-36, 6.37808476e-21, ...,\n",
       "        1.40937411e-18, 1.34531557e-12, 2.05731644e-20],\n",
       "       ...,\n",
       "       [1.06471102e-20, 1.83538311e-24, 5.42189415e-37, ...,\n",
       "        6.64631997e-20, 5.24529808e-10, 9.85660874e-17],\n",
       "       [3.12992410e-10, 9.96973659e-27, 1.20822297e-13, ...,\n",
       "        2.65224969e-19, 1.09845135e-17, 2.95451079e-20],\n",
       "       [5.35354205e-09, 2.00367073e-22, 1.56277877e-13, ...,\n",
       "        2.91524362e-16, 1.00000000e+00, 2.24257448e-08]], dtype=float32)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = modelANN.predict(x_val)\n",
    "basis = np.linspace(0,9,10)\n",
    "y_pre = np.sum(basis*(y_pre**2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pre = modelANN.predict(x_val)\n",
    "basis = np.linspace(0,9,10)\n",
    "y_pre = np.sum(basis*(y_pre**2), axis=-1)\n",
    "plt.title(\"Analytic NN - Classification(input(28,28))\")\n",
    "plt.xlabel(\"Target space\")\n",
    "plt.ylabel(\"Number of data\")\n",
    "plt.hist(y_pre, histtype='step', label = \"model prediction\", bins = 50)\n",
    "plt.hist(y_val, histtype='step',  label = \"target\", bins = 50, color='r')\n",
    "plt.legend()\n",
    "plt.savefig(\"./plot/Classification_Hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d6933550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7ff5d692e160>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./pre_train_models/ANN_Number_Classification/assets\n"
     ]
    }
   ],
   "source": [
    "modelANN.save(\"./pre_train_models/ANN_Number_Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Analytic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis_Reconstruct(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2, weights = [[],[],[],[]]):\n",
    "        super(Symmetry_Set_Basis_Reconstruct, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node, weights = [weights[0], weights[1]])\n",
    "        self.wk = tf.keras.layers.Dense(node, weights = [weights[2], weights[3]])\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "        return v, n\n",
    "        \n",
    "class Operator_Basis_Reconstruct(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2, weights = [[],[],[],[],[],[]]):\n",
    "        super(Operator_Basis_Reconstruct, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node, weights = [weights[0], weights[1]])\n",
    "        self.wk = tf.keras.layers.Dense(node, weights = [weights[2], weights[3]])\n",
    "        self.alpha = tf.keras.layers.Dense(1, weights = [weights[4], weights[5]])\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "        return v, n, self.alpha.weights\n",
    "        \n",
    "\n",
    "def Selection_Reconstruct(n, r = 0.01, ind=[False]):\n",
    "    n = tf.reduce_mean(n,axis=0)\n",
    "#     n = tf.reduce_sum(n, axis=0)\n",
    "    sl1 = tf.reduce_max(tf.math.abs(n), axis = -1)\n",
    "    sl1 = sl1.numpy()\n",
    "    node = len(sl1)\n",
    "    dl = np.max(np.abs(sl1))*r\n",
    "    index = np.linspace(0, node-1, node)[np.abs(sl1)>dl] \n",
    "\n",
    "    index = (set(ind))&(set(index)) if np.any(ind) else index\n",
    "\n",
    "    index = np.array(list(index))\n",
    "    index = index.astype(np.int32)\n",
    "    n = n.numpy()\n",
    "    n = np.take(n, index, axis=0)\n",
    "#     n = np.sum(n, axis = 0)\n",
    "    return n, index\n",
    "def rgsn_Reconstruct(rgsn):\n",
    "    return tf.squeeze(rgsn[0]).numpy(), tf.squeeze(rgsn[1]).numpy() # weight, bias\n",
    "\n",
    "def Out_Analytic_Set(x, n, index, rgsnw=1, rgsnb=0, mode = \"SSB\", digits=2):\n",
    "    n = np.around(n, digits)\n",
    "    rgsnw = np.around(rgsnw, digits)\n",
    "    rgsnb = np.around(rgsnb, digits)\n",
    "    n = n.astype(np.str)\n",
    "    SSB_keys = [\"vc1\", \"vc2\", \"vc3\", \"vc4\", \"vp2\", \"vp3\", \"vp4\"]\n",
    "    OB_keys = [\"sqrt\", \"ln\", \"rgsn\"]\n",
    "    x0 = np.empty(x.shape, dtype=np.str) \n",
    "    x0 = x0.astype(np.dtype('<U1000'))\n",
    "    for i in range(len(x)):\n",
    "        if i in index:\n",
    "            \n",
    "            w = np.take(n, np.linspace(0, len(index)-1, len(index))[index==i].astype(np.int32), axis=0)\n",
    "            w = w.astype(np.str)\n",
    "            w = np.squeeze(w)\n",
    "            if mode == \"SSB\":\n",
    "                for j in range(len(SSB_keys)):\n",
    "                    x0[i] =x0[i] +\"+\"+ w[j]+\"*\"+SSB_keys[j]+\"(\"+x[i]+\")\"\n",
    "            if mode == \"OB\":\n",
    "                for j in range(len(OB_keys)):\n",
    "                    if OB_keys[j] == \"rgsn\":\n",
    "                        x0[i] = x0[i]+\"+\" + w[j]+\"*\"+str(rgsnw)+\"*\"+\"(\"+x[i]+\")\"+str(rgsnb)\n",
    "                    else:\n",
    "                        x0[i] = x0[i]+\"+\" + w[j]+\"*\"+OB_keys[j]+\"(\"+x[i]+\")\"\n",
    "    return x0\n",
    "                    \n",
    "# def Dense_Reconstruct(w, b, ind):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.layers[3].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = tf.keras.models.load_model(\"./pre_train_models/ANN\")\n",
    "test = tf.keras.models.load_model(\"./pre_train_models/ANN_Lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f273b4e0a20>,\n",
       " <tensorflow.python.keras.saving.saved_model.load.Symmetry_Set_Basis at 0x7f273b4e09b0>,\n",
       " <tensorflow.python.keras.saving.saved_model.load.Operator_Basis at 0x7f273b4e0ac8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f273b4d20f0>]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Symmetry_Set_Basis_Reconstruct at 0x7f28a846e8d0>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x), weights =test.layers[1].get_weights() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '',\n",
       "       '+-0.03*sqrt(+0.03*vc1()+0.03*vc2()+0.03*vc3()+0.03*vc4()+0.03*vp2()+-0.03*vp3()+0.03*vp4())+-0.03*ln(+0.03*vc1()+0.03*vc2()+0.03*vc3()+0.03*vc4()+0.03*vp2()+-0.03*vp3()+0.03*vp4())+-0.03*1.15*(+0.03*vc1()+0.03*vc2()+0.03*vc3()+0.03*vc4()+0.03*vp2()+-0.03*vp3()+0.03*vp4())-0.04',\n",
       "       '', '', '', '', '', '', '', '', '',\n",
       "       '+-0.95*sqrt(+0.23*vc1()+0.23*vc2()+0.23*vc3()+0.23*vc4()+0.23*vp2()+-0.23*vp3()+0.23*vp4())+-0.95*ln(+0.23*vc1()+0.23*vc2()+0.23*vc3()+0.23*vc4()+0.23*vp2()+-0.23*vp3()+0.23*vp4())+-0.95*1.15*(+0.23*vc1()+0.23*vc2()+0.23*vc3()+0.23*vc4()+0.23*vp2()+-0.23*vp3()+0.23*vp4())-0.04',\n",
       "       '', '', '',\n",
       "       '+-0.02*sqrt(+0.02*vc1()+0.02*vc2()+0.02*vc3()+0.02*vc4()+0.02*vp2()+-0.02*vp3()+0.02*vp4())+-0.02*ln(+0.02*vc1()+0.02*vc2()+0.02*vc3()+0.02*vc4()+0.02*vp2()+-0.02*vp3()+0.02*vp4())+-0.02*1.15*(+0.02*vc1()+0.02*vc2()+0.02*vc3()+0.02*vc4()+0.02*vp2()+-0.02*vp3()+0.02*vp4())-0.04'],\n",
       "      dtype='<U1000')"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def: K = vc1+vc2+vc3+vc4+vp2-vp3+vp4\n",
    "-sqrt(0.23*K) -ln(0.23*K)-1.2*K-0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty([18], dtype=np.str)\n",
    "x, y = tf.constant(x_rg), tf.constant(y_rg)\n",
    "x, n = Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x), weights =test.layers[1].get_weights())(x, x, x)\n",
    "n1, ind1 = Selection_Reconstruct(n)\n",
    "a = Out_Analytic_Set(a, n1, ind1, rgsnw=1, rgsnb=0, mode = \"SSB\")\n",
    "x, n, rgsn = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x), weights =test.layers[2].get_weights())(x, x, x)\n",
    "n2, ind2 = Selection_Reconstruct(n, ind=ind1)\n",
    "rgsnw1, rgsnb1 = rgsn_Reconstruct(rgsn)\n",
    "a = Out_Analytic_Set(a, n2, ind2, rgsnw=rgsnw1, rgsnb=rgsnb1, mode = \"OB\")\n",
    "\n",
    "# x, n = Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x), weights =test.layers[3].get_weights())(x, x, x)\n",
    "# n1, ind1 = Selection_Reconstruct(n, ind=ind2)\n",
    "# a = Out_Analytic_Set(a, n1, ind1, rgsnw=1, rgsnb=0, mode = \"SSB\")\n",
    "# x, n, rgsn = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x), weights =test.layers[4].get_weights())(x, x, x)\n",
    "# n2, ind2 = Selection_Reconstruct(n, ind=ind1)\n",
    "# rgsnw1, rgsnb1 = rgsn_Reconstruct(rgsn)\n",
    "# a = Out_Analytic_Set(a, n2, ind2, rgsnw=rgsnw1, rgsnb=rgsnb1, mode = \"OB\")\n",
    "\n",
    "# x = tf.keras.layers.Dense(1, weights =test.layers[5].get_weights())(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', '0.0287*sqrt(0.0265*vc1()0.0225*v', '', '', '', '', '',\n",
       "       '', '', '', '', '0.9497*sqrt(0.2281*vc1()0.1196*v', '', '', '',\n",
       "       '0.0203*sqrt(0.024*vc1()0.0199*vc'], dtype='<U32')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Symmetry_Set_Basis_Reconstruct(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Operator_Basis_Reconstruct(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "print(x.shape)\n",
    "\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelANN.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-527-0cdf587fca8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test=[i[1] for i in yim_test]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfpr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpr\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The area under the curves are:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 776\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "y_score = modelANN.predict(x_val)[:,0]\n",
    "y_score = np.hstack(y_score)\n",
    "# test=[i[1] for i in yim_test]\n",
    "fpr , tpr , thresholds = roc_curve ( y_val , y_score)\n",
    "roc_auc = auc(tpr,fpr )\n",
    "print(\"The area under the curves are:\")\n",
    "print(\"AUC:{0:.9f}\".format(roc_auc))\n",
    "if roc_auc<0.5:\n",
    "    a = tpr\n",
    "    tpr = fpr\n",
    "    fpr = a\n",
    "    roc_auc = 1 - roc_auc\n",
    "    print(\"AUC:{0:.9f}\".format(roc_auc))\n",
    "    \n",
    "# FalsePositiveFull, TruePositiveFull, ThresholdFull = metrics.roc_curve(y_test,Predictions)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(tpr,fpr, label='Fully supervised: AUC={0:.5f}'.format(roc_auc))\n",
    "plt.ylabel('False Positive Rate',fontsize=20)\n",
    "plt.xlabel('True Positive Rate',fontsize=20)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.legend()\n",
    "# plt.legend(bbox_to_anchor=(0.8, -0.17),ncol=2)\n",
    "\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Block\n",
    "class Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(Selection, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "#         self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540412\n",
      "0.9305041\n",
      "0.90742856\n",
      "0.8848088\n",
      "0.862639\n",
      "0.8409134\n",
      "0.8196262\n",
      "0.79877156\n",
      "0.7783437\n",
      "0.7583367\n",
      "0.73874485\n",
      "0.7195623\n",
      "0.70078325\n",
      "0.68240196\n",
      "0.66441256\n",
      "0.64680934\n",
      "0.6295866\n",
      "0.6127385\n",
      "0.59625936\n",
      "0.5801435\n",
      "0.5643853\n",
      "0.54897904\n",
      "0.5339191\n",
      "0.5191999\n",
      "0.50481594\n",
      "0.4907616\n",
      "0.47703144\n",
      "0.46361995\n",
      "0.4505217\n",
      "0.43773136\n",
      "0.4252435\n",
      "0.41305286\n",
      "0.40115413\n",
      "0.3895421\n",
      "0.3782116\n",
      "0.36715743\n",
      "0.35637453\n",
      "0.34585783\n",
      "0.33560234\n",
      "0.3256031\n",
      "0.3158552\n",
      "0.30635378\n",
      "0.29709405\n",
      "0.28807122\n",
      "0.2792806\n",
      "0.2707176\n",
      "0.26237753\n",
      "0.25425592\n",
      "0.24634825\n",
      "0.23865008\n",
      "0.23115706\n",
      "0.22386485\n",
      "0.21676919\n",
      "0.20986587\n",
      "0.20315073\n",
      "0.1966197\n",
      "0.19026873\n",
      "0.18409383\n",
      "0.1780911\n",
      "0.17225665\n",
      "0.16658668\n",
      "0.16107745\n",
      "0.15572527\n",
      "0.1505265\n",
      "0.14547755\n",
      "0.14057492\n",
      "0.13581514\n",
      "0.13119482\n",
      "0.12671058\n",
      "0.12235916\n",
      "0.11813731\n",
      "0.11404186\n",
      "0.11006968\n",
      "0.10621771\n",
      "0.102482945\n",
      "0.09886242\n"
     ]
    }
   ],
   "source": [
    "while var1.numpy()>0.1:\n",
    "    opt.minimize(loss, [var1]).numpy()\n",
    "    print(var1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,1],[2,2],[3,3]])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [4, 4],\n",
       "       [9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry Variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: m<=n\n",
    "def find_N(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    n = a[-1:].numpy()\n",
    "    n = n[0]\n",
    "    return n\n",
    "\n",
    "def Tile_reshape(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    b = a*0+1\n",
    "    a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "    return a\n",
    "def VP(m, cn): # m: order,  cn: input tensor, k: range\n",
    "    cn = tf.cast(cn, tf.float64)\n",
    "    vp = tf.math.pow(cn,m)\n",
    "    vp = tf.reduce_sum(vp, axis = -1)\n",
    "    vp = tf.expand_dims(vp, axis = -1)\n",
    "    vp = tf.tile(vp, Tile_reshape(cn))\n",
    "    return vp\n",
    " \n",
    "def VC1(cn):\n",
    "    vc = tf.reduce_sum(cn, axis = -1)\n",
    "    vc = tf.expand_dims(vc, axis=-1)\n",
    "    vc = tf.tile(vc, Tile_reshape(cn))\n",
    "    vc = tf.cast(vc, tf.float64)\n",
    "    return vc\n",
    "def VC2(cn):\n",
    "    vc = (VC1(cn)**2 - VP(2, cn))/2\n",
    "    return vc\n",
    "def VC3(cn):\n",
    "    vc1 = VC1(cn)\n",
    "    vp2 = VP(2,cn)\n",
    "    vp3 = VP(3,cn)\n",
    "    vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "    return vc\n",
    "def VC4(cn):\n",
    "    n = find_N(cn)\n",
    "#     vc = (VC3(cn)*VP(0,cn) - 3/(n-2)*VC2(cn)*VP(1,cn) + 3/(n-2)*2/(n-1)*VC1(cn)*VP(3,cn) - 3/(n-2)*2/(n-1)*VP(4,cn) )/(n-3)\n",
    "    vc = (VC3(cn)*VP(1,cn) - VC2(cn)*VP(2,cn) + VC1(cn)*VP(3,cn) - VP(4,cn) )/4\n",
    "    return vc\n",
    "\n",
    "## VCN: \n",
    "# vcn = 0\n",
    "# for i in range(N):\n",
    "#     vcn += VC(N-i-1)VP(i+1)*(-1)**i\n",
    "# vcn = vcn/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Con(n,k):\n",
    "    fc=1\n",
    "    for i in range(k):\n",
    "        fc *=(n-i)\n",
    "        fc /= (i+1)\n",
    "    return fc\n",
    "def text(cn):\n",
    "    vc = (VC2(cn)*VP(1, cn) - VC1(cn)*VP(2,cn) + VP(3,cn))/3\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "n = a[-1:].numpy()\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561.5,  561.5,  561.5,  561.5,  561.5],\n",
       "       [   5. ,    5. ,    5. ,    5. ,    5. ],\n",
       "       [3616.5, 3616.5, 3616.5, 3616.5, 3616.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = tf.constant([[1,2,3,4,5],[1,1,1,1,1],[3,4,5,6,7]])\n",
    "# cn = tf.constant([[1,2,3,4],[1,1,1,1],[3,4,5,6]])\n",
    "\n",
    "# cn.numpy()\n",
    "VC4(cn).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "fc=1\n",
    "for i in range(N):\n",
    "    fc*=(i+1)\n",
    "    \n",
    "a = 0\n",
    "for i in range(N):\n",
    "    a += fc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-887b695135f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \"\"\"\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.math.multiply(VC3(cn),VC1(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "b = a*0+1\n",
    "a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(cn, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
