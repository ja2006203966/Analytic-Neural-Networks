{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.optimize as opt\n",
    "# import sys, os, random, gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.models import *\n",
    "# from keras.layers import *\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "from keras import metrics\n",
    "# from keras.utils import np_utils\n",
    "# import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "\n",
    "# Build your input pipeline\n",
    "# ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(10):\n",
    "for example in ds.take(i):\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "#         x.append(image)\n",
    "#         y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds.take(3):\n",
    "    image, label = example[\"image\"], example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PandasArray>\n",
       "[7129300520, 6414100192, 5631500400, 2487200875, 1954400510, 7237550310,\n",
       " 1321400060, 2008000270, 2414600126, 3793500160,\n",
       " ...\n",
       " 7852140040, 9834201367, 3448900210, 7936000429, 2997800021,  263000018,\n",
       " 6600060120, 1523300141,  291310100, 1523300157]\n",
       "Length: 21613, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"id\"].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date     price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000  221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000  538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000  180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000  604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000  510000.0         3       2.00   \n",
       "...           ...              ...       ...       ...        ...   \n",
       "21608   263000018  20140521T000000  360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000  400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000  402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000  400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000  325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view  ...  grade  \\\n",
       "0             1180      5650     1.0           0     0  ...      7   \n",
       "1             2570      7242     2.0           0     0  ...      7   \n",
       "2              770     10000     1.0           0     0  ...      6   \n",
       "3             1960      5000     1.0           0     0  ...      7   \n",
       "4             1680      8080     1.0           0     0  ...      8   \n",
       "...            ...       ...     ...         ...   ...  ...    ...   \n",
       "21608         1530      1131     3.0           0     0  ...      8   \n",
       "21609         2310      5813     2.0           0     0  ...      8   \n",
       "21610         1020      1350     2.0           0     0  ...      7   \n",
       "21611         1600      2388     2.0           0     0  ...      8   \n",
       "21612         1020      1076     2.0           0     0  ...      7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "...        ...            ...         ...  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_ALIASES',\n",
       " '_AXIS_IALIASES',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_NAMES',\n",
       " '_AXIS_NUMBERS',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_add_numeric_operations',\n",
       " '_add_series_or_dataframe_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_aggregate',\n",
       " '_aggregate_multiple_funcs',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_box_col_values',\n",
       " '_box_item_values',\n",
       " '_builtin_table',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_combine_frame',\n",
       " '_combine_match_index',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_dict_from',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_create_indexer',\n",
       " '_cython_table',\n",
       " '_deprecations',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_from_arrays',\n",
       " '_from_axes',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_cython_func',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_iget_item_cache',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_internal_get_values',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_builtin_func',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_datelike_mixed_type',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_numeric_mixed_type',\n",
       " '_is_view',\n",
       " '_ix',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_needs_reindex_multi',\n",
       " '_obj_with_exclusions',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_selected_obj',\n",
       " '_selection',\n",
       " '_selection_list',\n",
       " '_selection_name',\n",
       " '_series',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_setup_axes',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_try_aggregate_string_function',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " '_xs',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'condition',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'date',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'floordiv',\n",
       " 'floors',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'grade',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'id',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'lat',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'long',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'price',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'sqft_living',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot',\n",
       " 'sqft_lot15',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tshift',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'waterfront',\n",
       " 'where',\n",
       " 'xs',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rg = x_rg[:,2]\n",
    "x_rg = x_rg[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 18), (21613,))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rg.shape, y_rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(tf.keras.losses.Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KQV(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=128):\n",
    "        super(KQV, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "        wk_init = tf.random_normal_initializer()\n",
    "        wv_init = tf.random_normal_initializer()\n",
    "        \n",
    "        self.wq = tf.Variable(initial_value=wq_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wk = tf.Variable(initial_value=wk_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "        self.wv = tf.Variable(initial_value=wv_init(shape=(self.units, input_shape[-2] ), dtype='float32'), trainable=True)\n",
    "\n",
    "        \n",
    "#         b_init = tf.zeros_initializer()\n",
    "#         self.b = tf.Variable(initial_value=b_init(shape=(self.units,), dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "        q = tf.matmul(self.wq,inputs)\n",
    "        k = tf.matmul(self.wk,inputs)\n",
    "        v = tf.matmul(self.wv, inputs)\n",
    "\n",
    "        return k, q, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetry_Set_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=7, num_out=1, rank=2):\n",
    "        super(Symmetry_Set_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "        self.rui = tf.random_uniform_initializer(minval=-10, maxval=10)\n",
    "    \n",
    "    def Tile_reshape(self, cn):\n",
    "        a = cn.shape\n",
    "#         a = tf.constant(a)\n",
    "        b = tf.zeros(tf.rank(cn))+1\n",
    "        b = tf.cast(b,tf.int32)\n",
    "        a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1], tf.int32)], -1)\n",
    "        return a\n",
    "    def VP(self, m, cn): # m: order,  cn: input tensor, k: range\n",
    "#         cn = tf.cast(cn, tf.float64)\n",
    "        vp = tf.math.pow(cn,m)\n",
    "        vp = tf.reduce_sum(vp, axis = -1)\n",
    "        vp = tf.expand_dims(vp, axis = -1)\n",
    "        vp = tf.tile(vp, self.Tile_reshape(cn))\n",
    "        return vp\n",
    "    \n",
    "    def VC1(self, cn):\n",
    "        \n",
    "        vc = tf.reduce_sum(cn, axis = -1)\n",
    "        vc = tf.expand_dims(vc, axis=-1)\n",
    "        vc = tf.tile(vc, self.Tile_reshape(cn))\n",
    "#         vc = tf.cast(vc, tf.float64)\n",
    "        return vc\n",
    "    def VC2(self, cn):\n",
    "        vc = (self.VC1(cn)**2 - self.VP(2, cn))/2\n",
    "        return vc\n",
    "    def VC3(self, cn):\n",
    "        vc1 = self.VC1(cn)\n",
    "        vp2 = self.VP(2,cn)\n",
    "        vp3 = self.VP(3,cn)\n",
    "        vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "        return vc\n",
    "    def VC4(self, cn):\n",
    "        vc = (self.VC3(cn)*self.VP(1,cn) - self.VC2(cn)*self.VP(2,cn) + self.VC1(cn)*self.VP(3,cn) - self.VP(4,cn) )/4\n",
    "        return vc\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "#         out_num = self.order*2\n",
    "#         v = tf.expand_dims(v, axis = -1)\n",
    "#         v = tf.tile(v, self.Tile_reshape(out_num))\n",
    "        vc1 = self.VC1(v)\n",
    "        vc2 = self.VC2(v)\n",
    "        vc3 = self.VC3(v)\n",
    "        vc4 = self.VC4(v)\n",
    "        vp2 = self.VP(2,v)\n",
    "        vp3 = self.VP(3,v)\n",
    "        vp4 = self.VP(4,v)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"vc shape:\", vc1.shape)\n",
    "##--------------------------------------------------------\n",
    "        vc2 = tf.math.pow(tf.math.abs(vc2),1/2)*tf.math.sign(vc2)\n",
    "        vc3 = tf.math.pow(tf.math.abs(vc3),1/3)*tf.math.sign(vc3)\n",
    "        vc4 = tf.math.pow(tf.math.abs(vc4),1/4)*tf.math.sign(vc4)\n",
    "        vp2 = tf.math.pow(tf.math.abs(vp2),1/2)*tf.math.sign(vp2)\n",
    "        vp3 = tf.math.pow(tf.math.abs(vp3),1/3)*tf.math.sign(vp3)\n",
    "        vp4 = tf.math.pow(tf.math.abs(vp4),1/4)*tf.math.sign(vp4)\n",
    "\n",
    "\n",
    "##----------------------------------------------------------\n",
    "\n",
    "\n",
    "        vc1 = tf.expand_dims(vc1, axis=-1)\n",
    "        vc2 = tf.expand_dims(vc2, axis=-1)\n",
    "        vc3 = tf.expand_dims(vc3, axis=-1)\n",
    "        vc4 = tf.expand_dims(vc4, axis=-1)\n",
    "        vp2 = tf.expand_dims(vp2, axis=-1)\n",
    "        vp3 = tf.expand_dims(vp3, axis=-1)\n",
    "        vp4 = tf.expand_dims(vp4, axis=-1)\n",
    "\n",
    "        v = tf.concat([vc1, vc2, vc3, vc4, vp2, vp3, vp4], axis =-1)\n",
    "        print(\"v shape:\", v.shape)\n",
    "#         v = tf.Variable(self.rui(shape = tf.shape(v)), dtype=tf.float32)*v\n",
    "        \n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        q = self.wq(q)\n",
    "#         print(\"q shape:\", q.shape)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "\n",
    "        k = self.wk(v)\n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         print(\"wk\",k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "#         print(\"k shape:\", k.shape)\n",
    "#         n = tf.matmul(q,k) ##tooooooooooo slow\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##--------------------------------------------------------------------normalize----------\n",
    "#         k = tf.math.log(tf.math.abs(k+1e-10)+1)\n",
    "#         q = tf.math.log(tf.math.abs(q+1e-10)+1)\n",
    "\n",
    "#         print(\"kdiv\",tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))\n",
    "\n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2) ,axis=-1))+1e-10, axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2) ,axis=-1))+1e-10, axis=-1)\n",
    "#         print(\"k\",k)\n",
    "#         print(\"q\",q)\n",
    "##-----------------------------------------------------------------------------------------\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "#         n = k*q\n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"v shape:\", v.shape)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##-----------------------------------------------top k version------------------------------\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "##------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator_Basis(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=3, num_out=1, rank=2):\n",
    "        super(Operator_Basis, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.alpha = tf.keras.layers.Dense(1)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    \n",
    "    def call(self, q, k, v):\n",
    "        sqrt = tf.math.sqrt(tf.math.abs(v)+1e-10)\n",
    "        ln = tf.math.log(tf.math.abs(v)+1)\n",
    "#         exp = tf.math.exp(v)\n",
    "        rgsn = self.alpha(tf.expand_dims(v, axis=-1))\n",
    "        \n",
    "        sqrt= tf.expand_dims(sqrt, axis=-1)\n",
    "        ln = tf.expand_dims(ln, axis=-1)\n",
    "#         exp = tf.expand_dims(exp, axis=-1)\n",
    "\n",
    "#         v = tf.concat([sqrt, ln, exp, rgsn], axis =-1)\n",
    "        v = tf.concat([sqrt, ln, rgsn], axis =-1)\n",
    "\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "        k = self.wk(v)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "    \n",
    "\n",
    "#         n = k*q\n",
    "        n = tf.math.multiply_no_nan(k,q)\n",
    "\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         print(\"n shape:\", n.shape)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "        n = tf.transpose(n, perm=self.p) \n",
    "#         print(\"n shape:\", n.shape)\n",
    "\n",
    "\n",
    "#         v = tf.reduce_max(v, axis=-2)\n",
    "#         print(\"v shape:\", v.shape)\n",
    "\n",
    "##--------------------------------------------------sum all v*n version ------------------------------------------\n",
    "        v = tf.math.multiply_no_nan(n,v)\n",
    "#         v = v*n\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "        v = tf.reduce_sum(v, axis=-1)\n",
    "\n",
    "##----------------------------------------------------------------------------------------------\n",
    "#         v = tf.reduce_sum(v, axis=-2)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, node=1000, num_out=100, rank=2):\n",
    "        super(Data_Selection, self).__init__()\n",
    "        self.node = node\n",
    "        self.wq = tf.keras.layers.Dense(node)\n",
    "        self.wq2 = tf.keras.layers.Dense(node)\n",
    "        self.wk = tf.keras.layers.Dense(node)\n",
    "        self.num_out = num_out\n",
    "        self.p = [[0,2,1],[0,1,3,2], [0,1,2,4,3], [0,1,2,3,5,4]][rank-2]\n",
    "    def call(self, q, k, v):\n",
    "        q = tf.expand_dims(q, axis=-1)\n",
    "        q = self.wq(q)\n",
    "        q = tf.transpose(q, perm=self.p) \n",
    "#         print(\"q shape:\", q.shape)\n",
    "        k = tf.expand_dims(k, axis=-1)\n",
    "        k = self.wk(k)\n",
    "        k = tf.transpose(k, perm=self.p) \n",
    "        k = k/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(k,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        q = q/tf.expand_dims(tf.math.sqrt(tf.reduce_sum(tf.math.pow(q,2)+1e-10 ,axis=-1)), axis=-1)\n",
    "        n = k*q\n",
    "##------------------------------------------------------------\n",
    "        n = tf.transpose(n, perm=self.p)\n",
    "        print(\"n shape:\", n.shape)\n",
    "        v = tf.expand_dims(v, axis=-1)\n",
    "        v = n*v\n",
    "        v = tf.reduce_sum(v, axis=-2)\n",
    "        print(\"v shape:\", v.shape)\n",
    "\n",
    "##-----------------------------------------------------\n",
    "#         n = tf.reduce_sum(n, axis=-1)\n",
    "#         pn = tf.math.top_k(n, k = self.num_out)\n",
    "#         n = pn.values\n",
    "#         index = pn.indices\n",
    "#         v = tf.gather(v,index, batch_dims=-1)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(tf.rank(x))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train, axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.sum(np.sum(x_train, axis = -1), axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "d=np.expand_dims(d, axis=-1)\n",
    "\n",
    "x_train = x_train/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (1, 18)\n",
      "vc shape: (1, 18)\n",
      "v shape: (1, 18, 7)\n",
      "wk tf.Tensor(\n",
      "[[[ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]\n",
      "  [ 2.6270730e+19 -8.2268506e+18  2.3547427e+19  3.4691540e+19\n",
      "   -2.6427677e+19  2.5053866e+19 -3.0322136e+19]]], shape=(1, 18, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[ 2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19  2.6270730e+19  2.6270730e+19\n",
      "    2.6270730e+19  2.6270730e+19]\n",
      "  [-8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18 -8.2268506e+18 -8.2268506e+18\n",
      "   -8.2268506e+18 -8.2268506e+18]\n",
      "  [ 2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19  2.3547427e+19  2.3547427e+19\n",
      "    2.3547427e+19  2.3547427e+19]\n",
      "  [ 3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19  3.4691540e+19  3.4691540e+19\n",
      "    3.4691540e+19  3.4691540e+19]\n",
      "  [-2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19 -2.6427677e+19 -2.6427677e+19\n",
      "   -2.6427677e+19 -2.6427677e+19]\n",
      "  [ 2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19  2.5053866e+19  2.5053866e+19\n",
      "    2.5053866e+19  2.5053866e+19]\n",
      "  [-3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19 -3.0322136e+19 -3.0322136e+19\n",
      "   -3.0322136e+19 -3.0322136e+19]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[ 1.1536372e+00  8.6522788e-01  8.5080743e+02  1.4420465e+03\n",
      "    5.7681859e-01  0.0000000e+00  8.6522788e-01  8.6522788e-01\n",
      "    2.5956836e+00  5.7105042e+02  2.7975702e+02  5.7076196e+02\n",
      "    0.0000000e+00  2.8300451e+04  1.3720034e+01 -3.5294086e+01\n",
      "    6.1719586e+02  1.1536372e+03]\n",
      "  [-8.5340548e-01 -6.4005411e-01 -6.2938654e+02 -1.0667568e+03\n",
      "   -4.2670274e-01  0.0000000e+00 -6.4005411e-01 -6.4005411e-01\n",
      "   -1.9201623e+00 -4.2243570e+02 -2.0695082e+02 -4.2222235e+02\n",
      "    0.0000000e+00 -2.0935316e+04 -1.0149424e+01  2.6108873e+01\n",
      "   -4.5657193e+02 -8.5340546e+02]\n",
      "  [ 1.4279835e+00  1.0709877e+00  1.0531378e+03  1.7849794e+03\n",
      "    7.1399176e-01  0.0000000e+00  1.0709877e+00  1.0709877e+00\n",
      "    3.2129629e+00  7.0685187e+02  3.4628601e+02  7.0649487e+02\n",
      "    0.0000000e+00  3.5030578e+04  1.6982794e+01 -4.3687370e+01\n",
      "    7.6397119e+02  1.4279835e+03]\n",
      "  [-1.1096001e-02 -8.3220005e-03 -8.1833000e+00 -1.3870001e+01\n",
      "   -5.5480003e-03  0.0000000e+00 -8.3220005e-03 -8.3220005e-03\n",
      "   -2.4966002e-02 -5.4925203e+00 -2.6907802e+00 -5.4897461e+00\n",
      "    0.0000000e+00 -2.7220154e+02 -1.3196307e-01  3.3946827e-01\n",
      "   -5.9363604e+00 -1.1096001e+01]\n",
      "  [-7.7478671e-01 -5.8109003e-01 -5.7140521e+02 -9.6848340e+02\n",
      "   -3.8739336e-01  0.0000000e+00 -5.8109003e-01 -5.8109003e-01\n",
      "   -1.7432702e+00 -3.8351941e+02 -1.8788577e+02 -3.8332571e+02\n",
      "    0.0000000e+00 -1.9006680e+04 -9.2144222e+00  2.3703630e+01\n",
      "   -4.1451089e+02 -7.7478668e+02]\n",
      "  [-8.7473464e-01 -6.5605098e-01 -6.4511682e+02 -1.0934183e+03\n",
      "   -4.3736732e-01  0.0000000e+00 -6.5605098e-01 -6.5605098e-01\n",
      "   -1.9681530e+00 -4.3299365e+02 -2.1212315e+02 -4.3277496e+02\n",
      "    0.0000000e+00 -2.1458553e+04 -1.0403088e+01  2.6761414e+01\n",
      "   -4.6798303e+02 -8.7473462e+02]\n",
      "  [-1.6690795e+00 -1.2518096e+00 -1.2309462e+03 -2.0863494e+03\n",
      "   -8.3453977e-01  0.0000000e+00 -1.2518096e+00 -1.2518096e+00\n",
      "   -3.7554290e+00 -8.2619440e+02 -4.0475180e+02 -8.2577710e+02\n",
      "    0.0000000e+00 -4.0945023e+04 -1.9850113e+01  5.1063404e+01\n",
      "   -8.9295758e+02 -1.6690796e+03]]], shape=(1, 7, 18), dtype=float32)\n",
      "kdiv tf.Tensor([[35989.742 34145.016 35813.79  36438.703 35999.33  35913.438 36220.984]], shape=(1, 7), dtype=float32)\n",
      "k tf.Tensor(\n",
      "[[[0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225\n",
      "   0.23570225 0.23570225 0.23570225 0.23570225 0.23570225 0.23570225]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228\n",
      "   0.23570228 0.23570228 0.23570228 0.23570228 0.23570228 0.23570228]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]\n",
      "  [0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226\n",
      "   0.23570226 0.23570226 0.23570226 0.23570226 0.23570226 0.23570226]]], shape=(1, 7, 18), dtype=float32)\n",
      "q tf.Tensor(\n",
      "[[[3.6966380e-02 3.0038426e-02 3.2512918e-01 3.5053056e-01 2.1944409e-02\n",
      "   0.0000000e+00 3.0038426e-02 3.0038426e-02 6.1665431e-02 3.0594465e-01\n",
      "   2.7164879e-01 3.0592036e-01 0.0000000e+00 4.9394003e-01 1.2958258e-01\n",
      "   1.7306793e-01 3.0968288e-01 3.3978647e-01]\n",
      "  [3.1124566e-02 2.4955617e-02 3.2517225e-01 3.5175481e-01 1.7925721e-02\n",
      "   0.0000000e+00 2.4955617e-02 2.4955617e-02 5.4056674e-02 3.0509943e-01\n",
      "   2.6922941e-01 3.0507401e-01 0.0000000e+00 5.0186938e-01 1.2163760e-01\n",
      "   1.6645484e-01 3.0901039e-01 3.4051058e-01]\n",
      "  [4.1416258e-02 3.3991005e-02 3.2497981e-01 3.4959647e-01 2.5157360e-02\n",
      "   0.0000000e+00 3.3991005e-02 3.3991005e-02 6.7146964e-02 3.0638611e-01\n",
      "   2.7313933e-01 3.0636257e-01 0.0000000e+00 4.8855704e-01 1.3490477e-01\n",
      "   1.7740490e-01 3.1000936e-01 3.3918458e-01]\n",
      "  [1.3964046e-03 1.0487455e-03 2.8059804e-01 3.4158731e-01 7.0012844e-04\n",
      "   0.0000000e+00 1.0487455e-03 1.0487455e-03 3.1205164e-03 2.3672052e-01\n",
      "   1.6524658e-01 2.3666644e-01 0.0000000e+00 7.0994109e-01 1.5685607e-02\n",
      "   3.6985498e-02 2.4508846e-01 3.1545955e-01]\n",
      "  [2.9375188e-02 2.3457661e-02 3.2514268e-01 3.5212332e-01 1.6765820e-02\n",
      "   0.0000000e+00 2.3457661e-02 2.3457661e-02 5.1673368e-02 3.0477071e-01\n",
      "   2.6837167e-01 3.0474490e-01 0.0000000e+00 5.0450039e-01 1.1898976e-01\n",
      "   1.6421126e-01 3.0873981e-01 3.4071052e-01]\n",
      "  [3.1581409e-02 2.5348648e-02 3.2517639e-01 3.5165882e-01 1.8231904e-02\n",
      "   0.0000000e+00 2.5348648e-02 2.5348648e-02 5.4670598e-02 3.0517879e-01\n",
      "   2.6944196e-01 3.0515346e-01 0.0000000e+00 5.0120461e-01 1.2230630e-01\n",
      "   1.6701820e-01 3.0907512e-01 3.4045699e-01]\n",
      "  [4.4809200e-02 3.7049923e-02 3.2481110e-01 3.4887856e-01 2.7695838e-02\n",
      "   0.0000000e+00 3.7049923e-02 3.7049923e-02 7.1170427e-02 3.0663100e-01\n",
      "   2.7411965e-01 3.0660796e-01 0.0000000e+00 4.8472837e-01 1.3863398e-01\n",
      "   1.8040195e-01 3.1017375e-01 3.3869913e-01]]], shape=(1, 7, 18), dtype=float32)\n",
      "v shape: (1, 18, 7)\n",
      "n shape: (1, 18, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 18), dtype=float32, numpy=\n",
       " array([[9.7922925e+17, 8.0966167e+17, 7.1021882e+18, 7.6290285e+18,\n",
       "         6.0524301e+17, 0.0000000e+00, 8.0966167e+17, 8.0966167e+17,\n",
       "         1.5553235e+18, 6.7042557e+18, 5.9927380e+18, 6.7037515e+18,\n",
       "         0.0000000e+00, 1.0603152e+19, 3.0297832e+18, 3.9428487e+18,\n",
       "         6.7817976e+18, 7.4061943e+18]], dtype=float32)>,\n",
       " array([[ 4.00000e+00,  3.00000e+00,  2.95000e+03,  5.00000e+03,\n",
       "          2.00000e+00,  0.00000e+00,  3.00000e+00,  3.00000e+00,\n",
       "          9.00000e+00,  1.98000e+03,  9.70000e+02,  1.97900e+03,\n",
       "          0.00000e+00,  9.81260e+04,  4.75714e+01, -1.22375e+02,\n",
       "          2.14000e+03,  4.00000e+03]], dtype=float32))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_rg[15:16]\n",
    "Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x,x,x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "(None, 18)\n",
      "(None, 18)\n"
     ]
    }
   ],
   "source": [
    "## tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(18))\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.math.is_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(x_rg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_116 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_48 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_117 (Sy (None, 18)                70        \n",
      "_________________________________________________________________\n",
      "operator__basis_49 (Operator (None, 18)                20        \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x_rg = np.array(x_rg)\n",
    "y_rg = np.array(y_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rg = x_rg.astype(np.float32)\n",
    "y_rg = y_rg.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 1.3993e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 6s 8ms/step - loss: 0.2474 - accuracy: 1.3881e-04\n",
      "Epoch 2/10\n",
      "676/676 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0513 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0370 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0323 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0342 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "674/676 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0260 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0243 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0244 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "671/676 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0253 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "670/676 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "676/676 [==============================] - 5s 8ms/step - loss: 0.0227 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff282d1aa90>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), callbacks = callbacks, shuffle=True , epochs=10, batch_size=32, verbose=1)\n",
    "# modelANN.fit(np.log(np.abs(x_rg)+1), np.log(np.abs(y_rg)+1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n",
      "v shape: (None, 18)\n",
      "vc shape: (None, 18)\n",
      "v shape: (None, 18, 7)\n",
      "v shape: (None, 18, 7)\n",
      "n shape: (None, 18, 7)\n"
     ]
    }
   ],
   "source": [
    "y_pre = modelANN.predict(np.log(np.abs(x_rg)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5294644 ],\n",
       "       [0.46715382],\n",
       "       [0.5347007 ],\n",
       "       ...,\n",
       "       [0.5334146 ],\n",
       "       [0.5299744 ],\n",
       "       [0.5346126 ]], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(y_pre, histtype='step')\n",
    "# plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "plt.scatter(y_pre,np.log(np.abs(y_rg)+1))\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pre, histtype='step')\n",
    "plt.hist(np.log(np.abs(y_rg)+1), histtype='step' )\n",
    "# plt.xlim([0,2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28)\n",
      "(None, 784)\n",
      "n shape: (None, 784, 100)\n",
      "v shape: (None, 100)\n",
      "(None, 100)\n",
      "v shape: (None, 100, 7)\n",
      "n shape: (None, 100, 7)\n",
      "(None, 100)\n",
      "(None, 100)\n",
      "(None, 10)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "inputs = tf.keras.Input(shape=(28,28))\n",
    "x = inputs\n",
    "# x = tf.cast(x, tf.float64)\n",
    "print(x.shape)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# print(x.shape)\n",
    "x = Data_Selection(node = 100, num_out=20,rank=tf.rank(x))(x,x,x)\n",
    "print(x.shape)\n",
    "\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# c = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# c = tf.squeeze(c, axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "# print(x.shape)\n",
    "# a = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([x,b], axis=-1)\n",
    "# c = tf.concat([x,c], axis=-1)\n",
    "# print(\"a:\",a.shape)\n",
    "\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# c = Operator_Basis(num_out=1,rank=tf.rank(c))(c, c, c)\n",
    "# print(\"a:\",a.shape)\n",
    "# a = tf.squeeze(a, axis=-1)\n",
    "\n",
    "# x = tf.concat([x,a], axis=-1)\n",
    "# b = tf.concat([b,c], axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(b))(b, b, b)\n",
    "# x = tf.squeeze(x, axis=-1)\n",
    "# b = tf.squeeze(b, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# a = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# b = Symmetry_Set_Basis(num_out=1, rank=tf.rank(x))(x, x, x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# x = Operator_Basis(num_out=1,rank=tf.rank(x))(x, x, x)\n",
    "# a = Operator_Basis(num_out=1,rank=tf.rank(a))(a, a, a)\n",
    "# b = Operator_Basis(num_out=1,rank=tf.rank(b))(b, b, b)\n",
    "# print(x.shape)\n",
    "# x = tf.concat([x,a,b], axis=-1)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(32)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "print(x.shape)\n",
    "modelANN = tf.keras.Model(inputs= inputs, outputs=x, name='ANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ANN\"\n",
    "save_dir = './test1/'\n",
    "model_name = '%s_model_'% model_type \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ANN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "data__selection_16 (Data_Sel (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "symmetry__set__basis_45 (Sym (None, 100)               70        \n",
      "_________________________________________________________________\n",
      "operator__basis_30 (Operator (None, 100)               30        \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,510\n",
      "Trainable params: 1,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelANN.compile(optimizer='adam' , loss=loss_fn, metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelANN.compile(optimizer='adam',\n",
    "                 loss=loss_fn,\n",
    "                 metrics=['accuracy'])\n",
    "modelANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [ for i in y_train]\n",
    "y2 = []\n",
    "for i in y_train:\n",
    "    vec = np.zeros([10])    \n",
    "    vec[i]=1\n",
    "    y2.append(vec)\n",
    "y2=np.array(y2)    \n",
    "y2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "n shape: (32, 784, 100)\n",
      "v shape: (32, 100)\n",
      "v shape: (32, 100, 7)\n",
      "n shape: (32, 100, 7)\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1954 - accuracy: 0.2388\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1695 - accuracy: 0.2695\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 2.1632 - accuracy: 0.2755\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 53s 29ms/step - loss: 2.1611 - accuracy: 0.2781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4141d8550>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# modelANN.fit(x_train, y2 , callbacks = callbacks, shuffle=True , epochs=400, batch_size=32, verbose=1)\n",
    "modelANN.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection Block\n",
    "class Selection(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(Selection, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "#         self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_(t+1) = x_t - lr*grad.(f(x_t))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540412\n",
      "0.9305041\n",
      "0.90742856\n",
      "0.8848088\n",
      "0.862639\n",
      "0.8409134\n",
      "0.8196262\n",
      "0.79877156\n",
      "0.7783437\n",
      "0.7583367\n",
      "0.73874485\n",
      "0.7195623\n",
      "0.70078325\n",
      "0.68240196\n",
      "0.66441256\n",
      "0.64680934\n",
      "0.6295866\n",
      "0.6127385\n",
      "0.59625936\n",
      "0.5801435\n",
      "0.5643853\n",
      "0.54897904\n",
      "0.5339191\n",
      "0.5191999\n",
      "0.50481594\n",
      "0.4907616\n",
      "0.47703144\n",
      "0.46361995\n",
      "0.4505217\n",
      "0.43773136\n",
      "0.4252435\n",
      "0.41305286\n",
      "0.40115413\n",
      "0.3895421\n",
      "0.3782116\n",
      "0.36715743\n",
      "0.35637453\n",
      "0.34585783\n",
      "0.33560234\n",
      "0.3256031\n",
      "0.3158552\n",
      "0.30635378\n",
      "0.29709405\n",
      "0.28807122\n",
      "0.2792806\n",
      "0.2707176\n",
      "0.26237753\n",
      "0.25425592\n",
      "0.24634825\n",
      "0.23865008\n",
      "0.23115706\n",
      "0.22386485\n",
      "0.21676919\n",
      "0.20986587\n",
      "0.20315073\n",
      "0.1966197\n",
      "0.19026873\n",
      "0.18409383\n",
      "0.1780911\n",
      "0.17225665\n",
      "0.16658668\n",
      "0.16107745\n",
      "0.15572527\n",
      "0.1505265\n",
      "0.14547755\n",
      "0.14057492\n",
      "0.13581514\n",
      "0.13119482\n",
      "0.12671058\n",
      "0.12235916\n",
      "0.11813731\n",
      "0.11404186\n",
      "0.11006968\n",
      "0.10621771\n",
      "0.102482945\n",
      "0.09886242\n"
     ]
    }
   ],
   "source": [
    "while var1.numpy()>0.1:\n",
    "    opt.minimize(loss, [var1]).numpy()\n",
    "    print(var1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,1],[2,2],[3,3]])\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [4, 4],\n",
       "       [9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.pow(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry Variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: m<=n\n",
    "def find_N(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    n = a[-1:].numpy()\n",
    "    n = n[0]\n",
    "    return n\n",
    "\n",
    "def Tile_reshape(cn):\n",
    "    a = cn.shape\n",
    "    a = tf.constant(a)\n",
    "    b = a*0+1\n",
    "    a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "    return a\n",
    "def VP(m, cn): # m: order,  cn: input tensor, k: range\n",
    "    cn = tf.cast(cn, tf.float64)\n",
    "    vp = tf.math.pow(cn,m)\n",
    "    vp = tf.reduce_sum(vp, axis = -1)\n",
    "    vp = tf.expand_dims(vp, axis = -1)\n",
    "    vp = tf.tile(vp, Tile_reshape(cn))\n",
    "    return vp\n",
    " \n",
    "def VC1(cn):\n",
    "    vc = tf.reduce_sum(cn, axis = -1)\n",
    "    vc = tf.expand_dims(vc, axis=-1)\n",
    "    vc = tf.tile(vc, Tile_reshape(cn))\n",
    "    vc = tf.cast(vc, tf.float64)\n",
    "    return vc\n",
    "def VC2(cn):\n",
    "    vc = (VC1(cn)**2 - VP(2, cn))/2\n",
    "    return vc\n",
    "def VC3(cn):\n",
    "    vc1 = VC1(cn)\n",
    "    vp2 = VP(2,cn)\n",
    "    vp3 = VP(3,cn)\n",
    "    vc = (vc1**3-vp3-3*(vp2 * vc1-vp3 ))/6\n",
    "    return vc\n",
    "def VC4(cn):\n",
    "    n = find_N(cn)\n",
    "#     vc = (VC3(cn)*VP(0,cn) - 3/(n-2)*VC2(cn)*VP(1,cn) + 3/(n-2)*2/(n-1)*VC1(cn)*VP(3,cn) - 3/(n-2)*2/(n-1)*VP(4,cn) )/(n-3)\n",
    "    vc = (VC3(cn)*VP(1,cn) - VC2(cn)*VP(2,cn) + VC1(cn)*VP(3,cn) - VP(4,cn) )/4\n",
    "    return vc\n",
    "\n",
    "## VCN: \n",
    "# vcn = 0\n",
    "# for i in range(N):\n",
    "#     vcn += VC(N-i-1)VP(i+1)*(-1)**i\n",
    "# vcn = vcn/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Con(n,k):\n",
    "    fc=1\n",
    "    for i in range(k):\n",
    "        fc *=(n-i)\n",
    "        fc /= (i+1)\n",
    "    return fc\n",
    "def text(cn):\n",
    "    vc = (VC2(cn)*VP(1, cn) - VC1(cn)*VP(2,cn) + VP(3,cn))/3\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "n = a[-1:].numpy()\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float64, numpy=\n",
       "array([[ 225.,  225.,  225.,  225.,  225.],\n",
       "       [  10.,   10.,   10.,   10.,   10.],\n",
       "       [1175., 1175., 1175., 1175., 1175.]])>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC3(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561.5,  561.5,  561.5,  561.5,  561.5],\n",
       "       [   5. ,    5. ,    5. ,    5. ,    5. ],\n",
       "       [3616.5, 3616.5, 3616.5, 3616.5, 3616.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = tf.constant([[1,2,3,4,5],[1,1,1,1,1],[3,4,5,6,7]])\n",
    "# cn = tf.constant([[1,2,3,4],[1,1,1,1],[3,4,5,6]])\n",
    "\n",
    "# cn.numpy()\n",
    "VC4(cn).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "fc=1\n",
    "for i in range(N):\n",
    "    fc*=(i+1)\n",
    "    \n",
    "a = 0\n",
    "for i in range(N):\n",
    "    a += fc/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-887b695135f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \"\"\"\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.math.multiply(VC3(cn),VC1(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cn.shape\n",
    "a = tf.constant(a)\n",
    "b = a*0+1\n",
    "a = tf.concat([b[:-1],b[-1:]*tf.constant(a[-1])], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [2, 2, 2, 2],\n",
       "       [3, 3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(cn, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
